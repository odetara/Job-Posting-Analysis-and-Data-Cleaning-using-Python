job_id,job_employment_type,job_title,job_apply_link,job_description,job_city,job_country,job_posted_at_timestamp,employer_website,employer_company_type
1,FULLTIME,Data Engineer,https://ca.linkedin.com/jobs/view/data-engineer-at-clinia-3790345177,"• *Please note that our offices will be closed from December 25 to January 5, 2024 (inclusively). We will be delighted to respond to applications received as soon as we return, during the week of January 8, 2024. Happy Holidays!

Who are we?

We are a health technology startup building the search and data infrastructure for digital health systems of tomorrow. Our mission is simple, but the environment which we specialize in is complex.

We power enterprise-scale health organizations and healthtech startups to improve and optimize access to health care & support across North America and Europe. At our heart, we are a product & technology driven organization, and we look for people who share our vision leveraging technology to solve and scale some of the most impactful operational challenges in healthcare.

As our team grows, we are looking for an experienced data engineer to help us tie together our data processing pipelines that enable the development of our health-care specific ML models.

What are we looking for?

A FIT.

We would like the person who joins our team to be someone:
• who gets up in the morning wanting to be better than the day before, and for whom a 7/10 is not ""ok"";
• who wants to be part of a team and who has passion and collaboration as a must to reach a goal.

Your role

We are looking for a person with a robust background in building data pipelines to provide datasets for training machine learning models. We desire someone who is deeply passionate about ensuring data quality and is dedicated to continuously enhancing established processes to support the training of machine learning models.

As a Data Engineer, you will be in charge of:

1. Data Infrastructure Design:

How
• Collaborate closely with web scraping engineers, ETL engineers, and stakeholders to understand data requirements.
• Design secure and efficient processes for ingesting healthcare data from private sources and crawled websites.
• Develop and maintain robust data cleaning and transformation procedures for ensuring data quality and consistency.
• Utilize Spark and Ray for scalable, high-performance distributed data processing optimized for large healthcare datasets.
• Implement and manage Apache Airflow workflows for scheduling and automating routine healthcare data processing tasks.

Why
• Support the development of Health Grade Models for Clinia's search engine, with datasets serving as the foundational elements.
• Ensure data availability, versioning, and reliability to meet the critical needs of model development.

2. Security, Compliance, and Quality Assurance

How
• Work collaboratively with the GRC Lead to ensure data processing aligns with regulations and certifications (e.g., GDPR, HIPAA).
• Implement security measures such as data encryption, access controls, and anonymization techniques to safeguard sensitive data.

Why
• Clinia works in the HealthCare industry and it’s our duty to deploy the most secure processes when dealing with sensitive data. to minimize the risks of data leakages and misuse.
• Comply with certifications required for business development across diverse legislations due to the sensitive nature of the healthcare data.

3. Documentation and Knowledge Sharing:

How
• Maintain comprehensive documentation for data processing pipelines, including design decisions, configurations, and workflow dependencies.
• Facilitate knowledge-sharing sessions with the data engineering team to disseminate best practices, new techniques, and updates.

Why
• Promote transparency and understanding within the team by documenting key aspects of the data processing infrastructure.
• Foster a collaborative and informed team culture, allowing team members to stay updated on the latest advancements in data engineering and technology.

In terms of skills, you should have:
• Solid Python programming skills, as well as proficiency with SQL.
• Knowledge of different data processing paradigms (ETL, ELT, etc.)
• Experience working with data streaming pipelines
• Experience working with parallel and distributed data computing (Ray, Spark, Dask, Hadoop, etc.)
• Experience working with versioned data lakes (Apache Iceberg)
• Experience working with containers and cloud computing
• Knowledge of Scala (nice to have)
• Experience working with sensitive and clinical data (nice to have)

If you have other skills that you think would be a plus for the team, we are of course very curious to hear from you.

What we have to offer you
• 4 weeks of vacation;
• Summer schedules;
• Group insurance from day 1;
• Direct access to a 24/7 online doctor for you and your family through our partner (and client) Dialogue from day 1;
• Employee and Family Assistance Program (EFAP);
• Flexible hours: free to work the hours you are most productive;
• Flexible office: free to work from wherever you want;
• Autonomy, because Hey, you're the specialist;
• Independence of action in a highly collaborative environment;
• High-performance equipment (MacBook) and a workstation adapted to your needs (all team members have their own stand-up desk);
• Camellia Sinensis tea and Montreal roasted coffee for your office time;
• Pet therapy with Clinia's dogs @pico_the_teckle, Alaska and Opale;
• Team buildings, 5@7, and team activities.

But also, this:

Moving is important : Clinia fundamentally believes in a balanced, active lifestyle. That's why we decided to offer a bonus ($) for every hour of physical activity you do: hiking, biking, running, climbing - whatever your sport, whatever day of the week, we encourage you to keep going

We also offer the opportunity to :
• Play an essential role in the development of a scaling company;
• Contribute to the development of a product used by millions of patients in Canada;
• Work with a team of persevering and ambitious people with a true team spirit.

Our approach is simple:

We are a young and dynamic team that advocates the involvement and equality of everyone in decision-making - we don't say that to be cool, we really believe in it. So we're looking for someone who can use their expertise to help us build a solid future for tomorrow.Do you have the motivation, focus and entrepreneurial spirit to meet this challenge? We're looking for someone like you!

Apply now !
• By submitting your application, you consent to share your personal information with Clinia, which will use it to process your application for this job position. Clinia will not use this information for any other purposes than stated above.",Montréal,CA,2023-12-19 20:22:00,http://www.bdo.com,Consulting
2,FULLTIME,Data Engineer,https://ca.linkedin.com/jobs/view/data-engineer-at-artemis-consultants-3790054925,"We are seeking an experienced and passionate Data Engineer who can designing, developing, maintain and govern data assets and data related products in customer platforms by liaising with multiple stakeholders.
• Bachelor’s or Master’s (preferred) degree in in a quantitative or technical field such as Computer Science, Information Technology, Computer Engineering or equivalent
• 4+ years of experience in Data Engineering, Data Governance and working with Customer Data Platforms (CDP)
• Knowledge of all popular CDPs and expert working knowledge of at least one CDP
• Knowledge of market trends including cloud technology
• Hands on data stewardship experience
• Strong working knowledge of SQL, Hadoop, Hive, Python and PySpark
• Demonstrated interest in learning about emerging data platforms and Big Data technologies
• Strong communication, problem solving, and organizational skills
• Must be detail oriented, quality driven, and able to shift quickly to new tasks
• Experience working with Amperity CDP is preferred but not required.",London,CA,2023-12-19 15:55:00,http://www.bdo.com,Consulting
3,FULLTIME,"2024 RBCIS, Summer Co-op Data Engineer / Full Stack Dev (4 months)",https://ca.linkedin.com/jobs/view/2024-rbcis-summer-co-op-data-engineer-full-stack-dev-4-months-at-rbc-3784463482,"Job Summary

Job Description

What is the opportunity?

This role will encompass an end-to-end system view for Data and Digital solutions within I&TS Data management office.
• Build real-time data pipelines (inbound, outbound) through container-based solutions
• Build/enhance Portal and APIs
• Integrate data with Cloud based platforms, publish data through APIs and Portal
• Participate in Data curation requirements and support Data and Digital needs of business and technology stakeholders
• Evaluate current state of data access control in regards to authentication, authorization and encryption practices across I&TS systems. Develop and support remediation strategy
• Work in an agile team of Data Engineers, Developers

What do you need to succeed?
• Data Engineering: Python, Airflow, Spark
• API: Node.JS, NestJS, Apigee
• SQL/Database: Microsoft SQL Server, Azure SQL, Stored procedures
• Portal/analytics solutions: Angular, D3.js
• Cloud and Containers: Azure (ADLS2, Azure Databricks), Openshift, Docker
• Strong knowledge of algorithms and data structures.

Nice to have:
• Master’s degree in Computer science or equivalent experience
• Automation/DevOps: Jenkins, Selenium and similar technologies
• Source code control: GIT
• Experience working in agile/SaFe environment

Job Skills

Angular, Docker Kubernetes Administration, Node.js, Python (Programming Language), Structured Query Language (SQL)

Additional Job Details

Address:

RBC CENTRE, 155 WELLINGTON ST W:TORONTO

City:

TORONTO

Country:

Canada

Work hours/week:

37.5

Employment Type:

Full time

Platform:

Wealth Management

Job Type:

Student/Coop (Fixed Term)

Pay Type:

Salaried

Posted Date:

2023-12-19

Application Deadline:

2024-01-21

Inclusion and Equal Opportunity Employment

At RBC, we embrace diversity and inclusion for innovation and growth. We are committed to building inclusive teams and an equitable workplace for our employees to bring their true selves to work. We are taking actions to tackle issues of inequity and systemic bias to support our diverse talent, clients and communities.

We also strive to provide an accessible candidate experience for our prospective employees with different abilities. Please let us know if you need any accommodations during the recruitment process.

Join our Talent Community

Stay in-the-know about great career opportunities at RBC. Sign up and get customized info on our latest jobs, career tips and Recruitment events that matter to you.

Expand your limits and create a new future together at RBC. Find out how we use our passion and drive to enhance the well-being of our clients and communities at jobs.rbc.com",Toronto,CA,2023-12-19 22:30:00,http://www.rbc.com,Finance
4,FULLTIME,Lead Data Engineer,https://ca.linkedin.com/jobs/view/lead-data-engineer-at-nortal-3790096182,"Overview

At Nortal, we are driven by a grand vision – to create solutions that have a meaningful and far-reaching impact on people's lives. Whether it's revolutionizing tax systems, enhancing healthcare, or providing more convenient telecom services, our projects have already touched the lives of over half a billion people worldwide, and we're only just beginning.

We are providing end-to-end data solutions to governments and corporations in Europe, MEA, and North America, from data modeling and designing architectural solutions to their implementation. We work in a great atmosphere with highly skilled professionals, where each member can cover aspects required for a fully implemented solution, including DevOps duties - CI/CD and infrastructure provisioning.

Would you like to work with an extremely talented international team? If you have been dreaming about getting your hands dirty by writing highly scalable data processing code and creating data pipelines that make a difference in the world, we have job offer for you.

We are looking for a Lead Data Engineer, to take on large-scale challenges and build significant impact stories together!

Responsibilities
• Design, develop, and maintain robust data pipelines, ETL processes, and data integration solutions using a combination of different technologies and frameworks such as Azure/AWS, SQL, Python, etc.
• Develop and maintain data models, data warehouses, and data marts to support data analytics and business intelligence activities.
• Ensure data quality and integrity across the entire data lifecycle, from data ingestion to data consumption.
• Select and integrate appropriate data storage technologies, such as SQL or NoSQL databases, and Hadoop-based systems.
• Develop and maintain data processing and analysis tools using programming languages (Python is preferred)
• Design and implement data security and access control mechanisms to protect sensitive data and comply with data privacy regulations.
• Collaborate with clients and stakeholders to understand their business needs and develop data-driven solutions to meet their requirements.
• Help junior data engineers within projects.
• Contribute to the development and improvement of Nortal's data engineering methodologies and best practices.
• Keep up to date with the latest trends and innovations in data engineering and big data technologies and share knowledge with colleagues and clients.
• Collaborate with data, engineering, design, product, and executive teams to assist them with data-related technical issues.

Qualifications

What you will need to succeed:
• At least 5 years of combined data engineering and software development experience (Python background preferred)
• Familiarity with major cloud providers (GCP, AWS, Azure, etc.)
• Experience with Python and related development frameworks
• Experience with SQL and mainstream database platforms (Postgres, MongoDB, Oracle, etc.)
• Familiarity with Docker and Kubernetes
• Experience with at least one of the following: Databricks, Snowflake, Azure Synapse, Airflow
• Knowledge about big data and data modeling
• Experience with event-based modeling and stream processing, including Spark and Kafka
• Understanding and experience with data pipelines, warehousing, and their scalabilities
• Experience in data security and governance
• Keen on learning and exploring modern technologies/solutions
• Team player with effective communication skills

Why join Nortal?
• We hire people not only for their skills but also for cultural fit. We live by our values: commit to delivering value and results, take ownership, empower yourself and others, and own your future and growth. Besides our professionalism, we like to spice things up with good humor
• We care about your growth & development. In Nortal we support constant improvement and knowledge sharing via Learning Hives, external and internal training, dedicated time for self-learning, a mentorship program, and strong 1:1 culture
• We prioritize your health & well-being
• We support your work-life balance and provide flexible working hours",London,CA,2023-12-19 17:06:00,http://www.nortal.com,Computer Services
5,FULLTIME,2024 Investor Services - Business Data Analyst Co-op (12 months),https://jobs.rbc.com/ca/en/job/R-0000074144/2024-Investor-Services-Business-Data-Analyst-Co-op-12-months,"Job Summary

What is the opportunity?

As the Business Data Analyst co-op, you will work as part of an experienced Data and Analytics team that supports Investor Services’ businesses with analytics and insights to support development of new opportunities, manage and support business priorities, track and understand key leading and lagging results.

The role requires you to have an active interest in Financial data and Operational flows. Successful candidate will look to take initiative when trying to solve abstract problems through creativity and structure. The candidate must demonstrate a Growth Mindset and be willing to learn and absorb concepts “on the job”.

Job Description

What will you do?

Use your data and analytic skills to help business teams understand trends, solve problems and support business decisions including:
• Produce data-driven insights to help in informed decisions and actions by telling a convincing story and effectively communicate findings to business partners and executives.
• Prepare and integrate large and various types of data (structured/non-structured).
• Leverage visualization tools/packages to create powerful representations of results.
• Participate in meetings to gather and document business requirements.

What do you need to succeed?

Must-have:
• Working towards a degree in Business, Computer Science, Data Science, Mathematics, or other quantitative disciplines
• Advanced Python coding skills and hands on experience with data analysis and transformation packages such as Pandas and Numpy
• Familiarity with database and query languages (e.g. SQL)
• Strong communication and presentation skills
• Must be a self-starter, with strong analytical and interpersonal skills, as well as the ability to work in a fast-paced environment and manage multiple competing priorities
• Ability to learn and absorb new concepts (in business and in systems) quickly and apply new knowledge
• Exceptional problem-solving skills and ability to conceptualize strategy
• Attention to detail, organization, ability to multitask and time management is critical

Nice-to-have
• Strong working knowledge of developing Power BI reports/dashboards
• Familiarity with ML concepts, NLP, and text analytics methods and packages
• Experience in time-series prediction and anomaly detection
• Experience in working with data science platforms like Dataiku, Azure Databricks, AWS
• Familiarity with python machine learning frameworks such as Scikit Learn

Job Skills

Communication, Computer Literacy, Detail-Oriented, Interpersonal Relationships, Listening Effectively, Personal Development, Taking Initiative

Additional Job Details

Address:

RBC CENTRE, 155 WELLINGTON ST W:TORONTO

City:

TORONTO

Country:

Canada

Work hours/week:

37.5

Employment Type:

Full time

Platform:

Wealth Management

Job Type:

Student/Coop (Fixed Term)

Pay Type:

Salaried

Posted Date:

2023-12-19

Application Deadline:

2024-01-21

Inclusion and Equal Opportunity Employment

At RBC, we embrace diversity and inclusion for innovation and growth. We are committed to building inclusive teams and an equitable workplace for our employees to bring their true selves to work. We are taking actions to tackle issues of inequity and systemic bias to support our diverse talent, clients and communities.
​​​​​​​
We also strive to provide an accessible candidate experience for our prospective employees with different abilities. Please let us know if you need any accommodations during the recruitment process.

Join our Talent Community

Stay in-the-know about great career opportunities at RBC. Sign up and get customized info on our latest jobs, career tips and Recruitment events that matter to you.

Expand your limits and create a new future together at RBC. Find out how we use our passion and drive to enhance the well-being of our clients and communities at jobs.rbc.com.",Toronto,CA,2023-12-20 00:00:00,http://www.rbc.com,Finance
6,FULLTIME,Data Engineer,https://ca.linkedin.com/jobs/view/data-engineer-at-aviva-canada-3770031304,"Individually we are people, but together we are Aviva. Individually these are just words, but together they are our Values – Care, Commitment, Community, and Confidence.

We are looking for a collaborative and resourceful Data Engineer/ETL Developer. You are dedicated, naturally inquisitive and are comfortable in a fast-paced environment.

This role will be part of and a member of our Data Delivery Group, you will be responsible for analysis, design and implementation in high-performing, experienced team. You'll be required to apply your depth of knowledge and expertise to all many areas including requirements, infrastructure, and solutioning. Aviva has embarked on an exciting journey to modernize, craft and build a next generation of data platform to support the growing data needs for data engineering, analytics and Data Science.

We embrace a culture challenging the status quo and constantly look to efficiently simplify processes, technology, and workflow.

This position reports to the AVP – Data Delivery.

What You’ll Do
• Design and Develop ETL Pipeline to ingest data into Hadoop from different data sources (Files, Mainframe, Relational Sources, NoSQL Etc.) using Informatica BDM
• Parse unstructured data, semi structured data such as JSON, XML etc. using Informatica Data Processor.
• Analyze the Informatica PowerCenter Jobs and redesign and develop them in BDM.
• Design and develop efficient Mapping and workflows to load data to Data Marts.
• Perform the GAP analysis between various legacy applications to migrate them to newer platforms/data marts.
• Write efficient queries in Hive or Impala and PostgreSQL to extract data on Adhoc basis to do the data analysis.
• Identify the performance bottlenecks in ETL Jobs and tune their performance by enhancing or redesigning them.
• Work with Hadoop administrators, Postgres DBAs to partition the hive tables, refresh metadata and various other activities, to enhance the performance of data loading and extraction.
• Performance tuning of ETL mappings and queries.
• Write simple or medium complex shell scripts to preprocess the files, schedule ETL jobs etc.
• Identify various manual processes, queries etc. in the Data and BI areas, design and develop ETL Jobs to automate them.
• Participate in daily scrums; work with vendor partners, QA team and business users in various stages of development cycle.
• Advocate importance of data catalogs, data governance and data quality practices.
• Outstanding problem solving skills
• Work in an Agile delivery framework to evolve data models and solution designs to deliver value incrementally.
• You are a self-starter with experience working in a fast-paced agile development environment.

What You’ll Bring
• University degree in Computer Engineering or Computer Science
• 3+ years of experience working on Informatica BDM platform.
• Experience on various execution modes in BDM such Blaze, Spark, Hive, Native.
• 3+ years of experience working on Hadoop Platform, writing hive or impala queries.
• 5+ years of experience working on relational databases (Oracle, Teradata, PostgreSQL etc.) and writing SQL queries.
• Should have deep knowledge on performance tuning of ETL Jobs, Hadoop Jobs, SQL’s, Partitioning, Indexing and various other techniques.
• Experience in writing Shell scripts.
• Experience in Spark Jobs (Python or Scala) is an asset.
• Knowledge/experience in Cloud Data Lake Design – pref AWS technologies like S3, EMR, Redshift, Snowflake, could data catalog etc.,
• Understanding of reporting/analytics tools (QlikSense, SAP Business Objects, SAS, DataIku, etc.,)
• Familiar with the Agile software development
• Excellent verbal and written communication skills
• Insurance knowledge an asset-Ability to foundationally understand complex business process driving technical systems.

What You’ll Get
• Competitive rewards package including base compensation, eligibility for annual bonus, retirement savings, share plan, health benefits, personal wellness, and volunteer opportunities.
• Exceptional Career Development opportunities.
• We’ll support your professional development education.

Additional Information: Aviva Canada has an accommodation process in place to provide accommodations for employees with disabilities. If upon commencement of employment you require a specific accommodation because of a disability, please contact your Talent Acquisition Partner so that an appropriate accommodation can be arranged. This process applies throughout your career with Aviva Canada.",Markham,CA,2023-12-19 14:43:00,http://www.aviva.ca,Finance
7,FULLTIME,Digital Data Analyst (Entry Level) (Fair Marketing Inc),https://ca.linkedin.com/jobs/view/digital-data-analyst-entry-level-fair-marketing-inc-at-bcjobs-3788480358,"We are seeking a motivated and analytic individual to join our team as a Remote Digital Data Analyst. As a Data Analyst, you will be responsible for interpreting and analysing large data sets, making data-driven decisions, and presenting findings to management.

Responsibilities Include
• Collect and analyse large data sets from various sources
• Interpret data and identify trends and patterns
• Create reports and visualisations to communicate findings
• Collaborate with cross-functional teams to provide data-driven insights
• Continuously monitor data for accuracy and completeness
• Identify areas for improvement and make recommendations

Requirements
• Proficient in SQL, Excel, and data visualisation tools such as Tableau or Power BI
• Strong analytic skills with the ability to interpret complex data
• Excellent communication and presentation skills
• Ability to work independently and as part of a team
• Attention to detail and accuracy

If you are a self-starter who is passionate about data and enjoys problem-solving, we encourage you to apply. This is an entry-level position with room for growth within the company.

To apply, please submit your resume and cover letter highlighting your qualifications and why you would be a great fit for this position. We look forward to hearing from you

Value",Vancouver,CA,2023-12-20 04:14:00,http://www.bdo.com,Consulting
8,FULLTIME,Data Engineer,https://ca.bebee.com/job/20231219-5ac8f4a88517c24a0a5ee679438e8178,"Location:
Montreal, Quebec

Our client works to identify and solve the most complex and highest value business problems that can be addressed through data science techniques.

To achieve this, they provide data science, operations research and artificial intelligence solutions and software products to a broad range of industry and technology partners.

In this role, you will work in a client project environment with an AI-Agile Team composed of a Product Manager, consultant, Delivery Team Lead and Data Scientist and contribute to the translation of complex AI/data science algorithms into scalable software.

You will:
• Design, code, create tests, and integrate new features and functionality
• Design, build, and productize complex data pipelines
• Learn the different AI/data science components/models in order for the algorithm to be properly translated in production code
• Participate in scrum project meetings and update stories using project management tools
• Apply CI/CD practices to prevent integration problems as well as ensure that the code is releasable at any point in time
• Participate in the estimation of the Stories based on defined Acceptance Criteria and Definition of Done

Must Have Skills:
• You have 3+ year experience in building B2B solutions in a cloud environment
• You have experience with Operations Research / Machine Learning / Deep Learning
• Experience with Hadoop, Spark, Hive, Snowflake, Databricks, RedShift, BigQuery, etc
• You are a strong developer, fluent in one or more of the prominent tools/platforms and able to implement end-to-end solutions
• You have previous exposure to AI/data science concepts and, with the guidance of seasoned AI/data science engineers, are proficient in the translation of those concepts into production-grade, efficient code (asset).

Cloud:
AWS, Azure or GCP

Languages:
Python

Big Data:
Hadoop, Spark, Hive

Relational Database:
MySql, PostgresSQL, Oracle, MS-SQL

No

Sql:
Cassandra, Elastic Search, Mongo DB

Nice to Have Skills:
• Experience with application and cloud security.
• Helped organizations achieve security compliance such as SOC2, PCI-DSS, GDPR, PIPEDA, HIPAA, etc
• Any relevant security certifications. Specifically in cloud.
• Experience Java, C++, SCALA and Javascript are an asset
#J-18808-Ljbffr",Montréal,CA,2023-12-19 14:50:00,http://www.bdo.com,Consulting
9,FULLTIME,Database Engineer,https://jobs.rbc.com/ca/en/job/R-0000074081/Database-Engineer,"Job Summary

Job Description

What is the opportunity?

Wealth Management Applied Analytics and Innovation (WM AI) is responsible for developing and implementing a data and analytics strategy that delivers key insights to Senior Management, Advisors, and supporting functions across RBC Wealth Management.

Within WM AI, the DevOps/Infrastructure team is responsible for building and supporting the operational infrastructure of various applications and databases that are driving advanced insight and innovation for the business by leveraging data engineering, emergent cloud capabilities, machine learning techniques, and analyzing data sources from across Wealth Management and RBC.

Data engineers within WM AI work closely with the data scientists and analysts to understand the objectives of their projects, build data pipelines, design data architecture, and serve as a subject matter expert in database design decisions, data engineering approaches, and overall application architecture.

What will you do?

As a Data Engineer you will collaborate, innovate, support, and build analytical products and assimilate data in a flexible, start-up environment. You will tackle real RBC Wealth Management business challenges working as a member of a diverse group which includes business partners, Data scientists, Analytics Developers, UX/UI designers, and domain experts.

You will design database solutions, including server management, model data architecture, manage database operations, and support the various analytical tools used for delivery of business objectives. You will be leveraging our MSSQL and BI infrastructure along with other on premises resources, tools, and environments to support advanced business analytics and data applications.

You will work both independently and as part of a team to research, test, and ideate various solutions to business problems. You will work to build, support, and deploy solutions as well as manage infrastructure of various applications. You need to have a passion for building robust, stable, and scalable infrastructure and commitment to continuously improve and adapt existing applications and pipelines.

You will be working in a start-up like setting where fast-fail is highly valued, level of uncertainty is high, and requirements are not all defined in advance. You will be required to challenge the status quo, and think outside the box to develop and design solutions. You will need to be comfortable working with a wide range of stakeholders and functional teams and be able to work closely with stakeholders to drive business outcomes.

What do you need to succeed?

Must Have:
• 3+ years in building data applications, managing ETL pipelines, continuous deployment experience or data modelling experience including either academic research or applied work projects
• Experience in MS analytic toolset like PowerBI, MSSQL Studio, SSMS, SSAS
• Knowledge of database management , operations, and security principles in MSSQL
• Data modelling, design, and architecture in relational databases
• Drive to ensure good and robust design principles, and building scalable and secure solutions

Nice to Have:
• Expressed interest or previous experience in Wealth Management, Finance or FinTech
• In-depth experience in writing and managing databases, complex queries, and ETL pipeline
• Extensive experience designing and building database solutions to solve real world problems, with strong preference of this experience in MSSQL

What’s in it for you?

We thrive on the challenge to be our best, progressive thinking to keep growing, and working together to deliver trusted advice to help our clients thrive and communities prosper. We care about each other, reaching our potential, making a difference to our communities, and achieving success that is mutual.
• Leaders who support your development through coaching and managing opportunities
• Opportunity to try new things, bring fresh ideas, innovation
• Ability to make a difference and lasting impact
• Work in a dynamic, collaborative, progressive, and high-performing team

RBC is committed to supporting flexible work arrangements when and where available. Details to be discussed with Hiring Manager.

RBC requires as a condition of employment that all successful candidates in the United States and Canada be fully vaccinated against COVID-19 prior to their start date, and may require proof of the same. Reasonable accommodation is available where required by law.

Job Skills
Big Data Management, Cloud Computing, Data Architecture, Database Development, Database Structures, Data Management, Data Mining, Data Warehousing (DW), ETL Processing, Problem Solving, Quality Management, Requirements Analysis

Additional Job Details

Address:

RBC CENTRE, 155 WELLINGTON ST W:TORONTO

City:

TORONTO

Country:

Canada

Work hours/week:

37.5

Employment Type:

Full time

Platform:

Wealth Management

Job Type:

Regular

Pay Type:

Salaried

Posted Date:

2023-12-14

Application Deadline:

2024-01-01

Inclusion and Equal Opportunity Employment

At RBC, we embrace diversity and inclusion for innovation and growth. We are committed to building inclusive teams and an equitable workplace for our employees to bring their true selves to work. We are taking actions to tackle issues of inequity and systemic bias to support our diverse talent, clients and communities.
​​​​​​​
We also strive to provide an accessible candidate experience for our prospective employees with different abilities. Please let us know if you need any accommodations during the recruitment process.

Join our Talent Community

Stay in-the-know about great career opportunities at RBC. Sign up and get customized info on our latest jobs, career tips and Recruitment events that matter to you.

Expand your limits and create a new future together at RBC. Find out how we use our passion and drive to enhance the well-being of our clients and communities at jobs.rbc.com.",Toronto,CA,2023-12-20 00:00:00,http://www.rbc.com,Finance
10,FULLTIME,Data Analyst,https://hitmarker.net/jobs/bethesda-data-analyst-898514,"Join Constellation!

Come join Bethesda Game Studios, the award-winning development team behind Starfield, The Elder Scrolls and Fallout. Bethesda Game Studios strives to offer its employees a well-balanced home and work life by providing competitive salaries, a generous benefits program, and offices located in some of North America’s best cities.

With a goal of creating a culture as fun and diverse as our games and our players, we welcome applicants with unique skillsets, experience levels and backgrounds. If you are passionate about making a meaningful contribution to some of the most significant games in the industry we’d love to hear from you!

Responsibilities

Your Daily Life at Bethesda Game Studios

As Data Analyst, you will…
• Provide insights and analysis to our game teams to facilitate the full cycle of game development
• Mine data and perform analysis across game systems to help determine what is fun/not fun in the game, identify game imbalances, identify optimal strategies for monetization, etc.
• Design, develop, distribute, and maintain ad-hoc and recurring reports, visualizations, dashboards, and statistical models
• Interpret data and communicate actionable findings to development and business teams
• Partner with inter-departmental teams to elicit and document collection and reporting requirements
• Work with data and gameplay engineers to ensure architecture will support requirements
• Serve as a subject matter expert and resource for accessing and analyzing data using Tableau or other tools as necessary

Qualifications

What Makes You S.P.E.C.I.A.L.
• You have 3 or more years of experience as a data analayst
• You have applied knowledge of current data analysis visualization techniques, including practical experience with data visualization software (e.g. Tableau, Looker)
• You have strong critical thinking skills with knowledge and experience in analytic techniques and statistics
• You have intermediate to advanced SQL knowledge, including familiarity with statistical, aggregate, and windowing functions
• You are able to gather requirements and define business needs for data collection and analysis
• You are able to articulate with excellent verbal and written communication skills
• You have a passion for Bethesda Game Studios titles",Montréal,CA,2023-12-19 12:22:00,http://www.bdo.com,Consulting
11,CONTRACTOR,Junior Data Analyst,"https://www.ziprecruiter.com/c/Queen-Mary,-University-of-London/Job/Junior-Data-Analyst/-in-Kingston,ON?jid=9807a348c2218729","To display this page you need a browser with JavaScript support.
Competition Number: J1223-0179
Position Title: Junior Data Analyst
Position Number (Final): 00505587
Employee Group: Support Staff - USW Local 2010
Job Category: Information Technology
Department or Area: IT Services
Location: Kingston, Ontario, Canada (Remote)
Grade: 07 Review Salary Information Here
Hours per Week: 35
Job Type: Permanent (Continuing)
Shift: 7 Monday - Friday
Number Of Positions: 1
Date Posted: December 17, 2023
Closing Date: January 14, 2024

COVID 19 On-Campus Requirements

Prior to May 1, 2022, the University required all students, faculty, staff, and visitors (including contractors) to declare their COVID-19 vaccination status and provide proof that they were fully vaccinated or had an approved accommodation to engage in in-person University activities. These requirements were suspended effective May 1, 2022, but the University may reinstate them at any point.

About Queen's University

Queen's University is the Canadian research intensive university with a transformative student learning experience. Here the employment experience is as diverse as it is interesting. We have opportunities in multiple areas of globally recognized research, faculty administration, engineering & construction, athletics & recreation, power generation, corporate shared services, and many more.

We are committed to employment equity and diversity in the workplace and welcome applications from individuals from equity seeking groups such as women, racialized/visible minorities, Indigenous/Aboriginal peoples, persons with a disability, persons who identify in the LGBTQ+ community and others who reflect the diversity of Canadian society.

Come work with us!

Job Summary

A Brief Overview
Do you want to play a key role in developing and transforming the data landscape at one of Canada's universities? If exploring new cloud platform technologies and learning cutting edge skills sounds exciting to you, then we would love to hear from you!

The Information Technology Services (IT Services) department is looking for an experienced IT professional to take a leading role in developing critical data pipelines and dashboards to drive data-driven decision making throughout the university. The Junior Data Analyst will work with our experienced team of data professionals to define, develop, implement and support our critical data platform services. The Junior Data Analyst cleans, defines and transforms data into meaningful models and visualizations to serve as the life blood of our organization. The Junior Data Analyst is a team player; coordinating with internal and external technical subject matter experts to transform requirements into key data capabilities for enterprise data and analytics. The Data Analyst is a detailed oriented person who easily adapts to change and is excited to build new capabilities with leading edge technologies.

This position contributes to building critical data infrastructure, including databases, data pipelines, and dashboards. This position builds database queries to generate relevant information, and interpret and communicate results. This position develops and maintains periodic and ad-hoc reports, dashboards and visualizations. This position also interprets data needs, and determines which data sources to use.

Job Description

What you will do
Contributes to building critical data infrastructure, including databases, data pipelines, and dashboards.
Builds database queries to generate relevant information, and interpret and communicate results.
Develops and maintains periodic and ad-hoc reports, dashboards and visualizations.
Performs data analysis using statistics and modeling and creates reports.
Assists in assessing the quality of data collection.
Interprets data needs, and determines which data sources to use.
Updates and maintains the data catalogue and metadata repository.

Required Education
Four-Year Bachelor Degree or equivalent. In addition, requires trade certification, qualification, or on-going learning to remain ahead of changes in technology or emerging fields.

Required Experience
More than 2 years and up to and including 3 years of experience.
Consideration may be given to an equivalent combination of education and experience.

Job Knowledge and Requirements
Practical and applied knowledge of specialized methods and processes that are typically acquired through a combination of technical or academic qualification and/or work experience.
Provide consultation and advice on non-straightforward and/or complex issues.
Interaction with others typically requires interpersonal skills and the ability to understand and influence.
Adapt messages to meet the needs of the intended audience.
Build relationships, trust and credibility.
Manage own work and may train and review the work of casual employees, work study students and/or volunteers, to see commitments through to completion.
Contribute to setting work priorities and direction, supporting the team in achieving goals and objectives.
Participate in project team meetings and develop individual project plans.
Lead procedural or technological change within a unit.
Identify new problems and seek information and input to fully understand the cause of problems.
Identify opportunities to improve the effectiveness and efficiency of work processes.
Draw logical conclusions and provides opinions and recommendations.
Research equity, diversity, accessibility and inclusion resources and best practices relevant to the job and unit operations in order to inform evidence-based planning.
Commitment to principles of equity, diversity, accessibility, inclusion, Indigenization and human rights for equity deserving groups.

Employment Equity and Accessibility Statement

The University invites applications from all qualified individuals. Queen's is committed to employment equity and diversity in the workplace and welcomes applications from women, visible minorities, Aboriginal Peoples, persons with disabilities, and persons of any sexual orientation or gender identity. In accordance with Canadian Immigration requirements, priority will be given to Canadian citizens and permanent residents.

The University provides support in its recruitment processes to applicants with disabilities, including accommodation that takes into account an applicant's accessibility needs. Candidates requiring accommodation during the recruitment process are asked to contact Human Resources at hradmin@queensu.ca.

Are you interested in this job?",Kingston,CA,2023-12-20 00:10:00,https://www.qmul.ac.uk,Education
12,FULLTIME,Senior Data Engineer (AI Platform),https://ca.linkedin.com/jobs/view/senior-data-engineer-ai-platform-at-koho-3784451633,"About KOHO

KOHO’s purpose is to empower Canadians to build a great financial foundation with products that are radically transparent and easy to manage. We first launched in 2017, and we have since built a community of over 1 million users . Leading investors around the globe believe in our vision, and we’ve successfully raised over $320M to make our vision a reality.

Discover our culture here and get the inside scoop from our team here !

About The Role

We’re looking for a Senior Data Engineer to join our team for a role to work remotely based in Canada.

Reporting to a Software Development Manager, you’re going to be a part of a team that is at the forefront of developing innovative AI solutions, focusing on ML Ops, ETL, AWS SageMaker, model fine-tuning, and synchronous and asynchronous data processing. You will play a crucial role in building and enhancing our internal LLM/AI platform.

What You’ll Be Doing
• You’ll be developing, training, and deploying ML models using AWS SageMaker and other cutting-edge technologies.
• You’ll be designing and developing scalable data pipelines, ensuring efficient data ingestion, transformation, and storage for ML/AI use cases, Real-Time Data Analytics and Exploratory Analytics.
• You’ll be fostering a collaborative and innovative environment within the AI team as well as partner teams across KOHO.
• You’ll be collaborating with cross-functional teams to tailor data products, ensuring data quality and alignment with business objectives.
• You’ll be contributing to the strategic direction of the AI Platform team, staying abreast of industry trends and best practices.

Who You Are
• You hold a Bachelor’s or Master’s degree in Computer Science, Engineering, or a related field, with AWS Certifications in Machine Learning or Data Analytics being a plus.
• You have at least 5 years of experience in data engineering, with a strong focus on AWS services, especially SageMaker, AWS Glue, and EMR.
• You are proficient in programming languages like Python, R, Java, SQL, and Apache Spark & are familiar with data warehousing, ETL processes, big data, and cloud computing.
• You are familiar with ML/AI frameworks and toolkits, such as TensorFlow, PyTorch, or scikit-learn.
• You possess strong analytical and problem-solving skills and can communicate effectively with both technical and non-technical stakeholders.
• You are a self-starter who can handle multiple tasks, meet tight deadlines, and thrive in an Agile environment.

At KOHO, we are dedicated to providing pay transparency to all candidates. Compensation at KOHO is determined through various factors including but not limited to: comparable salary market data within Canada, technical skill assessment, a holistic view of previous work history, and internal pay equity with other KOHO team members.

Target Base Salary Range

$190,000 — $240,000 CAD

What's In It For You?

We Invest Time And Resources Into Making Sure KOHO Is As Good As The People We Hire. Here Are Some Of The Reasons We Attract The Best People

  ♂️ Balance Your Life - Company-wide Summer wellness days, Winter holiday closure, unlimited Personal Days, a wellness spending account, and maternity & parental leave top-up

   Remote First - Work from anywhere in Canada with a budget to set up your home office

   Level Up - Access to an in-house certified performance coach and an annual training budget

   Reach Your Goals - Salary assessments twice per year

   The KOHO Culture - We have won 7 ""Great Place to Work ®"" awards since 2019

   Be an Owner - Every KOHO employee gets a generous amount of equity with a 10 year exercise window

The KOHO culture is one of collaboration, creativity, and diverse perspectives. We are committed to building and fostering an inclusive, accessible environment for everyone. If you have any questions, concerns, or requests regarding accessibility needs, please contact peopleaccessibility@koho.ca and the People and Culture team will be happy to help.",London,CA,2023-12-19 21:10:00,http://www.koho.ca,Consulting
13,FULLTIME,Data Engineer,https://ca.bebee.com/job/20231219-57fde6e9ce3f8762c77523e76f669818,"Data Engineer
Toronto, OntarioApplied Sciences – Labs /Full-Time/ Hybrid About Klick Applied Sciences Klick Applied Sciences is the innovative arm of Klick Health, specializing in digital health solutions. The team leverages cutting-edge technology and data science to create patient-centered solutions, integrate connected health devices, and advance medical research. They also explore the use of virtual reality in healthcare and support the design of digital clinical trials. As part of Klick Health, Klick Applied Sciences is committed to improving health outcomes through technology.' Job Description Work term : Permanent, Full-time Location : Toronto, ON (Hybrid)The Klick Applied Sciences team is seeking a high performing, high achieving, and passionate Data Engineer to join our growing team. As a Data Engineer, you will be an integral part of the Data Science team working alongside our Product Development team to design, build, and maintain our data lake solutions.

Your mission will be:
• Collaborating with data scientists and developers to create and execute data collection and preprocessing pipelines
• Developing and maintaining knowledge of data available from upstream sources and within various platforms
• Designing and constructing data solutions using the latest technologies to meet the needs of our team
• Working closely with team members from diverse disciplines
• Contributing to the design, development, and maintenance of our data lake solutions, in partnership with the Product Development team

What tech skills you bring:
• 2-3 years of experience in building data processing pipelines, including data scraping, data ingestion, data storage/querying on the cloud. Prior experience with Datalakes and automating data pipelines using Airflow is desirable
• Proficiency in Python scripting and Linux/Ubuntu shell scripting
• A Bachelor's or Master's degree in fields such as computer science, engineering, applied science, biomedical science, bioinformatics, data science, or related disciplines
• Competence in building API endpoints/wrappers using Python/Flask, with a bonus for experience in CI/CD
• Strong skills in SQL, noSQL databases, and cloud storage platforms like AWS/EC2, S3, RDS, and similar services
• Proficiency in using git and GitHub, including the ability to work through pull-requests
• The capability to extract, transform, and load various data types, including CSV, XML, JSON, and large datasets in compressed files.
• Experience with AWS Glue, Redshift, or Athena to design and implement data pipeline solutions
• Demonstrated expertise in leveraging big data solutions, particularly using PySpark and AWS EMR
• Bonus points for experience with front-end web development frameworks

What unique attributes you bring:
• Passion for and knowledge of biological or clinical data, with a genuine interest in the pharmaceutical industry
• A high level of proficiency, ensuring high achievement in data engineering
• Strong problem-solving and collaboration skills to work effectively with cross-functional team members
• A strong drive for innovation and a passion for applying digital healthcare technologies to improve patient experiences and outcomes
• This Data Engineer role at Klick Applied Science offers a challenging and exciting opportunity for high-performing individuals with a commitment to excellence and a passion for cutting-edge healthcare technology In summary, the Data Engineer role at Klick Applied Science offers a compelling opportunity for individuals with a passion for healthcare innovation. Your responsibilities include data collection, preprocessing, and developing data solutions, all within a collaborative team. You'll need technical skills in Python, databases, and cloud platforms, as well as soft skills like problem-solving and innovation. If you're eager to make a meaningful impact in healthcare and possess the required skills, join us at Klick Applied Science to contribute to improving patient experiences through cutting-edge technology.#LI-LP2 #LI-Hybrid",Toronto,CA,2023-12-19 14:55:00,http://www.bdo.com,Consulting
14,FULLTIME,Associate Data Analyst,https://www.climatetechlist.com/job/terramera-associate-data-analyst-0x7IHXb4RcNcSb,"Job posting details for Associate Data Analyst at Terramera in Canada, listed on ClimateTechList jobs. ClimateTechList gathers 30,000+ job openings from over 1,040 climate tech companies and updates them daily.",Vancouver,CA,2023-12-20 00:00:00,http://www.terramera.com,Consulting
15,FULLTIME,Digital Data Analyst (Entry Level) (Fair Marketing Inc),https://ca.linkedin.com/jobs/view/digital-data-analyst-entry-level-fair-marketing-inc-at-bcjobs-3788482285,"We are hiring a Data Entry Clerk to join our Team.

Responsibilities For Data Entry Clerk
• Receive and process invoices for payment and update invoice details accordingly
• Accurately enter data into corresponding fields within various software programs
• Identify and correct data entry errors using appropriate quality control methods
• Perform related tasks like ordering office supplies and filing documents
• Manage and organize records and files
• Prepare relevant reports as needed
• Provide general data entry support across many teams on an ad-hoc basis

Qualifications for Data Entry Clerk
• High school diploma or general education degree (GED) required
• Working knowledge of Microsoft Office
• Strong computer skills
• Ability to enter data into a computer quickly and accurately
• Comfortable with office equipment including a computer, telephone, scanner, calculator, and photocopier
• Strong attention to detail
• Ability to think analytically

Value",Vancouver,CA,2023-12-20 04:14:00,http://www.bdo.com,Consulting
16,FULLTIME,Manager/ Data Analytics/,https://ca.bebee.com/job/20231219-578826d6f6eb97db9092c3daea79a0c5,"Job summary
Manager of Analytics position in the Department of Education and Early Childhood Development
Responsible for strategic planning, development, and implementation of education related data
Lead a team of professionals in data governance and analytics services

Job seniority: mid-to-senior level

Responsibilities
• Lead the planning, design, development, implementation, and improvement of education related data
• Develop strategies, architecture, plans, policies, standards, and guidelines for data management
• Build and maintain a robust infrastructure to support data management and analytics needs
• Manage a team of professionals in data governance and analytics services
• Ensure alignment of technical solutions with educational objectives and evidence-based decision-making processes
• Deliver valuable insights by drawing knowledge from multiple sources
• Communicate complex technical solutions and deliver presentations to stakeholders
• Drive change initiatives and projects related to data management
• Conduct needs assessment, develop project plans, and improve processes
• Promote and expand services offered by the data analytics team
Requirements
• Post-secondary degree in a related discipline
• Minimum of 8 years of hands-on analytics experience with 3 years in a team lead or management capacity
• Knowledge and experience with analytics architecture, master data management, ETL development, and data analysis
• Proficient in using analytical tools and databases, with emphasis on Cognos, Power BI, and Oracle
• Experience in delivering data management related change initiatives and projects
• Experience in project management and service delivery in a large and complex organization
• LEADS Leadership Framework competencies in Leads Self, Engage Others, Achieve Results, Develop Coalitions, and Systems Transformation
Key Skills Needed
• Analytics
• Data management
• Strategic planning
• Technical architecture
• Leadership
• Communication
• Change management
• Project management
Benefits
• Health, Dental, Life Insurance, Pension, General Illness (Short and Long Term), Vacation, and Employee and Family Assistance Programs
• Career Development and training opportunities
• Respect and recognition in an engaged workplace
• Flexible working schedules
• Employment Equity Policy supporting diversity and inclusion

Original job Manager/ Data Analytics/ / analysis/ master data management/ and optimization of Cognos solutions/ e posted on GrabJobs .
To flag any issues with this job please use the Report Job button on GrabJobs.

#J-18808-Ljbffr",Halifax,CA,2023-12-19 17:26:00,http://novascotia.ca,Consulting
17,FULLTIME,Manager/Lead Data Engineer,https://ca.linkedin.com/jobs/view/manager-lead-data-engineer-at-badal-io-3746814297,"About Badal.io

We are a boutique, rapidly growing, GCP (Google Cloud Platform) consulting company based out of Toronto. We work with GCP’s top customers (banking, telco, energy, retail, etc.) to help them with cloud transformation, security, analytics, ML, and data governance. Clients usually engage us to solve their most challenging business problems and help raise the bar at their organization.

Why Badal?

You get the best of both worlds. We operate like an early-stage startup with all the associated benefits (e.g., talent, growth, learning opportunities, flexibility), but get to solve enterprise-level technical challenges.
• People: We hire top-tier talent. Our team consists of ex-Googlers, YCombinator Alumni, and individuals that built software for 400M users.
• GCP is the Best Cloud: Maybe we are biased, but GCP is the most cutting-edge cloud provider, building on technologies that have been pioneered by Google: BigQuery, K8s/Anthos, Vertex AI, etc.
• Growth: We have doubled in size in the last 6 months, and are looking to double again this year.

You will
• Manage a team who works closely with backend engineers, product managers, and analysts
• Provide leadership and contribute to the definition, development, integration, test, documentation, and support across multiple platforms
• Serve as a process expert and provide architectural leadership to Jr engineers as needed
• Work closely with technical leads and client teams to fully demonstrate the benefits of GCP technology
• Introduce clients to data architecture and analytics best practices
• Solve some of the most challenging, high-scale data, and IoT problems (banking, telco, energy, retail, etc.).
• Write high-quality and testable batch and real-time data pipelines
• Work with Data Scientists to design pipelines that improve their productivity and enable them to implement their ideas
• Support clients in troubleshooting issues in their test and/or production environments and identifying root causes and solutions

You have
• Mentoring and helping the team build technical capability
• Ability to effectively communicate data insights and negotiate options at senior management levels
• Experience in leading significant project steps and communicating progress/approach with technical/non-technical peers/clients and leaders
• GCP experience ( for junior candidates, or exceptional talent with other cloud experience, we will provide training programs)
• Experience in large-scale, secure, and high-availability solutions in a Cloud environment, such as GCP.
• Experience with one Dataflow or Spark
• Experience with orchestration frameworks such as Airflow, Kubeflow, Azkaban, etc.
• Extensive programming experience in Python, Java and/or Scala.
• Good understanding of modern data architecture
• Good understanding of GCP services such as IAM, and Google Cloud Storage buckets
• Experience with business intelligence tools like QuickSight, Looker and Data Studio
• Technical writing experience; preparing and presenting technical material to a variety of audiences.
• Experience in working in or with, Agile delivery teams.

Nice to have
• Streaming experience with Dataflow, Spark, Flink, Kafka Streams, etc
• Strong understanding of Data Governance principles and experience working with tools such as Collibra or Immuta

Type of qualities we look for (across all roles)
• Passionate about delivering high-quality commercial software products and platforms to market
• Team player. We are a small team and enjoy working with each other and our clients - we would like to keep it the same way as we grow.
• Strong understanding of modern software engineering processes
• Client-focused and passionate about delivering strong business values.
• Able to communicate clearly and effectively with various audiences, including developers, clients, customers, partners, and executives.
• Flexible and willing to use the right technology for each problem in the context of timelines and business goals
• Ability to complete the job regardless of the circumstance.

Our Benefits
• Flexible vacation policy.
• Three weeks of vacation, plus we are closed over the winter holidays (+ ~1 week)
• One team-building event each quarter.
• Great health benefits with a $1500-$3000 HSA/WSA.
• Certification opportunities. We will pay for your GCP certification as well as other relevant training and certifications.
• Learning opportunities. We work across different industries, technologies and roles and will work with you to help you explore your interests.
• Blogging, open source, meetups and conference opportunities. We will provide a platform and time for you to pursue your ideas.
• Our organization values action over politics, and our management team is made up of engineers who thrive on achieving tangible results.

Badal is an equal-opportunity employer committed to creating a safe, diverse and inclusive environment. We encourage qualified applicants of all backgrounds including ethnicity, religion, disability status, gender identity, sexual orientation, family status, age, nationality, and education levels to apply. If you are contacted for an interview and require accommodation during the interviewing process, please let us know.",Toronto,CA,2023-12-19 19:06:00,http://www.bdo.com,Consulting
18,FULLTIME,"Manager, Data and Business Analytics (management experience required)",https://ca.linkedin.com/jobs/view/manager-data-and-business-analytics-management-experience-required-at-toronto-metropolitan-university-3784452071,"About Toronto Metropolitan

At the intersection of mind and action, Toronto Metropolitan University (TMU) is on a transformative path to become Canada’s leading comprehensive innovation university. Integral to this path is the placement of equity, diversity and inclusion as fundamental to our institutional culture. Our current academic plan outlines each as core values and we work to embed them in all that we do.

TMU welcomes those who have demonstrated a commitment to upholding the values of equity, diversity, and inclusion and will assist us in realizing the benefits of embedding these values into the work at every level and in every unit of the university. In addition, to correct the conditions of disadvantage in employment in Canada and to bring lived experiences to the work, we encourage applications from members of equity deserving groups that have been historically disadvantaged and marginalized, including First Nations, Métis and Inuit Peoples in Canada, First Nations Peoples in the United States, racialized people, Black people, persons with disabilities, women, and 2SLGBTQ+ people. Preference will be given to candidates with lived experiences as people from equity deserving groups, as well as experience working with these communities with which the University works every day. Please note that all qualified candidates are encouraged to apply and we welcome newcomers and immigrants to Canada.

In April 2022, the university announced its new name of Toronto Metropolitan University. Learn more about our next chapter.

The Chang School

The G. Raymond Chang School of Continuing Education is Canada’s foremost provider of university-based adult education, facilitating access to the University’s renowned, professionally relevant courses and programs. Since 1975, we have been delivering leading-edge workplace knowledge that empowers learners to reach their personal and professional goals. We have approximately 70,000 annual enrolments (in 1,500 courses, seminars, and workshops) in Arts; Business; Communication and Design; Community Services; Engineering, Architecture, and Science; Gateway for International Professionals; Programs for 50+; and Spanning the Gaps – Access to Post-Secondary Education. We also offer 86 career-related certificate programs and numerous course series, with 39 certificate programs that can be completed entirely at a distance. Our flexible, accessible programming is available on campus, via distance education, and off-site for employee groups at leading organizations.

Interested in joining a collaborative and inclusive community dedicated to making a real impact on Canada's workforce? The Chang School is more than just a continuing education unit. We're deeply committed to leveraging data to guide our programming and operations. Our goal is to make informed decisions that help continuous learners develop their capacity to respond to current and future workforce needs. We’re looking for someone to work closely with The Chang School’s many talented teams to play a key role in helping us move forward on this mandate.

At The Chang School, data informs all of our decision making. Your expertise in business analytics, passion for using data to improve the student experience, and creativity in introducing new sources of data to help us provide the most relevant offerings to our learners would be an invaluable asset to our multidisciplinary team. Business analytics and data play an essential role in helping us accelerate and implement this mission. Your ability to partner with and become a trusted advisor to colleagues from across The Chang School and your devotion to leading a business analytics team would make you a great fit. Does this sound like you? If so, we’d love to meet you!

The successful candidate will work in a hybrid work environment (combining in-person/on-campus and remote work).

The Opportunity

The Manager, Data and Business Analytics is a Solutions Facilitator, a Relationship Builder, and Problem-Solver. The successful candidate will leverage their expertise in Data & Business Analytics to develop, promote, and advocate for the most effective ways to obtain, extract, analyze and utilize data in meaningful ways to drive decision-making at The Chang School in an effort to continuously evolve and improve data usage strategy and ensure plans reflect up to date and emerging standards.

This role manages the school’s Data & Business Analytics team, made up of a small group of dedicated technical professionals, and which is part of the larger Technology Solutions team. This role is a connector and a trusted advisor that can effectively facilitate change, get buy-in for new ideas/methodologies, and work closely with diverse groups to come to fit-for-purpose solutions.

The Successful Candidate Will
• Work with Chang School leaders to prioritize business and information needs and advise on the best utilization of tools and technologies as it relates to data analysis.
• Work closely and collaboratively with a variety of units within The Chang School in order to facilitate data analysis solutions and champions data use, data management best practices, and the improvement of The Chang School's data ecosystem.
• Develop and Improve on the use of data tools, data collection, data analytics, data warehousing and sources, reports and other strategies that unify existing data systems to optimize efficiency and quality for The Chang School.
• Oversee the compilation and analysis and present key data on a multitude of situations for management decision making and strategic planning.
• Ensure that the information presented is relevant, properly processed, in a consistent and timely manner.
• Lead, develop, and grow the Data & Business Analytics team ensuring they have the support, guidance, and resources needed to do great work and can collaborate closely with the Chang School’s IT Operations and Applications teams as well as TMU’s Central IT teams and other partners in delivering technical solutions.

Qualifications

Specific training or job experience required before appointment includes:
• Post-secondary degree in Computer Science, Information & Data Management, Data Science, or related fields with demonstrated IT knowledge and its linkage to business decision making.
• Minimum Five (5) years of progressive and demonstrated work experience in the following areas:
• People management experience in the capacity of a team/department/project leader of a group of technical analysts, engineers, professionals on moderately complex projects. Strong supervisory experience, demonstrated capacity to inspire the trust and engagement of staff.
• Managing, maintaining, and troubleshooting Business Analytics, Data, and Reporting platforms/systems. For example, experience with the Microsoft stack for databases, SSIS, SSAS, SSRS, etc. would be ideal; equivalent experience in similar stacks will be considered. Experience with Tableau or comparable platforms with transferable experience such as PowerBI, Qlik Sense, Looker, etc. Working knowledge of DAX and/or MDX would be nice-to-have.
• Effective utilization of Analytics tools, data storage, manipulation and visualization, user support and training.
• Designing complex Enterprise-level Reports and Dashboards.
• Gathering, analyzing, and documenting user requirements.
• Creating and contributing meaningfully to technical and business requirements and documentation needed for both technical and business-driven projects/initiatives.
• Developing well-structured and clear technical communications, presentations, and reference artifacts that are audience-appropriate where audiences range from business-centric groups to technical groups (e.g. analysis/comparisons of different approaches, tools, methodology; introduction/advocating for new data sources/tools; continuous improvement roadmaps; data architecture diagrams; data dictionaries)

Demonstrated Experience In
• Leading technical implementation/upgrade projects from the initial stages through to implementation, documentation, and end-user training.
• Leading large/medium sized successful systems deployment/roll-outs including requirement gathering, technical feasibility, cost analysis, scheduling, stakeholder consultations and communications.
• Participating in planning and running of large/medium sized business analytics and reporting environments.
• Architecting and optimizing complex data integrations/ETL and other data processes.
• Advising/implementing processes/tools to streamline support and improve overall end users’ experience.
• Implementing best practices in data management and governance.
• Vendor/Supplier management (licensing, escalations, etc).

The Successful Candidate Will Also Have The Following Skills
• Strong understanding and ability to contextualize how the Data and Analytics unit fits within the larger technical landscape, business environment, user experience, etc.
• Superb oral and written Communication skills (clear, tactful, diplomatic, accurate); Ability to communicate clearly and effectively both orally and in written form with both technical and non-technical audiences at all levels of the organization
• Proficient Interpersonal, negotiation, and customer services skills
• Lead team-based projects, prepare and present customized reports to the intended target audience which may include a variety of stakeholders (ex. Senior management, staff, end-users, etc)
• Creative with exceptional analytical and problem-solving skills; Excellent attention to detail (both technical and functional); Strong technical and business problem-solving skills and a willingness to dive into software environments and technical issues
• Effective project management and change management skills: budget and timeline management, priority/scope management, risk & issues management, timely decision making, deal with changing priorities and multiple projects simultaneously
• Eagerness and ability to continually update technical skills and keep current on new toolsets and ways of doing things is important. A learning mindset that welcomes opportunities for improvement.
• Attention to detail, ability to absorb information quickly and disseminate information in an effective manner;
• Expert knowledge of a variety of office applications such as MS Office suite, Google suite, etc.
• Demonstrated technical skills and technology proficiencies with the following technologies:
• Statistical/Analytics/Reporting Platforms/Toolsets (e.g. Tableau SQL Server Reporting Services, PowerBI, etc.)
• Relational Database Technologies and Tools (including SQL Server Databases, SSIS, ETL Processes, etc.)
• Common Modern Operating Systems (Windows Server, etc)
• Collaboration and Productivity tools/platforms
• Knowledge of post-secondary education systems and issues or related sectors (public sector, etc) is an asset

The Perks

There is something for everyone! Employees are eligible for many benefits, services and discounts that TMU has to offer:
• Mid-year break that provides two weeks of paid time off in addition to your vacation.
• Group benefits including health and dental, employee and family assistance program (EFAP) and more!
• Tuition waiver for eligible employees and their spouse and/or dependent(s) and Tuition Rebate for eligible employees.
• TMU Retirement Pension Plan (RRPP): A defined benefit pension plan.
• Access to the TMU medical centre directly on campus.
• And many more!

#dataanalytics #businessanalytics

Additional Information

Position Number(s) 20003643Reports ToAssistant Dean, Business OperatonsDepartmentChang SchoolVacancy TypeFTCEEmployee GroupMACWork LocationHybrid (In-person/on-campus & remote)Start DateASAPEnd DateNAHours of Work 36.25Grade C52Salary ScaleMin:$83,758 Job Rate: $108,777 Max: $133796Hiring Salary Range$115,000 up to maximum of $125,000

As part of the selection process, candidates may be required to complete an occupational assessment. Applications will only be accepted online through Toronto Metropolitan University's career site.

Toronto Metropolitan University is committed to the principles of the Accessibility for Ontarians with Disabilities Act (AODA), and aims to ensure that independence, dignity, integration and equality of opportunity are embedded in all aspects of the university culture.

We will provide an accessible experience for applicants, students, employees, and members of the Toronto Metropolitan University community. We are committed to providing an inclusive and barrier-free work environment, beginning with the recruitment process. If you have restrictions that need to be accommodated to fully participate in any phase of the recruitment process, please contact hr@torontomu.ca. All information received in relation to accommodation will be kept confidential.",Toronto,CA,2023-12-19 20:30:00,https://www.torontomu.ca,Education
19,CONTRACTOR,"Data Scientist, Model Risk (12 Month Contract)",https://ca.linkedin.com/jobs/view/data-scientist-model-risk-12-month-contract-at-sagen-3790405204,"Job Summary

Reporting to the Director of Model Risk Governance, the Data Scientist, Model Risk is responsible for technical validation of predictive models developed by model developers as well as promoting the transparency and understanding of models used across the business to ensure the company is not subject to unjustified and unidentified risks due to the use of models.

Responsibilities
• The incumbent will closely collaborate with model owners and stakeholders across Finance, Risk, Operations and IT teams on model validation.
• Thorough technical validation of code and documentation of ETL and data pipelines, predictive models and its deployment.
• Provide validation findings and recommendation to the modelers.
• Develop a champion-challenger ML/Bayesian/DL/AI model as needed by the business.
• Support the Director, Model Risk Governance in documenting technical findings for presentation to validation groups and Company’s executive team.
• Oversee and ensure an end-to-end ML/Bayesian/DL/AI model lifecycle is built in accordance to company’s model risk management framework and industry best practices.
• Assist pipeline automation and other risk analytics efforts.

Skills And Qualifications
• Advanced degree in highly quantitative field (Applied Statistics, Applied Mathematics, Applied Physics, Computer Science, Operational Research, Applied Finance, Econometrics, Actuarial, Engineering, etc).
• Minimum 1 year of work experience in ML/Bayesian/DL/AI model development and deployment. Experience in model risk, quantification and validation is required.
• Strong programming fundamentals and advanced knowledge in Python, Pandas, R, PySpark, SQL and similar tools.
• Solid understanding of various ML/Bayesian/DL/AI algorithms and libraries, e.g. Scikit-learn, Spark MlLib, TensorFlow, Keras, PyTorch, RL etc.
• Experience with data visualization tool, particularly Tableau.
• Experience with AWS cloud services.
• Experience with containerization and orchestration tools, particularly Dockers and Kubernetes.
• Experience working with advanced Git Workflows (pull requests, code reviews, issues, and branching), Jira, and Confluence.
• Familiarity with any microservices such as Flask, Plumber, React, NodeJS, etc..
• Familiarity with Unix environment and scripting.
• Strong written and verbal communication skills enabling the translation of technical results into non-technical explanations.
• Fast-learner, proactive, results-oriented, strong problem-solving attitude, and a team player.

At Sagen, we offer:
• Competitive salary
• Annual Performance Bonus Plan
• Medical, Dental, Prescription Drug, and EFAP Benefits
• Company funded Pension Plan
• Company matching RRSP, TFSA and/or Non-registered Savings Plan
• Competitive vacation policy
• Life Insurance and Accidental Death & Dismemberment
• Short Term and Long-Term Disability programs
• Reimbursement programs for special occasions, health and wellness, mortgage insurance and tuition
• Work from Anywhere Days

S agen is committed to creating a diverse and inclusive workforce. We welcome, respect and value people from all backgrounds and abilities and create a sense of belonging that inspires our employees to be their authentic self.

We encourage applications from people with disabilities and will provide accommodations upon request throughout the selection and hiring process to meet individual needs.

Apply Now",Oakville,CA,2023-12-19 22:53:00,http://www.bdo.com,Consulting
20,CONTRACTOR,Data Engineer,https://ca.linkedin.com/jobs/view/data-engineer-at-affinity-3772187234,"Job Description:

On behalf of our client, Affinity is looking for Data Engineers for approved corporate projects to work with data architects and other team members to ensure understanding of requirements and mapping documents and develop extract(s)/report(s) per requirements.

Deliverables:
• Ensuring clear understanding of requirements.
• Code build as per requirements and mapping documents.
• Functional and regression testing.
• Data analysis and validation as per mapping documents.
• Production deployment and verification.

Qualifications:
• Applied knowledge in Big Data platforms, ideally with exposure to Hadoop ecosystem (HDFS, Hive, SPARK, NoSQL, YARN)
• Experience developing complex SQL queries
• Good programming skill in Scala
• Knowledge of data validations and DataOps (Jenkins, SVN/Git)
• Knowledge in enterprise systems

Hourly Rate: $80-$100 per hour.

Affinity Earn:

Know someone who’s great for this, or any of our open roles? Earn up to $4,000/year for each successful referral through Affinity Earn. You can also earn up to $50,000 for helping us find new clients. Learn about our referral program at https://affinity-group.ca/earn/ or browse our jobs & follow us at https://www.linkedin.com/company/affinity-staffing/jobs/

About Affinity:

Affinity Group is a full-service Information Technology services and staffing company. We believe recruiting is about creating long term relationships that foster a mutually beneficial partnership - an affinity. Bringing a new style of recruiting founded on five core principles: Transparency – Flexibility – Efficiency – Agility – Inclusivity.

We teamed up with ClimatePartner on 2022 to offset our emissions and move toward being a more environmentally friendly company and we are proud to now be officially Carbon Neutral Certified.

For more information on Affinity, please visit www.affinity-group.ca

Job Number: 9464",North Vancouver,CA,2023-12-19 12:58:00,http://www.bdo.com,Consulting
21,FULLTIME,Senior Data Engineer,https://ca.linkedin.com/jobs/view/senior-data-engineer-at-synechron-3783157457,"Responsibilities:
• Strong understanding or Snowflake on Azure Architecture, design, implementation and operationalization of large-scale data and analytics solutions on Snowflake Cloud Data Warehouse.
• Hands-on development experience with Snowflake features such as Snow SQL; Snow Pipe; Python; Tasks; Streams; Time travel; Zero Copy Cloning; Optimizer; Metadata Manager; data sharing; and stored procedures.
• Experience in Data warehousing - OLTP, OLAP, Dimensions, Facts, and Data modeling.
• Need to have working knowledge of MS Azure configuration items with respect to Snowflake.
• Developing EL pipelines in and out of data warehouse using combination of Data bricks, Python and Snow SQL.
• Developing scripts UNIX, Python etc. to Extract, Load and Transform data, as well as other utility functions.
• Provide production support for Data Warehouse issues such data load problems, transformation translation problems

Requirements:
• You are:
• Minimum 7 years of designing and implementing an operational production grade large-scale data solution on Microsoft Azure Snowflake Data Warehouse.
• Including hands on experience with productionized data ingestion and processing pipelines using Python, Data bricks, Snow SQL
• Excellent understanding of Snowflake Internals and integration of Snowflake with other data processing and reporting technologies

It would be great if you also had:
• Detail-oriented, ability to turn deliverables around quickly with a high degree of accuracy
• Strong analytical skills, ability to interpret business requirements and produce functional and technical design documents
• Good time management skills – Ability to prioritize and multi-task, handling multiple efforts at once
• Strong desire to understand and learn domain.
• Experience in a financial services/banking industry
• Ability to work in a fast paced environment; to be flexible and learn quickly.
• Ability to multi-task with attention to detail/ prioritize tasks.

We can offer you:
• A highly competitive compensation and benefits package
• A multinational organization with 44 offices in 19 countries and the possibility to work abroad
• 15 days of paid annual leave (plus national holidays)
• Maternity & Paternity leave plans
• A comprehensive insurance plan including: medical, dental, vision, life insurance, and long-/short-term disability
• RRSP with employer’s contribution
• A higher education certification policy
• Comprehensive Relocation Expense Coverage
• Extensive training opportunities, focused on skills, substantive knowledge, and personal development
• On-demand Udemy for Business for all Synechron employees with free access to more than 5000 curated courses
• Coaching opportunities with experienced colleagues from our Financial Innovation Labs (FinLabs) and Center of Excellences (CoE) groups
• Cutting edge projects at the world’s leading tier-one banks, financial institutions and insurance firms
• A flat and approachable organization
• An excellent working atmosphere: regular drinks, sports activities, offsite weekends with a young, dynamic team
• A truly diverse, fun-loving and global work culture

SYNECHRON’S DIVERSITY & INCLUSION STATEMENT

Diversity & Inclusion are fundamental to our culture, and Synechron is proud to be an equal opportunity workplace and is an affirmative action employer. Our Diversity, Equity, and Inclusion (DEI) initiative ‘Same Difference’ is committed to fostering an inclusive culture – promoting equality, diversity and an environment that is respectful to all. We strongly believe that a diverse workforce helps build stronger, successful businesses as a global company. We encourage applicants from across diverse backgrounds, race, ethnicities, religion, age, marital status, gender, sexual orientations, or disabilities to apply. We empower our global workforce by offering flexible workplace arrangements, mentoring, internal mobility, learning and development programs, and more.

All employment decisions at Synechron are based on business needs, job requirements and individual qualifications, without regard to the applicant’s gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law.

Le rôle : Développeur Intégrateur Snowflake

Responsabilités :
• Solide compréhension de Snowflake sur Azure. Architecture, conception, mise en œuvre et opérationnalisation de solutions de données et d'analyse à grande échelle sur Snowflake Cloud Data Warehouse.
• Expérience pratique du développement avec les fonctionnalités de Snowflake telles que Snow SQL, Snow Pipe, Python, Tâches, Flux, Time Travel, Clonage Zero Copy, Optimiseur, Gestionnaire de métadonnées, partage de données et procédures stockées.
• Expérience en entreposage de données - OLTP, OLAP, Dimensions, Faits et modélisation des données.
• Il est nécessaire d'avoir une connaissance pratique des éléments de configuration de MS Azure par rapport à Snowflake.
• Développement de pipelines EL entrants et sortants de l'entrepôt de données en utilisant une combinaison de Data bricks, Python et Snow SQL.
• Développement de scripts UNIX, Python, etc. pour extraire, charger et transformer les données, ainsi que d'autres fonctions utilitaires.
• Fournir un support de production pour les problèmes d'entrepôt de données tels que les problèmes de chargement de données, les problèmes de traduction de transformation.
• Comprendre les pipelines de données et les moyens modernes d'automatiser les pipelines de données à l'aide de tests basés sur le cloud et documenter clairement les mises en œuvre, de manière à ce que d'autres puissent facilement comprendre les exigences, la mise en œuvre et les conditions de test.

Exigences :

Vous êtes :
• Au minimum 7 ans d'expérience dans la conception et la mise en œuvre d'une solution de données à grande échelle en production opérationnelle sur Microsoft Azure Snowflake Data Warehouse.
• Expérience pratique de l'ingestion et du traitement de données en production à l'aide de Python, Data bricks, Snow SQL.
• Excellentes compétences en présentation et en communication, à la fois écrites et verbales, capacité à résoudre des problèmes et à concevoir dans un environnement aux exigences peu claires.

Ce serait génial si vous aviez également :
• Souci du détail, capacité à produire rapidement des livrables avec un haut degré de précision.
• Solides compétences analytiques, capacité à interpréter les besoins commerciaux et à produire des documents de conception fonctionnelle et technique.
• Bonnes compétences en gestion du temps - Capacité à hiérarchiser et à effectuer plusieurs tâches en même temps.
• Fort désir de comprendre et d'apprendre le domaine.
• Expérience dans le secteur des services financiers/bancaires.

Nous pouvons vous offrir :
• Un package de rémunération et d'avantages sociaux très compétitif.
• Une organisation multinationale avec 44 bureaux dans 19 pays et la possibilité de travailler à l'étranger.
• 15 jours de congé annuel payé (plus les jours fériés nationaux).
• Plans de congé de maternité et de paternité.
• Un plan d'assurance complet comprenant : assurance maladie, dentaire, vision, assurance vie, invalidité à long terme/court terme.
• REER avec contribution de l'employeur.
• Une politique de certification de l'enseignement supérieur.
• Une couverture complète des frais de déménagement.
• De nombreuses opportunités de formation axées sur les compétences, les connaissances substantielles et le développement personnel.
• Udemy à la demande pour les entreprises pour tous les employés de Synechron, avec un accès gratuit à plus de 5000 cours sélectionnés.
• Possibilités de coaching avec des collègues expérimentés de nos laboratoires d'innovation financière (FinLabs) et de nos groupes de centres d'excellence (CoE).
• Projets de pointe auprès des principales banques de niveau un, des institutions financières et des compagnies d'assurance au monde.
• Une organisation accessible et conviviale.
• Une excellente ambiance de travail : apéritifs réguliers, activités sportives, week-ends hors site avec une équipe jeune et dynamique.
• Une culture de travail vraiment diversifiée, amusante et mondiale.

DÉCLARATION DE DIVERSITÉ ET D'INCLUSION DE SYNECHRON

La diversité et l'inclusion sont fondamentales pour notre culture, et Synechron est fier d'être un lieu de travail égalitaire et un employeur pratiquant l'action positive. Notre initiative de diversité, d'équité et d'inclusion (DEI) «‘Same Difference’» s'engage à favoriser une culture inclusive - promouvoir l'égalité, la diversité et un environnement respectueux envers tous. Nous croyons fermement qu'une main-d'œuvre diversifiée contribue à renforcer les entreprises avec succès en tant qu'entreprise mondiale. Nous encourageons les candidats de divers horizons, qu'il s'agisse de race, d'origine ethnique, de religion, d'âge, de statut matrimonial, de genre, d'orientation sexuelle ou de handicap, à postuler. Nous autonomisons notre main-d'œuvre mondiale en proposant des arrangements de travail flexibles, du mentorat, une mobilité interne, des programmes d'apprentissage et de développement, et bien plus encore.

Toutes les décisions d'emploi chez Synechron sont basées sur les besoins de l'entreprise, les exigences du poste et les qualifications individuelles, sans tenir compte du genre, de l'identité de genre, de l'orientation sexuelle, de la race, de l'origine ethnique, du handicap ou du statut de vétéran du candidat, ou de toute autre caractéristique protégée par la loi.",Montréal,CA,2023-12-19 13:02:00,http://www.synechron.com,Computer Services
22,FULLTIME,"Data Analyst (Bangkok Based, relocation provided)",https://ca.linkedin.com/jobs/view/data-analyst-bangkok-based-relocation-provided-at-agoda-3750112612,"About Agoda

Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 3.6 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world.

Get to Know our Team:

The Performance Marketing Team of Agoda is a world leader in online marketing. This department is highly data-driven and focused on developing at-scale marketing programs that improve the lifetime value of Agoda customers through measurable marketing programs and channels. The team is a blend of the best analysts, marketing strategists, and data scientists in the world. The marketing leadership at Agoda have deep experience in data science, product, strategy, and other marketing fields and have built an organization that thrives on data, creative ideas, and technology. The Performance Marketing Team also fosters a great learning environment. You will be able to learn and grow by working closely with experts from a variety of backgrounds from all over the world.

In this Role, you’ll get to:
• Search: Experiment with text ads, bidding, and campaign structures on Google, Bing, Baidu, Naver, and other search engines. Adapt to new product features and roll out changes from successful tests
• Display: Test, analyze, and optimize campaigns on Facebook, Twitter, Instagram, and others
• Modeling: Analyze the vast amounts of data generated by experiments, develop models we can use for optimization, and build dashboards for account managers

What you’ll Need to Succeed:
• Bachelor’s Degree or higher from top university in a quantitative subject (computer science, mathematics, engineering, statistics or science)
• Ability to communicate fluently in English
• Exposure to one or more data analysis packages or databases, e.g., SAS, R, SPSS, Python, VBA, SQL, Tableau
• Good numerical reasoning skills
• Proficiency in Excel
• Intellectual curiosity and analytical skills

It’s Great if you Have:
• Experience in digital marketing
• Academic research experience

#STRA#ANLS#MRKT#3 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #baku #minsk #brussels #antwerp #ghent #charleroi #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics microsoft power bi java finance shopee traveloka google facebook ctrip trip.com makemytrip grab amazon pandas (software) artificial intelligence (ai) information technology capital one accenture upwork deloitte mckinsey bain microsoft uber lyft gojek lazada alibaba shopify expedia skyscanner

Equal Opportunity Employer

At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.

We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy .

To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.",Toronto,CA,2023-12-19 11:42:00,http://www.agoda.com,Consulting
23,FULLTIME,Sr Data Engineer,https://ca.linkedin.com/jobs/view/sr-data-engineer-at-teema-3781199444,"Are you a Data Engineering professional that can work independently? Are you skilled with AWS and enjoy working at high-growth startups?

If yes, read on. My client, a leader in the SportsTech industry in Canada is scaling rapidly and looking for Senior Data Engineers. They are building a cloud-based platform and DW SAAS solutions for clients in Sports and Entertainment. Seeking seasoned Data Engineers with deep AWS expertise and who can hit the ground running.

This is a permanent role and can be remote anywhere in Canada.

What you'll do:
• Take ownership of building and optimising products and features
• Build and test data pipelines, work on data migration
• Design large, complex data solutions to meet business needs
• Create relevant documentation, conduct code reviews

You will need:
• At least 5-8 years of experience as a Senior Data Engineer - preferably with a start up or product company
• At least 3 plus years of experience with AWS and related services
• Well-versed with ETL, databases and Python scripting
• Ability to hit the ground running in a fast paced environment

Apply today to get the conversation started!",London,CA,2023-12-19 21:39:00,http://www.teemagroup.com,Consulting
24,FULLTIME,Quality Data Analyst,https://ca.linkedin.com/jobs/view/quality-data-analyst-at-johnson-controls-3718998868,"Overview

The Quality Analyst is responsible for direct examination of quality data to determine trends and

gaps in processes and procedures across multiple company departments. This role is responsible for internal and supplier root cause investigations and performance data and will monitor QA systems and advise and present to executive team on company quality performance and KPIs and set goals.

Roles & Responsibilities
• Perform internal QA audits that are compliant with corporate policies, practices, and procedures.
• Assist with the maintenance of QA monitoring programs, including audits and controls.
• Promote and advocate quality achievement and performance improvement across the organization.
• Audit compliance with local, national, and international standards and legislation.
• Utilize field data to create and present historical data and trending data to Executives and customers.
• Lead Root Cause investigations.
• Analyze and present quality data.
• Create and maintain QA/QC documentation.
• Performs all duties in accordance with Silent-Aire Limited Partnership safety program standards and Alberta Occupational Health and Safety Act, Regulations, and Code.
• Other duties as required.

Knowledge, Skills, & Abilities
• Minimum 3 years of direct work experience with QA systems, regulations, guidelines, and associated standards.
• Post-Secondary Education in an appropriate field or a combination of education and experience is preferred.
• Knowledge of QA cause and effect methodologies.
• Experience in HVAC industry an asset.
• Technical experience in electrical and controls an asset.
• Training and/or experience of Six Sigma techniques and Lean Manufacturing are desirable.
• Highly motivated and self-directed, capable of multi-tasking, and able to work with minimal supervision.
• Extremely detail-oriented and analytical thinker.
• Able to interface directly with cross-functional teams.
• Strong problem identification and resolution skills.
• High level of proficiency with Microsoft Office, particularly Excel.
• Strong work ethic and positive team attitude.
• Clear and concise communication ability.

Working Conditions
• Office environment.
• Manual dexterity required to use desktop computer and peripherals.
• Occasional shop environment, requiring adherence to safety policies and exercise of caution, as the environment presents many naturally occurring hazards.
• Ability to wok and communicate with prudence, while effectively managing time, completing tasks, and working safely.

Contacts
• Communication is primarily internal to the assigned work team, Quality Supervisor, ad Quality Manager.",Edmonton,CA,2023-12-19 15:37:00,http://www.johnsoncontrols.com,Consulting
25,FULLTIME,Software Engineer - Big Data Engineer,https://ca.linkedin.com/jobs/view/software-engineer-big-data-engineer-at-capgemini-engineering-3725175275,"Life at Capgemini

Capgemini supports all aspects of your well-being throughout the changing stages of your life and career. For eligible employees, we offer:
• Flexible work
• Healthcare including dental, vision, mental health, and well-being programs
• Financial well-being programs such as 401(k) and Employee Share Ownership Plan
• Paid time off and paid holidays
• Paid parental leave
• Parenthood benefits like adoption assistance, surrogacy, and cryopreservation
• Social well-being benefits like subsidized back-up child/elder care and tutoring
• Mentoring, coaching and learning programs
• Employee Resource Groups
• Disaster Relief

About Capgemini Engineering

World leader in engineering and R&D services, Capgemini Engineering combines its broad industry knowledge and ground breaking technologies in digital and software to support the convergence of the physical and digital worlds. Coupled with the capabilities of the rest of the Group, it helps clients to accelerate towards Intelligent Industry. Capgemini Engineering has more than 55,000 engineer and scientist team members in over 30 countries across sectors including Aeronautics, Space, Defense, Naval, Automotive, Rail, Infrastructure & Transportation, Energy, Utilities & Chemicals, Life Sciences, Communications, Semiconductor & Electronics, Industrial & Consumer, Software & Internet.

Capgemini Engineering is an important part of the Capgemini Group, a global leader in partnering with companies to transform their business by harnessing the power of technology. The Group is guided every day by its purpose of optimising human energy through technology for an inclusive and sustainable future. It is a responsible and diverse organization of over 360,000 team members in more than 50 countries. With its strong 55-year heritage and deep industry expertise, Capgemini is trusted by its clients to address the entire breadth of their business needs, from strategy and design to operations, motivated by the fast evolving and innovative world of cloud, data, AI, connectivity, software, digital engineering and platforms. The Group reported in 2022 global revenues of €22 billion.

Get the Future You Want | www.capgemini.com

Disclaimer

Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.

This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.

Capgemini is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to your recruiting contact.

Click the following link for more information on your rights as an Applicant http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law

Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.

Please be aware that Capgemini may capture your image (video or screenshot) during the interview process and that image may be used for verification, including during the hiring and onboarding process.

Job Description

Name of the position: Big Data Engineer (Python, Spark SQL & AWS)

Reports to: Team Lead/Delivery Manager

Department/Project: Engineering

PURPOSE OF THE JOB
• Performs research, design, implementation and support tasks as a member of Capgemini team. Works in accordance with project guidelines, quality standards and code conventions.
• Responsible for area/areas within the team area of responsibility (AOR). One of the current team AOR is implement high-performance graph storage solution, integrate listeners into systems like Hadoop, Spark, and internal tools to produce graph nodes and vertices and help build visualizations and traversals of the graphs.
• Investigate, build, and implement the solutions for existing technical challenges, including building/improving the frameworks and tools used by other development teams.

Main Tasks And Responsibilities
• Acquires tasks from the project lead or Team Lead (TL), prepares functional and design specifications, approves them with all partners.
• Ensures that assigned area/areas are delivered with required quality objectives.
• Provides estimations, agrees task duration with the manager and gives to project plan of assigned area.
• Analyzes scope of alternative solutions and makes decision about area implementation based on their experience and technical expertise.
• Leads functional and architectural design of assigned areas. Makes sure design decisions on the project meet architectural and design requirements.
• Addresses area-level risks, provides and implements mitigation plan.
• Reports about area readiness/quality, and raises red flags in crisis situations which are beyond their AOR.
• Responsible for resolving crisis situations within their AOR.
• Initiates and conducts code reviews, builds code standards, conventions and guidelines.
• Suggests technical and functional improvements to make valuable contributions to the product;
• Constantly improves their professional level.
• Collaborates with other teams.
• If required, make yourselves available for the visits to the client location.

Required Education And Experience

Must have:
• University degree in Computer Related Sciences or similar
• 5+ years of solid commercial Python (Preferred) or Java coding experience
• 2+ years' experience in one or more open-source Data technologies (Hadoop, Spark/SQL, HiveSQL, Presto, Kafka)
• Experience with Data workflow orchestration engines for ETL jobs, such as Airflow
• High code quality, automated testing, and other engineering standard processes
• Strong OOP skills
• Effective communication, collaboration, and social skills
• Good English (oral & written)

Would be a plus:
• Experience with AWS",London,CA,2023-12-19 12:24:00,http://www.altran.com,Computer Services
26,CONTRACTOR,Machine Learning Analyst,https://ca.linkedin.com/jobs/view/machine-learning-analyst-at-leveragetek-it-solutions-3790321045,"LeverageTek is actively seeking an AI/ML Analyst for a 12-month contract with its Ottawa-based customer.

Work Location

The successful candidate will be required to work on-site at the customer headquarters in Ottawa, ON, on a hybrid basis.

Key Tasks

Model Support and Analysis:
• Assist in the development and refinement of machine learning models under supervision
• Participate in analyzing model results and suggest improvements
• Data Preparation and Management: Assist in data collection, cleaning, and preprocessing for analysis
• Help ensure data quality and integrity

Learning and Growth:
• Continuously learn and stay updated with AI and ML technologies and trends
• Engage in internal training and development opportunities

Team Collaboration:
• Collaborate with team members on AI/ML projects
• Effectively communicate findings and suggestions to both technical and non-technical colleagues

Quality Assurance:
• Assist in the testing and validation of AI/ML models
• Help identify and resolve performance issues

Documentation:
• Assist in documenting methodologies, solutions, and processes
• Contribute to project reports and presentations

Key Qualifications
• Bachelor’s degree in computer science, Artificial Intelligence, Machine Learning, or related field
• Basic knowledge of AI and ML principles
• Experience with programming languages such as Python or R

Qualifications
• Familiarity with basic ML algorithms and frameworks is a plus
• Strong analytical skills and eagerness to learn
• Good communication and teamwork skills

About LeverageTek IT Solutions

Thank you for taking the time to apply! Since our company’s inception in March 2003, LeverageTek IT Solutions has worked resolutely to become one of the industry’s most recognized and trusted suppliers of technology staffing and business consulting services. With hundreds of successful engagements to our credit with many of Canada’s leading public and private sector organizations, we are the experts in identifying, deploying, and supporting IT and business talent on a contract, contract-to-hire, and permanent basis. We work with customers across all sectors including academia, aerospace, aviation, finance, government, health care, high tech, military, not-for-profit, and more.

Our responsive service and ability to deliver the right fit, on time and within budget, typically leads to repeat engagements and a long-standing relationship.",Ottawa,CA,2023-12-19 18:01:00,http://www.bdo.com,Consulting
27,FULLTIME,"Senior Data Analyst (Product Team) (Bangkok Based, relocation provided)",https://ca.linkedin.com/jobs/view/senior-data-analyst-product-team-bangkok-based-relocation-provided-at-agoda-3750108818,"About Agoda

Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 3.6 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world.

Get to Know our Team:

In Product, ideas come alive. The world is moving fast so our culture empowers ownership and minimal bureaucracy. That’s the environment that enables you to do what you think is right – and quickly. Product Operations is a large, multicultural team of diversely talented individuals that serve as the curators of Agoda’s content. We manage all the content our customers and partners see on each of our products. As a part of our team, you will take ownership of processes that are critical to multiple other teams across the business. We are driving property-level content to map inventories from 3 rd  party supplies which will enable our reach to span the globe. Content Operations is also keen on self-improvement and innovation. We run our own structured data and analyze it to make impactful decisions. With the support of state-of-the-art technology and an enriching work environment, we strengthen the bottom line and drive new business for Agoda. 

The Opportunity:

As an Analyst/Senior Analyst, you will report directly to either the Senior Manager or Associate Director within the Product Department and this will be an individual contributor role. You will be responsible and fully empowered to work with the partners on the ground. You will be supported by a team within the Product department and work closely with other Team members within Agoda. You will be instrumental in ensuring there is consistency in data being used for reporting, identifying value-added data to help the business grow as well as using data to make strategic business decisions. You will be expected to dig into data to provide business insights, guide decision-making and offer valuable inputs to further grow our business model.

In this Role, you’ll get to:
• Translate internal briefs into analytical projects (to include refining the initial brief and asking the ‘right questions’, working through potential hypotheses and storyboarding the output)
• Use and analyze data from multiple large-scale data warehouses and present statistically strong analysis to a wide range of business stakeholders
• Conducted an analysis of customer behavior and their path through the platform, guaranteeing that the conversion rates for each front-end page met the established benchmarks and continually pinpointed opportunities for enhancement
• Partnered with the Product Design and User Research team to generate fresh data-driven projects, one of which involved the development of a Dashboard designed for more efficient monitoring of user behavior and the measurement of novel business metrics
• Drive new analytical initiatives and projects aimed at improving organizational efficiency and shaping Agoda supply
• Identify, support, and lead projects aimed at scaling up the way the Supply organization leverages on data, insights, and intelligence
• Automate manual operational processes and present back on time savings gained through modernization of business operations

What you’ll Need to Succeed:
• Bachelor’s degree or higher in Mathematics, Business, Economics, Data Science, Information Technology or similar field
• Bachelor’s Degree or higher in computer sciences, engineering, mathematics, statistics, data science or a related degree program. Masters degree preferred
• Advanced domain of data analysis and data visualization tools and software such as Excel, SQL, Tableau, Python or similar
• Analytical mindset, with proven track record in using data to measure performance and make decisions
• Excellent problem-solving skills including the ability to analyze and resolve complex problems using data
• Ability to work under pressure in a fast-paced and rapidly changing environment
• Excellent communication skills (both verbal and written), with proven ability to convey complex messages clearly and with conviction
• Team player with strong interpersonal, relationship-building, and stakeholder management skills

#STRA#ANLS#MRKT#3 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #baku #minsk #brussels #antwerp #ghent #charleroi #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server #productanalyst #product

Equal Opportunity Employer

At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.

We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy .

To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.",Toronto,CA,2023-12-19 13:41:00,http://www.agoda.com,Consulting
28,CONTRACTOR,Business Data Analyst,https://ca.linkedin.com/jobs/view/business-data-analyst-at-lancesoft-inc-3729324314,"Candidate Requirements/Must Have Skills:
• 5+ years of experience with VBA (extract/export data, create code)
• 3+ years of experience with SQL (extract/join data)
• Proficiency with MS tools (excel, word)
• 8+ years of experience with Data Analysis (data flows, data reconciliation)

Nice-To-Have Skills:
• Python Experience
• Familiarity with Accounting Principles (General Ledgers, GLs, etc.)
• Capital Markets product knowledge",London,CA,2023-12-19 21:57:00,http://www.lancesoft.com,Staffing
29,FULLTIME,Sr. Software Engineer - Data Engineer,https://ca.linkedin.com/jobs/view/sr-software-engineer-data-engineer-at-capgemini-engineering-3755141605,"Life at Capgemini

Capgemini supports all aspects of your well-being throughout the changing stages of your life and career. For eligible employees, we offer:
• Flexible work
• Healthcare including dental, vision, mental health, and well-being programs
• Financial well-being programs such as 401(k) and Employee Share Ownership Plan
• Paid time off and paid holidays
• Paid parental leave
• Family building benefits like adoption assistance, surrogacy, and cryopreservation
• Social well-being benefits like subsidized back-up child/elder care and tutoring
• Mentoring, coaching and learning programs
• Employee Resource Groups
• Disaster Relief

About Capgemini Engineering

World leader in engineering and R&D services, Capgemini Engineering combines its broad industry knowledge and cutting-edge technologies in digital and software to support the convergence of the physical and digital worlds. Coupled with the capabilities of the rest of the Group, it helps clients to accelerate their journey towards Intelligent Industry. Capgemini Engineering has more than 55,000 engineer and scientist team members in over 30 countries across sectors including Aeronautics, Space, Defense, Naval, Automotive, Rail, Infrastructure & Transportation, Energy, Utilities & Chemicals, Life Sciences, Communications, Semiconductor & Electronics, Industrial & Consumer, Software & Internet.

Capgemini Engineering is an integral part of the Capgemini Group, a global leader in partnering with companies to transform and manage their business by harnessing the power of technology. The Group is guided every day by its purpose of unleashing human energy through technology for an inclusive and sustainable future. It is a responsible and diverse organization of over 360,000 team members in more than 50 countries. With its strong 55-year heritage and deep industry expertise, Capgemini is trusted by its clients to address the entire breadth of their business needs, from strategy and design to operations, fueled by the fast evolving and innovative world of cloud, data, AI, connectivity, software, digital engineering and platforms. The Group reported in 2022 global revenues of €22 billion.

Get the Future You Want | www.capgemini.com

Disclaimer

Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.

This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.

Capgemini is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to your recruiting contact.

Click the following link for more information on your rights as an Applicant http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law

Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.

Please be aware that Capgemini may capture your image (video or screenshot) during the interview process and that image may be used for verification, including during the hiring and onboarding process.

Name of the position: Senior Data Engineer

Department/Project: Engineering

PURPOSE OF THE JOB

As a Senior Engineer, you will build distributed data processing solution and highly loaded database solutions for various cases including reporting, product analytics, marketing optimization and financial reporting. Give as part of self-organized team of experienced data engineers working in a complicated, innovative environment for our client, crafting the foundation for decision-making at a company dealing with billions of events per day.

Investigate, build, and implement the solutions for existing technical challenges. Provide mentorship, instruction, direction, leadership to a development team with the purpose of achieving project goals.

Main Tasks And Responsibilities
• Acquires tasks from the project lead or Team Lead (TL), prepares functional and design specifications, approves them with all team members.
• Ensures that assigned area/areas are delivered within required quality objectives.
• Provides estimations, agrees task duration with the manager and gives to project plan of assigned area.
• Analyzes scope of alternative solutions and makes decision about area implementation based on their experience and technical expertise.
• Leads functional and architectural design of assigned areas. Makes sure design decisions on the project meet architectural and design requirements.
• Addresses area-level risks, provides and implements mitigation plan.
• Responsible for resolving crisis situations within their AOR.
• Initiates and conducts code reviews, creates code standards, conventions and guidelines.
• Suggests technical and functional improvements to make valuable contributions to the product;
• Constantly improves their professional level.
• Collaborates with other teams.

Required Education And Experience

Must have:
• 5+ years of professional experience
• University degree or equivalent experience in Computer Related Sciences or similar
• shown experience working in data engineering, business intelligence, or a similar role
• Proficiency in programming languages such as Python
• demonstrated ability in ETL orchestration and workflow management tool Airflow
• Guide in Database fundamentals, SQL and distributed computing
• proven experience with the Distributed data/similar ecosystem (Spark, Hive, Presto o and/or streaming technologies such as Kafka/Flink.
• Experience working with Snowflake, Redshift, PostgreSQL and/or other DBMS platforms

Nice to have:
• Experience in AWS (EC2/S2/IAM).",London,CA,2023-12-19 12:07:00,http://www.altran.com,Computer Services
30,CONTRACTOR,Product Support Data Analyst (12 Month Contract),https://ca.linkedin.com/jobs/view/product-support-data-analyst-12-month-contract-at-volkswagen-group-canada-inc-3771712421,"It’s more than a Career, it’s a Passion!

We love our cars, but it’s the people behind them who make them what they are. To build great cars, we need great people. That’s why Volkswagen Group Canada pays competitive salaries, offers fringe benefits, and provides unique opportunities for personal and professional growth. We encourage and reward initiative, creativity, teamwork and performance within a fast-paced, stimulating environment. And did we mention that there are really cool Volkswagen and Audi vehicles all over the place?

We are currently looking for a Product Support Data Analyst at our Corporate Offices in Ajax, ON

This role is responsible for the monitoring and analysis of market quality topics for the VW and Audi vehicle population. The primary task is the analysis and reporting of data to the respective factories and internal teams. The secondary task is to perform deep dive analysis utilizing many data sources (warranty, technical assistance centre tickets, Parts, road side, sales) to identify and quantify new and upcoming trends, and report to the necessary areas of responsibility.
• This is a 12-month contract with the possibility of extension, on a flex hybrid model requiring 2 days in the Ajax office**

Primary Responsibilities
• Monitoring of field Warranty claims / Tow-in data for defect trends / Long term durability trends and reporting of market quality topics to respective factories / manufacturers for all models
• Support of the Dealer network / Technical helpline / Technical Quality Managers by supplying technical data and trend information for the entire vehicle population.
• Provide smart data analysis to product support team to improve efficiency in topic analysis
• Create and manage dealer dashboard system showing dealer performance in various areas of business
• Market liaison and relationship with assigned VW/Audi factories
• Provide technical data reporting to other internal departments
• Perform data analysis on retuned warranty parts as requested by VW / AUDI AG.
• Identify product improvements based on information from all available data sources.
• Establish and provide technical reports as requested.
• Support the New Model Launch process readiness by providing detailed quality performance reporting
• Support the technical literature accuracy, translation and availability

Qualifications
• Post-Secondary Education in Engineering, Business and/or equivalent working experience
• 1 + years of experience of data analysis in a fast paced environment, supporting teams and business decisions
• Familiarity with the automotive industry (manufacturing, dealerships, technical knowledge) is beneficial
• Experience in Fault Analysis Process (root cause analysis), Technical reporting
• High degree of proficiency with Excel (V-lookups, H-lookups, Pivot Tables)
• Proven ability to analyze large data sets and extract meaningful trends and actionable results
• Knowledge of French/ German language is an asset
• Travel up to 5%

What You’ll Get In Return
• A flexible and collaborative team dynamic
• Opportunities for development
• Opportunities to participate in exciting company events that give back to the community
• Competitive employer paid benefits and overall compensation package
• And much more!

Interested applicants are asked to submit their application by December 31, 2023
• Please note that we appreciate the interest of all candidates, however only those under consideration will be contacted.

Volkswagen Group Canada Inc. is committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, family status, gender identity, gender expression, national origin, age, disability or any other characteristic protected by federal, or local laws.

Volkswagen Group Canada Inc. is committed to providing accommodations for people with disabilities including during the application process. If you require an accommodation because of a disability, we will work with you to determine what reasonable accommodation may be available to meet your needs whether it be as an applicant or an employee. Applicants need to make their needs known in advance. If you are selected for an interview and require an accommodation, you are encouraged to advise the Recruiter who will consult with you to determine an appropriate and reasonable accommodation",Ajax,CA,2023-12-19 16:57:00,http://www.vw.ca,Manufacturing
31,FULLTIME,"Senior Data Scientist, Acquisition",https://ca.linkedin.com/jobs/view/senior-data-scientist-acquisition-at-grammarly-3774283748,"Grammarly is excited to offer a remote-first hybrid working model. Team members work primarily remotely in the United States, Canada, Ukraine, Germany, or Poland. Certain roles have specific location requirements to facilitate collaboration at a particular Grammarly hub.

All roles have an in-person component: Conditions permitting, teams meet 2–4 weeks every quarter at one of Grammarly’s hubs in San Francisco, Kyiv, New York, Vancouver, and Berlin, or in a workspace in Kraków. This flexible approach gives team members the best of both worlds: plenty of focus time along with in-person collaboration that fosters trust and unlocks creativity.

Grammarly team members in this role must be based in the United States or Canada, and they must be able to collaborate in person 2 weeks per quarter, traveling if necessary to the hub(s) where the team is based.

The opportunity

Grammarly is the world’s leading AI writing assistance company trusted by over 30 million people and 70,000 professional teams every day. From instantly creating a first draft to perfecting every message, Grammarly’s product offerings help people at 96% of the Fortune 500 get their point across—and get results. Grammarly has been profitable for over a decade because we’ve stayed true to our values and built an enterprise-grade product that’s secure, reliable, and helps people do their best work—without selling their data. We’re proud to be one of Inc.’s best workplaces, a Glassdoor Best Place to Work, one of TIME’s 100 Most Influential Companies, and one of Fast Company’s Most Innovative Companies in AI.

To achieve our ambitious goals, we’re looking for a Senior Data Scientist to join our incredible team and work on core marketing measurement and optimization projects. The ideal candidate will have strong technical expertise and marketing domain knowledge and collaborate with cross-functional teams to develop solutions and drive data-driven actions. The person in this role will advance our statistical rigor, testing, and measurement methodologies, define a framework to measure the impact of our marketing channels, leverage Grammarly’s internal data and Google Ads platform data to solve ambiguous marketing problems and provide data-driven solutions.

The Grammarly data teams are trusted subject matter experts who uncover new insights to inform marketing, product, and growth strategies. We have large datasets and are looking for folks with deep technical and analytical skills who can break down complex business problems and provide solutions with high impact and visibility for marketing and the company. Our teams have the freedom to innovate and uncover breakthroughs—and, in turn, influence the marketing roadmap.

Your impact

As a Senior Data Scientist, You Will
• Lead testing and measurement efforts for our key online marketing channels, especially paid searches, such as Google and Bing.
• Develop cross-channel measurement models such as MediaMixModeling to optimize budget allocation.
• Collaborate with Engineering and Marketing teams to drive LTV bidding optimizations and their impact measurement for our digital marketing channels.
• Measure the effectiveness of Individual Marketing channels and Cross-Channels by building/leveraging different attribution models and experimentation methods.
• Devise a solution to inform marketing strategy and drive measurement in a cookieless world.
• Analyze the impact of our overall marketing budget to understand its full-funnel impact and how it influences Grammarly for Business conversions.
• Run elasticity analysis to drive discussions and identify opportunities for spending re-allocation across countries.
• Conduct deep-dive analyses into marketing channel performance and user behavior.

We’re Looking For Someone Who
• Embodies our EAGER values—is ethical, adaptable, gritty, empathetic, and remarkable.
• Is inspired by our MOVE principles, which are the blueprint for how things get done at Grammarly: move fast and learn faster, obsess about creating customer value, value impact over activity, and embrace healthy disagreement rooted in trust.
• Is able to collaborate in person 2 weeks per quarter, traveling when necessary to the hub where the team is based.
• Has 8+ years of relevant work experience.
• Has experience as an influential and effective thought partner to marketing teams.
• Demonstrates strong communication, proactiveness, creativity, and prioritization skills.
• Has strong analytical and critical thinking skills and a strong bias toward actionable insights.
• Has the ability to work in a fast-paced, dynamic environment.
• Has practical experience in data analysis, statistics, and marketing measurement.
• Is proficient in SQL, Python, R, Scala, or an equivalent language.

Support for you, professionally and personally
• Professional growth: We believe that autonomy and trust are key to empowering our team members to do their best, most innovative work in a way that aligns with their interests, talents, and well-being. We support professional development and advancement with training, coaching, and regular feedback.
• A connected team: Grammarly builds a product that helps people connect, and we apply this mindset to our own team. Our remote-first hybrid model enables a highly collaborative culture supported by our EAGER (ethical, adaptable, gritty, empathetic, and remarkable) values. We work to foster belonging among team members in a variety of ways. This includes our employee resource groups, Grammarly Circles, which promote connection among those with shared identities, such as BIPOC and LGBTQIA+ team members, women, and parents. We also celebrate our colleagues and accomplishments with global, local, and team-specific programs.

Compensation And Benefits

Grammarly offers all team members competitive pay along with a benefits package encompassing the following and more:
• Excellent health care (including a wide range of medical, dental, vision, mental health, and fertility benefits)
• Disability and life insurance options
• 401(k) and RRSP matching
• Paid parental leave
• Twenty days of paid time off per year, eleven days of paid holidays per year, and unlimited sick days
• Home office stipends
• Caregiver and pet care stipends
• Wellness stipends
• Admission discounts
• Learning and development opportunities

Grammarly takes a market-based approach to compensation, which means base pay may vary depending on your location. Our US and Canada locations are categorized into compensation zones based on each geographic region’s cost of labor index. For more information about our compensation zones and locations where we currently support employment, please refer to this page. If a location of interest is not listed, please speak with a recruiter for additional information.

Base pay may vary considerably depending on job-related knowledge, skills, and experience. The expected salary ranges for this position are outlined below by compensation zone and may be modified in the future.

United States

Zone 1: $197,000 - $253,000year (USD)

Zone 2: $177,000 - $228,000/year (USD)

Zone 3: $168,000 - $215,000/year (USD)

Zone 4: $157,000 - $202,000/year (USD)

We encourage you to apply

At Grammarly, we value our differences, and we encourage all—especially those whose identities are traditionally underrepresented in tech organizations—to apply. We do not discriminate on the basis of race, religion, color, gender expression or identity, sexual orientation, ancestry, national origin, citizenship, age, marital status, veteran status, disability status, political belief, or any other characteristic protected by law. Grammarly is an equal opportunity employer and a participant in the US federal E-Verify program (US). We also abide by the Employment Equity Act (Canada).

Please note that EEOC is optional and specific to US-based candidates.

#NA

All team members meeting in person for official Grammarly business or working from a hub location are strongly encouraged to be vaccinated against COVID-19.",Toronto,CA,2023-12-19 11:26:00,http://www.grammarly.com,Consulting
32,FULLTIME,"Lead Data Scientist (Bangkok based, relocation provided)",https://ca.linkedin.com/jobs/view/lead-data-scientist-bangkok-based-relocation-provided-at-agoda-3751173776,"About Agoda

Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 3.6 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world.

Get to Know Our Team

The Data department , based in Bangkok , oversees all of Agoda’s data-related requirements. Our ultimate goal is to enable and increase the use of data in the company through creative approaches and the implementation of powerful resources such as operational and analytical databases, queue systems, BI tools, and data science technology. We hire the brightest minds from around the world to take on this challenge and equip them with the knowledge and tools that contribute to their personal growth and success while supporting our company’s culture of diversity and experimentation. The role the Data team plays at Agoda is critical as business users, product managers, engineers, and many others rely on us to empower their decision making. We are equally dedicated to our customers by improving their search experience with faster results and protecting them from any fraudulent activities. Data is interesting only when you have enough of it, and we have plenty. This is what drives up the challenge as part of the Data department, but also the reward.

The Opportunity

Please note -The role will be based in Bangkok.

We are looking for ambitious and agile data scientists that would like to seize the opportunity to work on some of the most challenging productive machine learning and big data platforms worldwide, processing some 600B events every day and making some 5B predictions.

As part of the Data Science and Machine Learning (AI/ML) team you will be exposed to real-world challenges such as: dynamic pricing, predicting customer intents in real time, ranking search results to maximize lifetime value, classifying and deep learning content and personalization signals from unstructured data such as images and text, making personalized recommendations, innovating algorithm-supported promotions and products for supply partners, discovering insights from big data, and innovating the user experience. To tackle these challenges, you will have the opportunity to work on one of the world’s largest ML infrastructure employing dozens of GPUs working in parallel, 30K+ CPU cores and 150TB of memory.

In This Role, You’ll Get to
• Design, code, experiment and implement models and algorithms to maximize customer experience, supply side value, business outcomes, and infrastructure readiness
• Mine a big data of hundreds of millions of customers and more than 600M daily user generated events, supplier and pricing data, and discover actionable insights to drive improvements and innovation
• Work with developers and a variety of business owners to deliver daily results with the best quality
• Research discover and harness new ideas that can make a difference

What You’ll Need To Succeed
• 4+ years hands-on data science experience
• Excellent understanding of AI/ML/DL and Statistics, as well as coding proficiency using related open source libraries and frameworks
• Significant proficiency in SQL and languages like Python, PySpark and/or Scala
• Can lead, work independently as well as play a key role in a team
• Good communication and interpersonal skills for working in a multicultural work environment

It’s Great if You Have
• PhD or MSc in Computer Science / Operations Research / Statistics or other quantitative fields
• Experience in NLP, image processing and/or recommendation systems
• Hands on experience in data engineering, working with big data framework like Spark/Hadoop
• Experience in data science for e-commerce and/or OTA

We welcome both local and international applications for this role. Full visa sponsorship and relocation assistance available for eligible candidates.

#sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #sydney #melbourne #perth #toronto #vancouver #montreal #shanghai #beijing #shenzhen #prague #Brno #Ostrava #cairo #alexandria #giza #estonia #paris #berlin #munich #hamburg #stuttgart #cologne #frankfurt #hongkong #budapest #jakarta #bali #dublin #telaviv #milan #rome #venice #florence #naples #turin #palermo #bologna #tokyo #osaka #kualalumpur #malta #amsterdam #oslo #manila #warsaw #krakow #doha #alrayyan #riyadh #jeddah #mecca #medina #singapore #seoul #barcelona #madrid #stockholm #zurich #taipei #tainan #taichung #kaohsiung #bangkok #Phuket #istanbul #london #manchester #edinburgh #hcmc #hanoi #lodz #wroclaw #poznan #katowice #rio #salvador #newdelhi #bangalore #bandung #yokohama #nagoya #okinawa #fukuoka #jerusalem #IT #4

Equal Opportunity Employer

At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.

We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy .

To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.",Toronto,CA,2023-12-19 11:31:00,http://www.agoda.com,Consulting
33,FULLTIME,"Analyst/Senior Analyst (Supply Analytics, Bangkok-based, Relocation provided)",https://ca.linkedin.com/jobs/view/analyst-senior-analyst-supply-analytics-bangkok-based-relocation-provided-at-agoda-3750890541,"About Agoda

Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 3.6 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world.

THIS ROLE IS BASED IN BANGKOK, THAILAND (WITH RELOCATION PROVIDED)

Location: Bangkok, Thailand (*Not open for remote work.)

Get to Know our Team:

As part of the Supply Analytics, you will be responsible for identifying new partners and opportunities, cultivating a relationship with them, and working together with them to deliver the best outcome for our end customers. You would also be responsible with managing the day-to-day interaction with the partner and working closely with other teams within Agoda to ensure the partners needs are met.

We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda’s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek. Utilizing our strong brand and resources, we build new channels to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business.

The Opportunity:

As an Analyst/Senior Analyst, you will report directly to either the Senior Manager or Associate Director within the Supply Department and this will be an individual contributor role. You will be responsible and fully empowered to work with the partners on the ground. You will be supported by a team within the Supply department and work closely with other Team members within Agoda.

In this Role, you’ll get to:
• Translate internal briefs into analytical projects (to include refining the initial brief and asking the ‘right questions’, working through potential hypotheses and storyboarding the output)
• Use and analyze data from multiple large-scale data warehouses and present statistically strong analysis to a wide range of business stakeholders
• Proactively identify opportunities for growth within supply and the wider business
• Drive new analytical initiatives and projects aimed at improving organizational efficiency and shaping Agoda supply
• Identify, support, and lead projects aimed at scaling up the way the Supply organization leverages on data, insights, and intelligence
• Automate manual operational processes and present back on time savings gained through modernization of business operations

What you’ll Need to Succeed:
• At least 3-5+ years of experience working as an Analyst with experience in analytics/data science/insights/strategy/BI
• Advanced working knowledge and hands-on experience in SQL
• Strong knowledge and hands-on experience in data visualization tools such as Tableau (preferably)
• Expert domain of data analysis and data visualization tools and software such as Excel, Python (or R)
• Bachelor’s degree ideally in a business or quantitative subject (e.g. computer science, mathematics, engineering, science, economics or finance)
• A good understanding of statistical modelling knowledge or any machine learning technique knowledge (such as hypothesis testing, regression, logistic regression, random forest, etc.)
• Good stakeholder management experience. Comfortable presenting to senior leadership and C-suite
• Experience in conducting A/B testing experimentation
• Strong experience in finding data insights and provide business recommendation to the business
• A hacker’s mindset – the ability to build simple but clever and elegant solutions to new problems within significant resource, operational and time constraints through deep understanding of the business, creative problem solving, and a wide range of expertise in data, analytics, automation, programming, and prototyping
• Excellent communicator with superior written, verbal, presentation and interpersonal communication skills
• Data driven in both decision making and performance measurement
• Extreme comfort in ambiguous, fast-paced environment
• Ability to multi-task, prioritize and coordinate resources

It’s Great if you Have:
• MBA or Masters in a quantitative subject (e.g. computer science, mathematics, engineering, science, economics or finance)
• Program management certifications (e.g. PMI, PRINCE2) to compliment your program management experience
• Asian market experience
• Travel industry / e-commerce / tech / consulting experience

#sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #baku #minsk #brussels #antwerp #ghent #charleroi #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis

Equal Opportunity Employer

At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.

We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy .

To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.",Toronto,CA,2023-12-19 14:14:00,http://www.agoda.com,Consulting
34,FULLTIME,Data Engineer,https://uk.linkedin.com/jobs/view/data-engineer-at-curve-analytics-3784439276,"Curve is a next-gen insights and analytics consultancy that leverages digital consumer data and advanced technology to help businesses unlock consumer opportunities. Digital consumer data is powerful; it's big, it's real, and it's always updating. We transform data from sources such as Social, Reviews, Search, and Web to reveal fresh insights for our clients; helping them to build better products and brands, and deliver effective marketing to consumers.

Our software, machine learning and AI are key to how we deliver impact, centred on:
• Natural Language Processing, GPT & other LLMs: unearthing trends, themes and other patterns from large text-based data sets, and deploying state-of-the-art AI to automate and empower consumer facing businesses and their insights & analytics functions
• Marketing Data Science & Personalisation: using first party consumer data to understand each client's consumer base, building personalisation and other machine learning models to better engage with and excite consumers
• Analytics Engineering & Data Architecture: data engineering across a variety of tools to integrate these leading technologies into optimised and efficient data models and ecosystems, feeding into best-in-class analytics dashboards and front-end platforms
• Software Engineering: full stack expertise to build, maintain and support internal and externally facing Software & Data as a Service solutions, in AWS, that accelerate delivery and unlock deeper insights for our clients

As a start-up, we can move faster than most companies and do things differently. We have experienced rapid growth so far and we’re looking for a Data Engineer to join our growing team.

About the role:

You’ll play a crucial role in designing, building and productionising innovative data pipelines, in the cloud, from scratch. You’ll work on a mix of small analytics proof of concepts and larger projects, both of which pushing the boundaries of what we can do with data; finding and using novel data sources and APIs, and enriching them with leading analytics, data science and AI methods.

Your role will be twofold. You’ll be working directly with our London-based client-base, as well as helping to shape the future of our fast-growing start-up. We’ll let you challenge yourself, from your core of data engineering to support our data science and dashboard visualisation work, to grow your cloud architecture and engineering knowledge, and to understand the business and strategic impact of your great engineering work – to whatever extent suits you.

You should be passionate about developing industry first data science and analytics capabilities and have an innovative and creative mindset.

What you’ll be doing:
• Build innovative data solutions in Python, PySpark & SQL across Databricks, Snowflake, AWS and more
• Support the development and rollout of industry first global analytics programmes
• Develop and deploy automated code pipelines, from data acquisition, owning transformation and supporting data modelling
• Help to productionise machine learning models and integrate leading APIs from OpenAI, GCP, Microsoft and other open source solutions
• Work closely with great programme teams - project lead, data scientists and analysts – and interface with client technology counterparts
• Identify ways to improve data reliability, processing efficiency and quality of our data output
• Produce detailed documentation and champion code quality
• Interrogate rich data sources such as social, search, surveys, reviews, clickstream, sales, connected devices and beyond
• Identify and explore opportunities to acquire new data sources that deliver innovative perspectives to our clients

What we’re looking for:
• Bachelor’s degree or higher in an applicable field such as Computer Science, Statistics, Maths or similar Science or Engineering discipline
• Experience designing, building and maintaining SQL databases (and/or NoSQL)
• Experience with designing efficient physical data models/schemas and developing ETL/ELT scripts
• Strong python and other programming skills (Java and/or Scala desirable)
• Experience developing data solutions in cloud environments such as Azure, AWS or GCP – Azure Databricks & Snowflake experience a bonus
• Strong SQL background
• Some exposure to big data technologies (hadoop, spark, presto, etc.)

Nice to haves or excited to learn:
• Experience with APIs
• Experience with Data Science and / or NLP
• Data & Solution Architecture understanding
• Experience of software development, CI/CD pipelines and/or other DevOps practices and principles
• Experience utilising social listening tools and / or search / web analytics tools

Benefits:

Here are some of the benefits Curve employees enjoy.
• Competitive Salary: Salary is important and so we pay competitively versus other consultancies.
• Annual Leave: 25 days holiday a year plus bank holidays.
• Annual Bonus: Our Annual Bonus is based on company and individual performance.
• Generous Pension: You can expect to receive a generous pension contribution
• Health and Wellbeing: We've got you covered with AXA Private Healthcare, including a 24/7 Employee Assistance Programme. You will also be able to join our internal Wellness Sessions and will be allocated to a People Manager for confidential support
• Growth and Development: Development is at the heart of everything we do. You will be able to create a Personalised Growth Plan and get involved in our internal training. You will also get a yearly individual learning budget for training, books, courses, certifications, and conferences.
• Wellbeing Support: You will have access to Weekly Wellness Sessions every Wednesday and will be allocated to a People Manager for confidential support.
• Cycle to Work Scheme: Save on the cost of a brand new bike with our Cycle to Work Scheme.
• Hybrid Working: At Curve, you can split your time between working remotely and from our HQ.
• Raising Awareness and CSR: From interactive workshops around mental health to educational presentations to Earth Day initiatives, as a team, we love to raise awareness on different topics!
• Free Drinks and Snacks: In our office, you will be able to enjoy a variety of fresh fruit every week and unlimited tea and coffee to fuel up for the day!
• Social Calendar: Whether it’s a quick drink at the pub after work or our annual summer party, we have a vibrant social culture with frequent social events!
• Positive environment: Work in an open, respectful, and inclusive environment where everyone can grow and thrive.

We’re looking for candidates who really want to make an impact. Join us!

Curve is an equal opportunity employer dedicated to building an inclusive and diverse workforce. We do not discriminate on the basis of disability, sex, gender reassignment, sexual orientation, pregnancy and maternity, race, religion or belief and marriage and civil partnerships. All employment is decided on the basis of qualifications, merit, and business need. If you require any reasonable adjustments to be made during the recruitment process then please don’t hesitate to let us know.",London,GB,2023-12-19 17:38:00,http://www.bdo.com,Consulting
35,FULLTIME,Data Engineering Analyst,https://www.hfg.co.uk/job/data-engineering-analyst-4,"We have partnered with a leading London insurer to find them a Data Engineering Analyst to join their rapidly expanding team. This is a fantastic opportunity to work as part of a centralized data and analytics resource for commercial, operational, and technical areas, providing consolidated, granular, accurate data/reporting for analytics, analysis, and business execution. Provide technical support for the design, construction and maintenance of data for the business. This role includes but is not limited to:
• Provide technical support for the design, construction and maintenance of data for the business.
• Coordination of data projects with different levels of complexity depending on existing methods, processes and tools.
• Manages and coordinates stakeholders and builds a robust communication structure for data-related projects.
• Advises stakeholders and actively clarifies their expectations and requirements
• Ability to assume responsibility for change, communication, quality and risk management.
• Understand the data relationships that exist between the business processes and systems. In turn apply this knowledge when interpreting the information requirements from the business.
• Translate data, analysis and commentary into a format for presentation to senior management.
• Gather, interpret, identify gaps and translate business MI and reporting requirements into solutions.
• Carry out analysis and interpret data to support the business in strategic and commercial decisions.
• Understand database and data science concepts and terminology, design principles and elements in order to deliver data and analytics

Please apply for further information.",London,GB,2023-12-19 17:00:00,http://www.hanafn.com,Finance
36,FULLTIME,Junior Data Engineer,https://uk.linkedin.com/jobs/view/junior-data-engineer-at-rockpool-digital-3790307920,"Are you smart, ambitious and passionate about managing and using data? Do you want to create scalable data platforms for some of the UK’s top brands?

We're looking for a Junior Data Engineer to join our team, who's excited about developing their expertise and knowledge of SQL and data engineering.

With a mix of home working and team collaboration in our vibrant, open plan office in Bristol, on any given day you could be doing one or all of these things:
• Work with stakeholders to understand business objectives and interpret them into data models
• Identify opportunities for data acquisition, data usage and insight generation
• Create data reporting that enables data driven decision making
• Build data systems and pipelines using development tools
• Ensure that data solutions uphold data governance and/or data compliance frameworks
• Provide second line technical support for existing data platforms

Requirements

All our teams work to exacting standards, and so we're looking for a talented data engineer:
• Experience of database interrogation, querying and analysis tools
• Ability to model business problems into data structures within SQL Server
• Awareness of ETL concepts and tools such as SSIS or Azure Data Factories
• Great attention to detail and the ability to problem solve
• Understanding of data visualisation tools (e.g. Power BI)
• Appreciation of software development within an agile environment

Preferable
• Microsoft Certified: Azure Data Engineer Associate (DP-203)

Benefits

Working at Rockpool is slightly different than elsewhere. We've tried to make life as simple as possible, placing our trust in our team to make decisions and manage their own work:
• We don't do middle management, so you can easily share your brilliant ideas
• You will have the flexibility to set and manage your own working hours
• We like to talk, like normal people do - you'll get regular, open, and honest feedback

We invest heavily in the wellbeing of our employees. So the role also comes with the following benefits:
• 28 days annual leave (plus bank holidays on top)
• Option to buy or sell a further 5 days of leave
• Matched pension contributions up to 8%
• Private health insurance
• Group life assurance
• Wellbeing fund that contributes £25 per month towards an activity that promotes your mental or physical wellbeing
• Annual profit related bonus (historically about £2,500 per annum)
• Significant investment in your learning and development
• Company provided breakfasts, fruit, beer fridge and soft drinks
• Regular company funded socials and away day",Bristol,GB,2023-12-19 17:51:00,http://rockpooldigital.com,Consulting
37,FULLTIME,Senior Data Analyst,https://careers.bankofireland.com/jobs/cc5dc501-b3d7-48e9-b215-daf58f5b2256,"What is the opportunity?

This is an exciting opportunity where you will be reporting and creating insights data-driven solutions to support the business! You will collaborate with other specialists, spread capability awareness and develop new talent. Join the team and accelerate the adoption of analytics to transform the bank, engage our customers and deliver value.

In this role you will:
• Contribute to a creative data driven culture centred on an agile environment, problem solving and design thinking
• Conduct data science related engineering to build new data marts and productionised data features
• Engage collaborators, and challenge requirements, to respond to critical business issues, and support the organisation's transformation strategy and values
• Collaborate with colleagues from across the Bank to eliminate silos, to drive the adoption of the Enterprise Data Warehouse & Enterprise Data Lake and to share standard process
• Write and refine stories, elicit acceptance criteria for relevant scenarios/use cases; facilitate the capture of solution options.
• Work with customer requirements to prototype, develop, test, deploy and maintain operational and strategic dashboards.
• Optimise the Tableau reporting layer (efficiency and lag time)

What will make you stand out?
• Strong troubleshooting, debugging, and performance tuning skills.
• Experience of Big Data tools eg Spark, Impala and Kafka
• Proven knowledge of how to process big datasets as well as streaming data and unstructured data sources, including Hive, Spark, Kafka and HBase and are eager to further develop yourself in this area
• Experience with data governance, data lineage, and metadata practices
• Familiar with database concepts and Linux development environments.
• A Big Data Engineer with production level experience with one or more Big Data platforms, preferably either (cloud) platforms: Cloudera, Azure, AWS
• Experience developing data visualisation through Tableau or an equivalent software platform

Experience with any of the following will help you to stand out but is not vital in order to apply for this role:
• Third Level qualification, in mathematics, statistics, finance, IT, or another subject area including a significant numerical element

Essential Qualifications

There are no specific qualifications or minimum educational requirements needed for this role.

More about the team

The Group Data and Analytics Office (GDAO) and Data, Digital & Strategic Reporting (DDAS) is an enabler for Bank Of Ireland UK business divisions.

We are a shared function that centralises Data, Digital & Analytics activities across the portfolio enabling simplification, standardisation and sharing of standard processes and insight development uplift.

We aim to reduce 'fire fighting' and increase opportunity to deliver value-add initiatives in Data & Digital teams (including prioritisation of initiatives and support across the portfolio)

#LI-HYBRID

Why work with us?

The Bank of Ireland company culture prioritises work-life balance with an opportunity for flexible working, along with 24 days annual leave and excellent pension contributions. Family can mean different things to different people; we offer 6 months paid maternity leave, an innovative fertility and surrogacy policy and working parent supports.

Your wellbeing is important to us; we have an employee assistance program along with other fantastic supports. We also encourage and support staff to pursue educational and professional qualifications to grow and enhance your career!

Key Competencies
• Accountable - Self
• One Group, one team - Self
• Agile - Self
• Champion Transformation - Self
• Amplify Capability - Self

Where Agency assistance is required Bank of Ireland Recruitment Team will engage directly with suppliers. Unsolicited CVs / profiles supplied to Bank of Ireland by Recruitment Agencies will not be accepted for this role.

Bank of Ireland Group is an equal opportunities employer and is committed to fostering an inclusive workplace which values and benefits from the diversity of our workforce.

We offer reasonable accommodation at every stage of the application and interview process. If you require assistance, please contact recruitdirect@boi.com.",Belfast,GB,2023-12-19 14:20:00,http://www.bankofireland.com,Finance
38,FULLTIME,"Data Engineer, Analytics",https://uk.linkedin.com/jobs/view/data-engineer-analytics-at-meta-3730074946,"At Reality Labs, we are helping more people around the world come together and connect through world-class AR and VR hardware and software. With global departments dedicated to AR/VR research, computer vision, haptics, social interaction, and more, Meta is committed to driving the state of the art forward through relentless innovation.Join our MetaWorks team to help shape the future of work in VR and AR and contribute to establish and scale innovative products that'll change the way we work!As a highly collaborative organisation, our data engineers work cross-functionally with software engineering, data science, and product management to optimise growth, strategy, and experience for our users.In this role, you will see a direct correlation between your work, company growth, and user satisfaction. Beyond this, you will work with some of the brightest minds in the industry, and you'll have a unique opportunity to solve some of the most interesting data challenges with efficiency and integrity, at a scale few companies can match.

Data Engineer, Analytics Responsibilities:
• Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way
• Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains
• Define and manage SLA for all data sets in allocated areas of ownership
• Solve challenging data integration problems, utilizing optimal ETL patterns, frameworks, query techniques, sourcing from structured and unstructured data sources
• Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership
• Improve logging
• Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts
• Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts
• Influence product and cross-functional teams to identify data opportunities to drive impact

Minimum Qualifications:
• Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience
• Experience with one or more of the following: data processing automation, data quality, data warehousing, data governance, business intelligence, data visualization, data privacy
• Experience with SQL, ETL, data modeling and at least one programming language (e.g., Python, C++, C#, Scala).

Preferred Qualifications:
• Master's in a STEM field
• Experience working with TB to PB scale data.

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.",London,GB,2023-12-19 12:23:00,https://www.meta.com,Manufacturing
39,FULLTIME,Data Analyst,https://uk.linkedin.com/jobs/view/data-analyst-at-cambridge-spark-3790443601,"Department: Product & Technology

Location: Home based, UK

Reports to: CTO

Hours: 37.5 per week

Salary: (Depending on experience)

Role Overview

We’re an EdTech company on a mission to help organisations develop their Data Science & AI capabilities.

We are looking for a Data Analyst to join our emerging Data & Insights team, working with stakeholders across multiple departments to develop tools for self-serve access to data and respond to ad hoc data requests.

Key responsibilities:
• Build and maintain dashboards providing self-serve insights into existing datasets for various departments such as Delivery, Operations, Sales, Go-to-Market and Product.
• Respond to ad hoc data requests when self-serve tools are not available. This includes working with stakeholders to understand a problem and use your understanding of available datasets to provide an answer
• When the data necessary to answer a request is not readily available, work with relevant teams as well as engineering to update our pipelines and make it available
• Conduct deep dive strategic analysis to provide insight to a specific question or problem information important business decisions. Provide an evidence-based approach backed by data, shared to stakeholders as part of a well structured report
• Coordinate with the engineering team to improve our data pipelines, ensuring the right data is made available, processed and cleaned prior to be consumed for further analysis
• Develop and maintain a data projects roadmap by working with various stakeholders to define requirements and prioritise projects based on impact on the business
• Work with key stakeholders who maintain various sources of data to improve our data quality, integrity and ability to for reporting purposes
• Take ownership of data products from concept to launch and maintenance
• Document and communicate with the rest of the business dashboards and tools available to them, as well as cataloguing existing and available data for ad hoc reporting

Candidate Specification:

Essential
• Experience developing dashboards using BI tools such as Looker, PowerBI and Tableau
• Experience responding to data related queries and working closely with stakeholders to understand requirements
• Strong familiarity with data quality, data management and reporting best practices
• Experience working in an agile environment and ability to manage small data projects
• Ability to communicate insights effectively using evidence backed by data
• Excellent analytical and problem-solving skills with a proactive and constructive approach
• Ability to dive into data to find root causes of a problem and come up with a solution
• Ability to work with limited supervision
• Strong familiarity manipulating data with Excel for data analysis
• Familiarity with Excel macros or a BI query language (such as Looker expressions, PBI DAX, etc..)
• Willingness to automate tasks as much as possible, using existing tools or working with an engineering team for adhoc solutions

Desirable
• Familiarity or willingness to learn SQL for data queries
• Familiarity or willingness to learn Python for code based data analysis
• Interest in education
• Experience working in a startup environment

Company Benefits:
• Remote first company providing flexibility to work from home
• Pension with up to 5% matched contributions
• 25 days holiday + 8 bank holidays + 1 day off on your birthday
• Pre-tax gym allowance of £30 per month
• Annual Summer and Xmas events
• Company socials including everything from Cambridge College formals, pub nights to team building events
• Contribution towards books and training courses that help you learn and grow in your role with us
• Private medical insurance and cash plan
• Holiday buy back scheme (up to 10 days p/a)
• EAP with 24 hour confidential support line

Background to the Organisation

We are an education technology company that enables corporate and government organisations to achieve their business goals by educating their workforce with critical digital transformation skills to succeed in the AI era.

We deliver unique and innovative professional education that is accelerating the digital transformation of our clients, advancing the careers of their employees, helping people get into work and closing the digital skills gap. We are in a sector that is crucial to the economy and workforce, with a lot of opportunity for change and innovation. We are at the cutting edge of teaching applied data and digital skills, with our unique patented learning platform EDUKATE.AI offering our clients and learners a unique learning experience. EDUKATE.AI was developed with support from Innovate UK and provides all of our learners with 24/7 immediate feedback on their work, helping accelerate the learning process and providing a sandbox environment to experiment on real world datasets.

Since 2016, we have supported more than 15,000 learners across four continents with nearly 550,000 pieces of code submitted for feedback on EDUKATE.AI. We are trusted by some of the most recognisable brands in the world to educate their workforce, including Microsoft, the NHS, GSK, easyJet, the BBC and John Lewis. Our focus on applied learning to create business impact sets us apart - individual learners have reported applying their skills at work to generate recorded value of up to £40m.

Values

At the centre of the way we work together and inspire each other to achieve success are these core values:

Entrepreneurial

We take initiative and show entrepreneurial spirit which fuels innovation at Cambridge Spark. This includes identifying opportunities for improvement, taking ownership for implementing solutions effectively and driving improvement by using proof of concepts to demonstrate the feasibility and value of their work.

Team Spirit

Everyone is part of building an open and transparent culture, communicating effectively to raise issues, discuss improvements and share the evidence used to make decisions.

Customer-focused

Our customers are at the centre of everything we do, inspiring us to create great work. We strive to build friendly, professional and lasting relationships with them to better understand and anticipate their needs.

Gold Standard

We are experts in our field and are constantly developing our technology and offering. We set the benchmark in our industry: both in what we offer customers and in how we deliver it.

____________________________________________________________________________

Cambridge Spark is an Equal Opportunities Employer and prohibits discrimination and harassment of any kind. Cambridge Spark is committed to the principle of equal employment opportunities for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Cambridge Spark are based on business needs, job requirements and individual qualifications, without regard to race, colour or ethnicity, ability or disability, gender or gender reassignment, sexual orientation, marital status, religion, age or any other status protected by the laws or regulations in the locations where we operate. Cambridge Spark will not tolerate discrimination or harassment based on any of these characteristics. Cambridge Spark encourages applicants of all ages.

Powered by JazzHR

qbla4dRTKO",Cambridge,GB,2023-12-19 23:39:00,http://www.bdo.com,Consulting
40,FULLTIME,"Data Analyst, Management Data Analysis",https://uk.linkedin.com/jobs/view/data-analyst-management-data-analysis-at-national-grid-3790082248,"About Us

National Grid touches the lives of almost everyone, with an energy network that stretches across the Atlantic. We’re an international team, and our work underpins the lives of millions of people. Feet forwards, head up, and eyes bright, we’re working hard to create value for people today – and shape the future of energy tomorrow.

In the UK, we don’t generate or sell energy – we join the dots to get energy from A to B. From making a cup of tea in the morning, to keeping the lights on in hospitals, our electricity network puts power in the hands of people. Without it, the world as we know it would grind to a halt.

The world of energy is changing beyond recognition. Working at National Grid, you won’t just be touching the lives of almost everyone in the UK – you’ll be shaping the way we use and consume energy for generations to come.

Job Purpose

Joining our Global People Analytics team, you will play an integral role enabling National Grid to keep pace in the rapidly changing energy sector by growing our workforce and organisational capability and empowering our people for great performance. Within our innovative and collaborative team, we appreciate our people, celebrate diversity, cultivate an inclusive environment and have fun too, as we deliver value for National Grid and the communities we serve.

People Analytics is one of the fastest growing HR disciplines. We are responsible for workforce data, reporting, analytics and workforce planning. We provide critical people insights on diversity, talent, recruiting, learning, reward, head count, attrition, among many others where we trend, forecast, translate and communicate people data into actionable insights for our stakeholders and clients.

As a People Analytics Analyst you will translate and communicate people data into insights that will drive decision making relating to all thing’s ‘people’. As the ideal candidate you will have analytical and consultative skills and thrive managing concurrent projects while working within a global team to drive value driven outcomes.

Key Accountabilities
• Contribute in delivering HR analytics capabilities that drive insight and predictability through people and organizational data which enable leadership and decision-making
• Serve as a thought partner to support a wide array of stakeholders and consumers of people analytics on HR data, insights, trends, forecasts and workforce centric issues informed by data
• Utilize analytics providing quantitative findings and other inputs providing trending, forecasting, among other techniques to derive insights and comprehensive recommendations
• Support in delivery of ad-hoc analytics requests applying creative data visualization, and communication that will translate data and subject matter into actionable and consumable insights for stakeholders and clients
• Support delivery of Power BI solutions as part of our exciting digital transformation to deliver automated people analytics products that will improve standardization, efficiency, team performance and client self-service capability
• Support capability growth, ‘demystifying’ people data and analytics across community of HR Professionals and the Business, developing skills, knowledge and confidence that will enable business planning and decision making to be informed by people data

Technical / Specialist Skills And Experience
• 2+ years’ experience working as a data analyst, or similar role with advanced Excel and Power Point expertise
• Preferred knowledge of Power BI and/or Tableau with SQL, Alteryx expertise
• Experience extracting and manipulating data from large enterprise data platforms and/or HR systems
• Basic understanding of modelling, scenarios and correlations analysis
• Experience making cohesive reports and structuring data from disparate sources, able to provide data visualization and to message analytics subject matter
• Ability to effectively communicate and interact with business stakeholders to discuss and explain analytics to non-technical stakeholders
• Attention to detail and commitment to accuracy of results, especially in times of rapid turn-around needs
• Demonstrated judgment and discretion when dealing with highly sensitive people data
• Practiced at developing working relationships quickly and effectively across an organisation and thriving in a collaborative team environment

Qualifications
• Degree level qualification in a quantitative or Industrial Organizational Psychology, Management Information Systems, Business or Data Analytics or related qualifications
• Prior 2+ years work experience in an Analytics role
• Prior HR Analytics or related experience strongly desired
• Proficient in Excel, ETL tools and techniques, Power BI and/or other reporting data manipulation tools

More Information

A competitive salary between £39,000 – £48,000 – dependent on capability

As well as your base salary, you will receive a bonus based on personal and company performance and a competitive contributory pension scheme where we will double match your contribution to a maximum company contribution of 12%. You will also have access to a number of flexible benefits such as a share incentive plan, salary sacrifice car and technology schemes, support via employee assistance lines and matched charity giving to name a few.

At National Grid, we work towards the highest standards in everything we do, including how we support, value and develop our people. Our aim is to encourage and support employees to thrive and be the best they can be. We celebrate the difference people can bring into our organisation, and welcome and encourage applicants with diverse experiences and backgrounds, and offer flexible and tailored support, at home and in the office.

Our goal is to drive, develop and operate our business in a way that results in a more inclusive culture. All employment is decided on the basis of qualifications, the innovation from diverse teams & perspectives and business need. We are committed to building a workforce so we can represent the communities we serve and have a working environment in which each individual feels valued, respected, fairly treated, and able to reach their full potential.",Warwick,GB,2023-12-19 19:43:00,http://www.nationalgrid.com,Utilities
41,FULLTIME,Data Engineer,https://gb.bebee.com/job/20231220-ff04a8e2fe326d4e57729cbfba9679bd,"Data Engineer

We're looking for a Data Engineer to join our IT Systems Integration team in Leighton Buzzard or Milton Keynes supporting our business and IT departments. This role will be an expansion to an already existing well established team of DBAs/Engineers and Analysts ready to support the Group's expansion.

You will be working with some very talented people who are always looking to move forward with the latest and greatest technology, this role will demand great attention to detail and an analytical mind-set. It will be a chance for someone who is looking to get into the data world or expand on their analytical knowledge and mind-set with a new challenge.

Key responsibilities of the Data Engineer:
• Building data models of unknown structured data of third-party systems.
• Developing processes documentation for operational ETL systems integrations.
• Analysing data structures to build MI models for consolidation projects.
• Understanding and maintaining data quality of system and operational databases.
• Support ad-hoc report generation or data extracts via T-SQL queries.
• Responsible for managing all IT Operational Service reporting in SSRS and PowerBI.
• Understanding and aligning the group JML process.
• Manage and maintain the group GDPR data processes.
• Interpret written functional requirements and technical specification documents and translate into reporting deliveries.
• Manage the IT Operational Data Warehouse and develop new schema for additional systems.

Experience & skills required to be successful as an Operational Data Analyst:
• Data Analytics skills.
• Understanding complex JML processes.
• T-SQL skills.
• Understanding of Database management
• Experience with SQL Server Reporting Services (SSRS) and SQL Server Integration Services (SSIS).
• Advanced Microsoft Excel skills.
• Knowledge of data warehousing and different schema methodologies.

Desirable skill of the Operational Data Analyst :
• Understanding of advanced bespoke T-SQL data collection solutions.
• Exposure to MySQL & Oracle.
• Experience with SSIS and ETL Processing.
• Functional knowledge of SSAS and multi-dimensional analytical development.
• DBA/DBD operational experience.

Connells Group is one of the largest and most successful estate agency and property services providers in the UK and as of March also encompasses Countrywide. Founded in and with a network of over 1, branches nationwide, the Group combines residential sales and lettings expertise with a range of consumer and corporate services including new homes, mortgage services, conveyancing, EPC provision, surveying, corporate lettings, asset management, land & planning, LPA receivers and auctions.

Connells Group UK is an equal opportunities employer and positively encourages applications from suitably qualified and eligible candidates regardless of sex, race, disability, age, sexual orientation, transgender status, religion or belief, marital status, or pregnancy and maternity.",Milton Keynes,GB,2023-12-20 02:06:00,http://www.countrywide.co.uk,Finance
42,FULLTIME,Data Engineer (Scala),https://uk.linkedin.com/jobs/view/data-engineer-scala-at-signify-technology-3787691503,"Role: Data Engineer (Scala)

Location: London (Hybrid 1-2 days)

Job Type: Permanent

Salary: Up to £90,000

Unable to offer sponsorship

Signify Technology is working with a fraud prevention company whose products process high volumes of data with the aim of detecting and preventing fraud and other financial crime. To achieve this they have developed a state of the art platform which detects anomalous and suspicious activity.

Responsibilities:
• Thriving in a dynamic, Agile workplace
• Handling data processing/ETL pipelines
• Analyzing and dissecting diverse and real-world data
• Engaging in full-stack development, with a strong emphasis on data processing/ETL
• Tackling challenging problems through efficient, robust, and high-impact code
• Operating in the cloud with production-ready systems
• Defining and disseminating best practices and the knowledge you've cultivated
• Nurturing your career in one of the UK's fastest-growing scale-up companies

Requirements
• Proven experience with Scala.
• Big data experience
• Knowledge of big data technologies such as Spark and Hadoop.
• Experience working in Agile environments.
• Cloud experience, ideally with GCP.
• Ability to work in the UK without requiring sponsorship

For more information, please apply or contact me - euan.roche@signify-tech.com",London,GB,2023-12-19 11:04:00,http://www.signifytechnology.com,Consulting
43,FULLTIME,Google DevOps / Data Engineer - London - Financial Services,https://www.investigo.co.uk/job/google-devops-slash-data-engineer-london-financial-services,"Role: Google DevOps / Data Engineer

Location: Central London (Liverpool Street)

Rate: £800 inside IR35

Start: Jan

We are looking for a Google DevOps / Data Engineer to join out financial service client for a January start. You'll need to be able to attend their London office 3 days per week.

They're looking for someone to support their move away from KDB to Google native technologies, with experience in:
• Google Dataflow (Essential)
• GCE/GKE (Essential)
• Google BigQuery (Essential)
• Argo (Nice to have)
• Terragrunt (Nice to have)
• Google Looker (Great bonus)

If this sounds like you, or someone you know, please reach out.",London,GB,2023-12-19 11:32:00,http://www.bdo.com,Consulting
44,FULLTIME,"Splunk Data Engineer, Security",https://findajob.dwp.gov.uk/details/13653108,"Join us as a Splunk Data Engineer, Security
• This is an opportunity for a technically minded individual to join us in Security as a Splunk Data Engineer.
• You’ll be the voice of our customers, using data to tell their stories and put them at the heart of all decision-making
• We’ll look to you to drive the build of effortless, digital first customer experiences
• If you’re ready for a new challenge and want to make a far-reaching impact through your work, this could be the opportunity you’re looking for

What you'll do

As a Splunk Data Engineer, you’ll be looking to simplify our organisation by developing innovative data driven solutions through data pipelines, modelling and ETL design, inspiring to be commercially successful while keeping our customers, and the bank’s data, safe and secure.

You’ll drive customer value by understanding complex business problems and requirements to correctly apply the most appropriate and reusable tool to gather and build data solutions. You’ll support our strategic direction by engaging with the data engineering community to deliver opportunities, along with carrying out complex data engineering tasks to build a scalable data architecture.

Your responsibilities will also include:
• Building advanced automation of data engineering pipelines through removal of manual stages
• Embedding new data techniques into our business through role modelling, training, and experiment design oversight
• Delivering a clear understanding of data platform costs to meet your departments cost saving and income targets
• Sourcing new data using the most appropriate tooling for the situation
• Developing solutions for streaming data ingestion and transformations in line with our streaming strategy

The skills you'll need

To thrive in this role, you’ll need a strong understanding of data usage and dependencies and experience of extracting value and features from large scale data. You’ll also bring practical experience of programming languages alongside knowledge of data, data warehousing, data modelling capabilities and software engineering fundamentals.

Additionally, you’ll need:
• Experience of ETL technical design, data quality testing, cleansing and monitoring, data sourcing, and exploration and analysis
• A good understanding of modern code development practice and experience of working in a governed, and regulatory environment
• Strong communication skills with the ability to proactively engage and manage a wide range of stakeholders
• Experience in using Splunk 8 or 9 in a clustered environment and developing user cases
• An understanding of working on technology projects and using technology change management processes
• Knowledge of working in an agile way and using tools like AgilePlace to manage work",London,GB,2023-12-20 00:00:00,http://www.natwestgroup.com,Finance
45,FULLTIME,Data Analyst,https://uk.linkedin.com/jobs/view/data-analyst-at-malaberg-3789897563,"We're hiring the very best quantitative analysts to join our agile in-house team. You will be working on the fastest growing direct to consumer (e-commerce) brands and will have access to unlimited performance bonus.

What You'll Be Doing
• Launch and optimize social and search advertising campaigns
• Improve Conversion Rate across multiple funnels - multivariant and A/B testing
• Design new funnels and analyse granular data using proprietary data warehouse
• Manage unlimited budget while staying profitable. Compensation is directly correlated to your personal campaign performance and paid monthly
• Optional managerial roles available

What You'll Need
• Results-driven and numbers-oriented personality
• High attention to detail
• Flexibility and adaptability
• Commitment to innovations

A little about us

We're passionate about building life changing consumer products and delivering them with astonishing service. We are also one of the UK's fastest growing direct to consumer companies.

The Benefits
• Salary above market
• All the latest tech you need
• Pension plan",London,GB,2023-12-19 13:09:00,http://www.bdo.com,Consulting
46,FULLTIME,Data Analyst,https://www.recruit.net/job/data-analyst-jobs/DAAED20F32D674E9,"Data Analyst (Integrations)

Must NOT require any form of sponsorship and Hold Full Right to Work in the UK.

Salary - Up to £55,000 DOE

Client Overview: Our client is an Award Winning Software Solutions Provider who specialise in providing services to the Legal Sector.

The Data Analyst will specialize in developing integrations between our platform and third-party applications. This customer-facing role involves assisting clients in designing, developing, and maintaining business intelligence solutions, creating innovative reporting tools and dashboards, and supporting data migration activities.

We are seeking a disciplined thinker capable of thriving in a high-output environment. The ideal candidate possesses outstanding organizational, communication, and presentation skills, with a keen eye for detail while maintaining a broader perspective. Proactivity, adaptability, and a results-driven mindset are essential, along with the ability to work collaboratively, under pressure, and take initiative to meet deadlines.

CORE RESPONSIBILITIES

As a member of the Data Services team, you will be responsible for:
• Developing, testing, and maintaining integration and ETL interfaces between our platform and third-party applications.
• Writing custom scripts for data transformations to meet data model requirements.
• Designing, developing, and maintaining business intelligence solutions.
• Crafting and executing queries upon request for data and presenting information through reports and visualizations.
• Collaborating with consultants and customers to enhance their product experience through the creation of bespoke innovative reports and dashboards, providing actionable business intelligence.
• Assisting Senior Data Services Analyst with ongoing optimization of technology tools, scripts, and documentation supporting migration and integration processes.
• Communicating effectively with all stakeholders involved in the project, including clients, third-party partners, and internal staff.
• Analysing data issues and implementing resolutions.
• Operating our data migration tools to produce working platform systems.
• Producing migration scope documents and mapping schema detailing migration transformation processes into our platform.

Supplementary responsibilities:

As required, supporting the Data Services team to migrate customer data from their existing legacy system to our platform. This includes operating our highly developed data migration tooling to produce a working system from customers' source data.

KNOWLEDGE & SKILLS REQUIRED

Essential:
• In-depth knowledge in own discipline and basic knowledge of related disciplines.
• Integration – delivering solutions to customers using Microsoft tools (ADF, Logic Apps, Power Automate, and SSIS).
• Data migration experience.
• Client-facing role experience.
• Problem-solving skills and the ability to take a new perspective on existing solutions.
• Excellent working knowledge of database structures, particularly T-SQL.
• Experience with API protocols.
• Data visualization and data warehousing experience.
• Proven experience with the extraction, transformation, and loading of data from various sources.
• Strong planning and organizational skills.
• Can-do attitude and a commitment to providing a great customer experience.
• Strong work ethic and willingness to work extended hours as required.
• Embraces new technology and engages in continuous professional development to maximize opportunities for our customers.

Desired:
• Knowledge of MS Dynamics, Power BI, PowerShell, JSON, and Visual C#.",Birmingham,GB,2023-12-20 00:00:00,http://www.bdo.com,Consulting
47,FULLTIME,Data Analyst,https://uk.linkedin.com/jobs/view/data-analyst-at-partner-group-3788142218,"Data Analyst

Up to £35,000 + benefits

London

Digital Agency

Partner Financial are supporting a Global Digital Agency with a strong foothold in the global market. The business has continued to be successful, growing their international presence over the years, and they are currently looking to appoint a Data Analyst to join their Global Data and Analysis team.

The successful candidate will be joining a key team for the business, in charge of collecting, analysing, and delivering global reports for the business, providing an excellent understanding of international markets. The opportunity would be well suited for someone who enjoys working with data and taking an analytical approach to solving problems and creating insights.

The key responsibilities will include:
• Liaising with Business stakeholders and supporting the team in building analytical solutions and insights.
• Working towards understanding trends in their perspective markets and providing consistent reporting and analysis support.
• Providing support in collecting and reviewing data from reporting companies.
• Delivering various ad-hoc support for whatever is needed across the team.
• Troubleshooting data discrepancies; resolving and articulating them.

The ideal Candidate:
• Excellent academic background
• Previous experience of working in an analytical position.
• Comfortable dealing with high volumes of information and data and ability to extract insights out of them.
• Highly inquisitive and organised with the ability to work to work on multiple pieces of work, with multiple deadlines.
• Passion for the industry and genuine interest to have a career with the business.

Interested candidates should send their CV to Vas Karadimas. I will be contacting candidates with the closest match to the client’s selection criteria within 10 working days of application to arrange an initial meeting. If you have not heard from me within these timescales, thank you for your interest but please consider your application unsuccessful on this occasion. If you would like to have a confidential discussion about your current situation then please feel free to give us a call to discuss.",London,GB,2023-12-19 16:37:00,http://partnerfinancial.co.uk,Consulting
48,FULLTIME,Lead Data,https://gb.bebee.com/job/20231219-8de02fbb7d6aeebd3838f310c1257de1,"My client are looking for a talented and motivated Consulting Analytics Manager to help execute the data literacy strategy across the business by enabling self-service dashboard access on curated data.
The team combines data analytics & business reporting with financial planning and profitability.

They have a wide range of responsibilities which includes company-wide business intelligence, pricing, forecasting, commercial finance, reporting, dashboard development and risk management for various business units.
Strong Tableau and Python experience
Strong Data modelling skills
Excellent + bonus + package

Location:
London (good work from home options available)

If you are interested in this Consulting Analytics Manager position and meet the above requirements please apply immediately.",London,GB,2023-12-19 16:06:00,http://www.bdo.com,Consulting
49,FULLTIME,Senior Data Science Exploitation Analyst,https://careers.axa.com/de/de/job/AXGRGLOBAL230005VYYESTALEOENEXTERNALDEDE/Senior-Data-Science-Exploitation-Analyst,"We’re looking for an experienced and enthusiastic person to join us in AXA Retail’s Pricing department as a Senior Data Science Exploitation Analyst. In this role you'll seek out new data sources that will add predictive value to our pricing algorithms across all our Home and Motor products, testing their power, and supporting the delivery of these sources into analytical and production environments. You’ll also add additional business value by reviewing and enhancing existing data sources alongside the assessment of new data sources. If you’re curious, driven, and passionate about driving value through data then we encourage you to apply!

At AXA we work smart, empowering our people to balance their time between home and the office in a way that works best for them, their team and our customers. You'll work at least 40% of your week away from home, either at one of our office locations, visiting partners or attending industry events.

What you’ll be doing:
• Help to shape the direction of our data enrichment processes with a forward-looking approach and willingness to experiment
• Identify novel ways of using existing data for the creation of new modelling features
• Lead the development of modelling tools and metrics to assess the value of new data sources
• Support the maintenance and categorisation of production data used in pricing
• Contribute to the development of current data pipelines
• Assist with the governance and contractual aspects of acquiring and managing data sources
• Proactively develop your data handling skills and knowledge, and support the development of others

Due to the number of applications we expect to receive for this role, we reserve the right to close this advert earlier than the listed closing date to ensure we’re able to effectively manage interest. Therefore, if you’re interested in joining us at AXA, please don’t hesitate to apply.

Your Profile

What we’re looking for:
• Relevant academic or professional experience in the data science or data engineering space
• Critical and analytical approach to problem structuring
• Ability to continually learn and develop
• Strong drive to deliver and comfortable collaborating in a team
• Knowledge of data engineering and data science in general with demonstrable practical skills
• Self-sufficient in working through analytical projects from idea to results phases
• Experience working with Git would be advantageous

As a precondition of employment for this role, you must be eligible and authorised to work in the United Kingdom.

About AXA

With a presence in over 60 countries, and 165,000 employees serving the needs of 107 million customers, AXA is big.

But never too big to care for every single person who works here. So when you join us, we promise to put our collective might behind you and your career.

You’ll work in an open and supportive environment where you’ll be developed, challenged and encouraged to move around to achieve even bigger and better things – nationally and internationally. You’ll learn directly from senior leaders, from the best in our business. And you’ll enjoy real responsibility, really early on.

Every large company today talks about supporting diversity and inclusion. But at AXA UK, these values form an integral part of everything we do. For us, it’s about bringing together the best talent, helping people to realise their full potential by being 100% themselves at work and delivering outstanding service to everyone – regardless of difference.

About the Entity

AXA Retail helps people live the life they love, knowing we’ve got their back, at home and on the road. Our people are vital to us becoming more digital, faster and easier to access. We’re a dynamic team of experts completely committed to making sure our customers ‘get back to the good stuff’ when the unexpected happens.

What We Offer

At AXA UK, we’re appreciative of the people who work for us and our rewards package is reviewed regularly to reflect that. You can expect to receive:
• Competitive annual salary
• Annual company & performance-based bonus
• Contributory pension scheme (up to 12% employer contributions)
• Life Assurance (up to 10 x annual salary)
• 25 days annual leave plus Bank Holidays
• Opportunity to buy up to 5 extra days leave or sell up to 5 days leave
• AXA employee discounts
• Gym benefits

To apply, click on the ‘apply for this job’ button, you’ll then need to log in or create a profile to submit your CV. We’re proud to be an Equal Opportunities Employer and don’t discriminate against employees or potential employees based on protected characteristics. If you have a long term health condition or disability and require reasonable adjustments during the application or interview process, we’re proud to offer access to the AXA Accessibility Concierge. For our support, please send an email to leanne.white@axa-insurance.co.uk.

#LI-Hybrid",London,GB,2023-12-20 00:00:00,http://www.axa.com,Finance
50,FULLTIME,DATA ENGINEER,https://uk.linkedin.com/jobs/view/data-engineer-at-grupo-fcamara-3790476849,"FCamara UK is looking for a new person to join our team in the role of Data Engineer to work with us on one of our projects in the banking area.

Responsabilidades e atribuições

Responsibilities:
• Develop, construct and maintain a Datawarehouse for Bank.
• Collaborate with development teams to find which data can be gathered, and how the data is going to be synchronized.
• Recommend and implement ways to improve data reliability, efficiency, and quality.
• Communicate directly with UK Bank stakeholders
• Conduct research for industry and business questions.

Requisitos e qualificações

Hard Skill:
• SQL Server (5+ years)
• Datawarehouse (3+ years)
• Microservices (3+ years)
• Power BI (2+ years)
• English C1 (advanced conversation for direct interaction with the customer from England)

Soft Skill:
• Protagonism
• Quality orientation
• Strong problem-solving
• Communication skills

Informações adicionais

TRANSFORMAMOS MUNDOS SONHADOS EM TRAJETÓRIAS REAIS.    

Aqui somos #SangueLaranja!

Estamos há 16 anos no mercado, lado a lado com nossos clientes, proporcionando experiências transformadoras.

Somos um ecossistema de tecnologia e inovação, com expansão global; atuamos no Brasil, Portugal e Reino Unido.   

F de Formação: acreditamos na prática da cultura do compartilhamento, no senso de comunidade, e que o conhecimento

tem o poder da transformação!

Possuímos iniciativas, e ações sociais, que promovem o desenvolvimento, como a comunidade tech Orange Juice, o Programa de Formação,

nossa escola de liderança e diversas parcerias com ONGs e Edtechs.

Na FCamara todos são bem-vindos, para nós, Diversidade, Respeito e Ética, são elementos inegociáveis e fazem parte do nosso DNA.

E aí, está pronto para fazer parte de um time incrível e ser protagonista da própria história?",London,GB,2023-12-20 04:09:00,http://www.bdo.com,Consulting
51,FULLTIME,Data Engineer,https://onlydatajobs.com/job/299039/Data-Engineer-Greater-London-London,"Description

Job Title: Data Engineer

Location: London

Reporting To: Head of Data & Analytics

Who we are

At Monica Vinader, we're on a mission to prove that buying better, wearing longer and doing better don't have to be mutually exclusive. From our commitment to making the most sustainable jewellery we can using precious materials, to the timeless style and endless versatility of our pieces, we are driven to making everyday fine jewellery accessible and affordable.

And don't just take our word for it, we are proud to be recognised in the industry through our recent awards, proving we are leading the way in sustainable jewellery:
• Ethical/Sustainable Jewellery Business of the Year 2021 & 2023, Retail Jeweller
• Jewellery Brand of the Year 2023, Retail Jeweller
• Queen's Award for Enterprise: Sustainable Development 2022
• Responsible Luxury Business of the Year 2023 & 2022, Positive Luxury

We are digital first, omni-channel, customer obsessed, female led and inclusive, focused on creating meaningful relationships with our community, who we owe our success to. We are looking for someone special to join our team to help us make luxury something we can all enjoy everyday.

Where we need your help

We have all the makings of an iconic brand - beautiful products that are timeless and designed to last, service that exceeds our customers expectations, a passionate founder that cares deeply about doing what is right and a loyal and growing community who advocate for us.

As a Data Engineer you will play a crucial role in leveraging data and technology to enhance business efficiency, scale, and customer experience. We are on a mission to empower our teams through data-driven decision-making, and you will be instrumental in building and improving systems, solving complex problems, and ensuring the availability and quality of our data. You will collaborate closely with various teams, utilising your expertise in data engineering to drive commercial value and support our business initiatives.

What you'll do

Data Platform & Infrastructure:
• Design, build, and maintain our data architecture from conceptual through to physical data models.
• Implement and iterate data extraction and ingestion processes from multiple systems and platforms to ensure quality data exists within our enterprise GBQ Data Warehouse.
• Evaluate ETL processes in line with best practices to optimise performance efficiency, as well as contributing to the evolution of the data stack as a whole.
• Establish quality processes and diagnostics for the proactive identification of quality issues and data anomalies alongside prioritisation and resolution of service desk tickets.
• Collaborate with relevant teams to set up and govern reverse-ELT processes e.g to support Growth Marketing segmentation and experimentation.

Modelling and Analysis:
• Collaborate with teams to translate business requirements into structured models and datasets fit for analysis and reporting.
• Automate data pipelines for repetitive reporting and analysis processes.

Data governance and Improvement:
• Ensure documentation is up to date and accessible to stakeholders.
• Identify opportunities for data and analytic methodology improvements.
• Proactively recommend and implement enhancements to drive efficiency.

What you'll bring
• Highly proficient in data architecture, SQL, data modelling, and ELT/ETL processes (dbt a plus).
• Experience with modelling behavioural event based datasets for customer and web analytics.
• Use of platforms such as GA4, Bloomreach CDP, Advertising Platforms to conduct ETL and reverse-ETL via various pipelines including tools such as Fivetran and Census.
• Experience surfacing data models into tools such as Sigma, Looker Studio, Google Sheets.
• Ideally one other programming language (e.g., Python).
• Growth mindset with the ability to gather requirements effectively from business stakeholders.
• Proven experience in a similar data engineering role in a dynamic environment.

To be successful at Monica Vinader...
• You are a doer
• You're a team player
• You're humble
• You are honest, straightforward and transparent
• You are a good teacher/mentor (approachable and accessible)
• You want to get your hands dirty
• You solve problems
• You are resilient
• You are flexible
• You are entrepreneurial, smart, and passionate
• If you don't know something, you say so. Then go figure it out quickly
• You love working in a creative environment
• You have a sense of humour
• You are an insatiable learner

Additional Requirements

Ability to document your authorisation to work in the United Kingdom.

Travel Requirements

Regular travel to our London office may be required.

Our Aims and Values

Our mission is to be the leading accessible luxury brand, by delivering outstanding quality, design and customer service. We are:

Customer Obsessed

Our customers are at the core of everything we do. We will always deliver an outstanding and personal experience to them every time they interact with us, to ensure their ongoing support and loyalty.

Caring

We treat people with respect, as we would want to be treated. We are apolitical and assume good intentions in others. We are open and honest with each other while ensuring we take an empathetic and supportive approach.

Fast Paced

We are passionate about what we do, and we want to reach as many customers as fast as we can. We combine focus with pragmatism and flexibility so that we can move at pace in whichever direction we need to take.

Exceptional

We have a relentless desire to continually learn and improve to ensure our products and approach are exceptional. Our tenacity, high standards and attention to detail give us a competitive advantage.

Commercial

We focus hard on facts and approach things in a logical, rational and analytical way. We challenge each other to make sure we make decisions and take actions that create value for our business and our customers.

Monica Vinader as a global business makes the following inclusive culture pledge:
Our jewellery is for everyone and so is our community. Together, we will continue to implement sustainable changes to ensure that career opportunities and progression are open to all. We commit to celebrating the diverse voices of our employees, partners, and the customers we serve.

This job description is not intended to be an exhaustive list of duties to be performed by the employee. This job description may be altered to reflect the business needs of the company.

Monica Vinader Ltd, Holkham Studios, Longlands, Holkham Park, Wells-next-the-Sea,
Norfolk, NR23 1SH

www.monicavinader.com

Page 1 of

At Monica Vinader, we're on a mission to prove that buying better, wearing longer and doing better don't have to be mutually exclusive. From our commitment to making the most sustainable jewellery we can using precious materials, to the timeless style and endless versatility of our pieces, we are driven to making everyday fine jewellery accessible and affordable. We are digital first, customer obsessed, female led and inclusive, focused on creating meaningful relationships with our community, who we owe our success to. We are looking for someone special to join our team to help us make luxury something we can all enjoy everyday.Further information is available at www.monicavinader.com",London,GB,2023-12-19 11:34:00,http://www.monicavinader.com,Retail
52,FULLTIME,Senior Data Scientist / Machine Learning Engineer,https://www.cv-library.ie/job/1258000000000229449/Senior-Data-Scientist-Machine-Learning-Engineer,"Job Description

This is an exciting opportunity for a Machine Learning Engineer / Data Scientist to deliver high-value analytics solutions for Version 1 customers. This provides a unique opportunity for people who are passionate about technology and have a deep commitment to code quality and best practices to build something special and make a real difference to our business and to our customer’s business.

You will have strong experience in building solutions using a variety of open-source tools based on Python and Spark with a proven track record in delivering high-quality work to tight deadlines.

The role will require a Machine Learning Engineer / Data Scientist with excellent communication skills, who is willing to continuously learn and listen. Creative problem-solving and a keen understanding of how predictive analytics can be leveraged in business processes are a must. We’re looking for a Machine Learning Engineer / Data Scientist who is inherently curious, driven, willing to learn & and develop, with an owning the problem and a self-starter attitude.",London,GB,2023-12-19 15:12:00,http://www.version1.com,Computer Services
53,FULLTIME,"Splunk Data Engineer, Security",https://findajob.dwp.gov.uk/details/13653110,"Join us as a Splunk Data Engineer, Security
• This is an exciting opportunity for a technically minded individual to join us in Security as a Splunk Data Engineer
• You'll use your technical expertise to collaborate with colleagues and build effortless, digital first customer experiences
• You’ll be simplifying the bank by developing innovative data driven solutions, using insight to be commercially successful, and keeping our customers’ and the bank’s data safe and secure
• Participating actively in the data engineering community, you’ll deliver opportunities to support the bank’s strategic direction while building your network across the bank

What you'll do

As a Splunk Data Engineer, you’ll play a key role in driving value for our customers by building data solutions. You’ll be carrying out data engineering tasks to build, maintain, test and optimise a scalable data architecture, as well as carrying out data extractions, transforming data to make it usable to data analysts and scientists, and loading data into data platforms.

You’ll also be:
• Developing comprehensive knowledge of the bank’s data structures and metrics, advocating change where needed for product development
• Practicing DevOps adoption in the delivery of data engineering, proactively performing root cause analysis and resolving issues
• Collaborating closely with core technology and architecture teams in the bank to build data knowledge and data solutions
• Developing a clear understanding of data platform cost levers to build cost effective and strategic solutions
• Sourcing new data using the most appropriate tooling and integrating it into the overall solution to deliver for our customers

The skills you'll need

To be successful in this role, you’ll need a good understanding of data usage and dependencies with wider teams and the end customer, as well as experience of extracting value and features from large scale data. Understanding of working on technology projects and using technology change management processes

You’ll also demonstrate:
• Experience of ETL technical design, including data quality testing, cleansing and monitoring, and data warehousing and data modelling capabilities
• Good knowledge of modern code development practices
• Strong communication skills with the ability to proactively engage with a wide range of stakeholders
• Experience in using Splunk 8 or 9 in a clustered environment and developing user cases
• Experience of using programming languages alongside knowledge of data and software engineering fundamentals
• Knowledge of working in an agile way and using tools like AgilePlace to manage work",Bristol,GB,2023-12-20 00:00:00,http://www.natwestgroup.com,Finance
54,FULLTIME,Senior Data Engineer,https://uk.linkedin.com/jobs/view/senior-data-engineer-at-hcltech-3789883211,"Highly organized, Cloud Data analytical and experienced Big data engineer with overall 7+ years of hands-on experience in the areas of Cloud Data & Big data components Design, Development and Solution implementation apart from HMI applications development and Data migration experience includes

8 years. Hands-on experience in Data Engineering, Data Governance, data modelling (logical & physical), designing end to end data pipelines which includes, Data Ingestion, Data Transformation, Data profiling, Data Assurance, Data Warehousing and ETL programming, streaming and performance tuning of big data pipelines. Solid understanding of traditional infrastructure, applications, data landscape and migration of data intensive applications from on-premises Data sources like SQL, Oracle, SAP, Office one drive, SharePoint and data warehouses, data marts to cloud environments.

7+ years of programming experience using Cloud Data engineering Python, PySpark, Azure Data Lake Storage blob, Gen1, Gen2, DBFS, Autoloader, Delta Live Tables, Delta format files, Azure Databricks, Azure Data Factory, Azure Synapse Analytics, Event Grid, Azure Cosmos, Azure SQL, Azure HDInsight and Azure DevOps CI/CD and development. Good exposure and project implementations using Hadoop, HDFS, Spark, Hive, Phoenix, HBase, Scala, Kafka, Oozie, Yarn and Linux/Unix Shell scripting Has good exposure to agile software development methodologies (TDD, Scrum, Sprints, Peer programming) and Agile Project management and Code collaboration tools like GitHub, Jenkins, Nexus, Azure Repos and team collaboration tools like Confluence and Jira. Good exposure on Micro services, container and server less technologies Docker, Kubernetes and infrastructure as code – Terraform",Leeds,GB,2023-12-19 11:59:00,http://www.hcltech.com,Computer Services
55,FULLTIME,Public Cloud - Compute and Storage Engineer - SVP (Hybrid),https://onlydatajobs.com/job/256251/Public-Cloud-Compute-Storage-Engineer-Svp-Hybrid-Greater-London-London,"The Compute and Storage Engineer will be instrumental in implementing the architecture and the engineering processes and best practices to enable the foundational infrastructure (compute, network, storage, observability) required for application hosting in public cloud. This role is responsible for all infrastructure segments from hardware selection, operating systems and virtualization layers to cloud management tooling, monitoring, and orchestration. The ideal candidate has experience in professional software development, designing and creating highly available cloud systems, and has the ability to implement cloud strategy. Advanced industry knowledge is key, as well as knowledge in building an engineering organization. The role requires a talented technologist with experience engaging with application developers throughout the full development life-cycle - from inception and design to deployment, operation, and iterative development.

Responsibilities:
• Provide foundational infrastructure for public cloud (compute, storage, network)
• Deliver the tooling and capabilities needed to enable our cloud first strategy
• Provide developer-friendly cloud onboarding, account creation and management for supported cloud providers
• Provide o11y products like ELK, Elasticsearch, Kibana, Prometheus, etc. to engineering teams for centralized logging, APM tooling, monitoring and alerting
• Ensure compliance to regulations and policy by implementing accurate requirements traceability
• Provide cloud network services to enable a fast and resilient hybrid cloud with built in security capabilities
• Develop, cascade and enforce engineering best practices using modern SDLC that enables CI/CD and favors automation, auditability, automated testing, infrastructure and policy as code
• Provide technical leadership in the design of highly complex cloud systems
• Develop and advocate for new cloud native solutions to undefined system needs, where no solution is available within the technical community
• Drive client satisfaction by identifying and developing process improvement and automation initiatives while ensuring compliance of solutions to operations roadmap

Basic Qualifications
• Undergraduate degree in related field or equivalent experience
• Hands on experience developing and engineering software and consumer facing applications
• Experience developing and scaling JAVA REST services, using frameworks such as Spring
• Experience in modern microservices architectures and deployments
• Experience working in a distributed, cloud-based environment using Azure/AWS/GCP (Docker/Kubernetes)
• Experience with cloud infrastructure and data services (compute, storage, networking and others)
• Experience with Infrastructure as Code (IaC) practices and frameworks
• Experience working with cloud-based relational and NoSQL databases
• Experience with Test Driven Development (TDD) and test automation using unit testing and behavioral testing frameworks
• Familiarity with devops and SRE practices
• Experience with modern SDLC tools, branching strategies, and ability to develop and enforce CI/CD practices
• Familiarity with Domain Driven Design and Event Driven Architectures
• Knowledge of front-end stack, best practices, frameworks and overall architecture
• Strong analytical skills
• Strong collaboration and interpersonal skills
• Experience working with Linux/UNIX, Docker

Preferred Qualifications
• Experience as an AWS Solutions Architect, Cloud Security Certification, and/or OpenStack Administrator Certification a plus. (Other cloud-related certification also a plus.)
• Experience with TDD and automated UI testing frameworks
• Experience working with any design frameworks
• Developer level operations proficiency - knowledge of networking, familiarity with load balancers, hypervisors, CDNs, etc

Job Family Group:
Technology

Job Family:
Systems & Engineering

Time Type:
Full time

Citi is an equal opportunity and affirmative action employer.

Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Citigroup Inc. and its subsidiaries (""Citi"") invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.

View the ""EEO is the Law"" poster. View the EEO is the Law Supplement.

View the EEO Policy Statement.

View the Pay Transparency Posting",London,GB,2023-12-19 11:36:00,http://www.citigroup.com,Finance
56,FULLTIME,GCP Data Engineer,https://gb.bebee.com/job/20231220-78bd1316e258a8a4eb979fd2c98c8305,"We are seeking an experienced Agile Scrum Master to join one of our clients who are in the media and broadcasting space.

This will be joining their cloud-based project team to facilitate the scrum processes and enable the team to continuously improve and deliver high quality products.
Provide overall guidance on scrum best practices and agile values for the team.
• Facilitate sprint planning, daily standups, reviews, and retrospectives.
• Work on data engineer/and or analyst delivery tasks as well.
• 3+ years' experience as Scrum Master or similar agile facilitator role.
• 3+ years' experience as Data Engineer or Data Analyst.
• Experience working with technical teams like data engineers, analysts, or data scientists.
• Strong understanding of scrum values, principles, and practices.
•",London,GB,2023-12-20 00:09:00,http://www.bdo.com,Consulting
57,FULLTIME,Data Engineer,https://uk.linkedin.com/jobs/view/data-engineer-at-publicis-groupe-3789877269,"Publicis Groupe is a global leader in communication. The Groupe is positioned at every step of the value chain, from consulting to execution, combining marketing transformation and digital business transformation. Publicis Groupe is a privileged partner in its clients’ transformation to enhance personalization at scale. The Groupe relies on ten expertise concentrated within four main activities: Communication, Media, Data and Technology. Through a unified and fluid organization, its clients have a facilitated access to all its expertise in every market. Present in over 100 countries, Publicis Groupe employs around 101,000 professionals.

The Team

Performics Labs is a newly created team within Performics with the remit of developing and evolving our global performance product at speed. The Performics Labs team is comprised of two connected elements: a sub-team focussed on innovation and a sub-team focussed on scaling, with this role sitting within the innovation sub-team. The innovation sub-team is intended to take three key inputs – Performics market needs, martech landscape developments and longer-term strategic objectives – and translate these inputs into product MVPs that can be piloted within the markets and, if suitable, pushed to the scaling sub-team to fully productise. The focus for this sub-team is on speed and agility, with an aspiration to deliver a double-digit number of MVPs each year. The innovation sub-team is UK-based and will connect closely with the UK Technology & Intelligence (T&I) team, sharing a common operating framework and infrastructure in order to optimise efficiency.

Job Description

THE ROLE

The Data Engineer will directly report into the Global Head of Performics Labs, but will have a dotted line into the T&I engineering team, which will provide most day to day management functions. They will work in a small team to deliver MVPs based on the needs of markets, fed in by the global centres of excellence and channel leadership; the strategic priorities of Performics, fed in by the Performics product steering committee; and the latest developments in the martech landscape.

The Data Engineer will work within an operational framework aligned with the UK T&I team, providing infrastructure, ops processes, tools etc. as a foundation to increase efficiency. Within this framework, the Data Engineer will need to proactively drive MVP development, including ideation and technical development, sometimes working as part of a small team (potentially including other engineers, data scientists, UX support and/or ops support) and sometimes individually, based on the specific needs of the project. As such, this is a role for a proactive, energetic developer who wants to experiment, learn and keep moving; as comfortable self-directing on owned projects as taking direction on larger collaborations.

KEY RESPONSIBILITIES
• Analyse defined inputs and ideate technical solutions to address challenges / capitalise on opportunities
• Design or support solution architecture and implementation plans for MVPs
• Conduct feasibility research and build proof of concepts for MVPs
• Build or collaborate in building MVPs
• Collaborate with Head of Performics Labs, T&I Client Development team and Global Channel Leads to deploy MVPs onto pilot clients
• Collaborate with Labs scaling team to hand-off successful MVPs for scaling

Qualifications

Must Have skills
• Extensive experience using Python and SQL
• Good knowledge of cloud infrastructure (esp. Google Cloud Platform)
• Experience in application development
• Knowledge of ETL pipelines

Nice/Good to Have skills
• Experience with key marketing platform APIs (e.g. Google, Meta, Amazon APIs)
• Domain expertise in digital marketing
• Experience in front-end development (e.g. JavaScript, React)
• Good understanding of agile methodology

Additional Information

COMPANY VALUES

TRUST

Trust is the cornerstone upon which we build our relationships. We hold ourselves to the highest standards of how a partner should behave. We treat our people and our clients with respect, transparency and honesty

TALENT

This is first and foremost a people business. We are committed to ensuring Publicis Groupe is a destination for the best talent in our industry. We value people as individuals, growing ourselves as we grow our client’s business

TRANSFORMATION

True transformation comes when we stop managing change, and instead initiate change. We believe in our purpose to be the admired force for business transformation. We believe that focusing on performance and results has the power to transform client business",London,GB,2023-12-19 11:18:00,http://www.publicisgroupe.com,Advertising
58,FULLTIME,Data Engineer,https://onlydatajobs.com/job/281355/Data-Engineer-Greater-London-London,"Kraken is the technology tentacle of the Octopus Energy Group.

About Octopus

Octopus Energy is an energy technology business founded in 2015. Our aim is to drive society's transition to Net Zero by changing the way customers buy and use energy. To achieve this we:

Build the technology we need to efficiently provide customers with amazing experiences and support - we've been a Which recommended supplier 6 years in a row and maintain a Trustpilot score of 4.8 stars

- Challenge the tease and squeeze tactics of traditional energy pricing. We provide fair and transparent pricing that means all our customers get great value for the long term

- Bring renewable energy to our customers - all our products are 100% renewable and we're working to build new renewable generation right from the customer scale to the grid scale

- Reinvent energy products with smart, data driven tariffs that help to balance customer demand with renewable generation. Our Octopus Agile Tariff, Tesla Energy Plan, Octopus Go EV and Agile Outgoing Solar tariff are all industry firsts and enable our customers to be active players in a renewable energy system

Since 2015, we've grown to supply over 5.5 million customers in the UK. We've also spread our tentacles and are now in France, Italy, Spain, Germany, Japan, Australia, New Zealand & the U.S. Our in-house developed technology platform, Kraken, is licensed by retail giants including E.ON in the UK, Origin Energy in Australia and Toyko Gas in Japan.

About our Data Platform Team

At Octopus we've developed a data platform that provides data services to the business in the UK and our retail energy businesses around the world. The platform enables self-service of data analytics to hundreds of data hungry users as well as automation of all our data workflows from simple ETL jobs to ML training and prediction.

The data platform team works across the whole customer domain on anything from natural language understanding of our customer communications to processing billions of smart meter readings to build customised smart energy tariffs.

As the volume, scope and geographical range of our data services rapidly expand, we're looking for an experienced data engineer to join the team to help us build and maintain our platform, pipelines and data sources.

This is a fantastic opportunity to work on data problems that genuinely move us closer to Net Zero with a company that is passionate about building great technology to change the way customers use energy.

What you'll do...
• Build new data sources and data pipelines that deliver key data and insights to the business
• Work closely with the data science and analytics teams to maintain and develop our central data models in dbt
• Build and maintain testing and documentation frameworks for our data sources
• Work with the business to scope and deliver new data engineering projects and requirements
• Maintain and build on our existing data infrastructure and tools
• Support the internationalisation of our data infrastructure as we continue to grow globally

Our Data Platform Stack...
• Databricks our datalake approach
• Spark for data processing
• Python as our main programming language
• Kubernetes for data services and task orchestration
• dbt for data modelling
• Airflow purely for job scheduling and tracking
• Circle CI for continuous deployment
• Parquet and Delta file formats on S3 for data lake storage
• SparkSQL for analytics
• Streamlit for data applications

What you'll have...
• First and foremost, we want our data engineers to be great software engineers with a passion for writing high quality code
• It would be helpful to have experience/expertise in the following (in rough priority order):
Spark

SQL

Experience modelling data for analytics - ideally experience using dbt as a modelling tool

Experience in assuring data quality

Experience deploying data services in a cloud environment (ideally AWS)
• The projects will be varied and we're looking for someone who can work autonomously and proactively to scope problems and solve and deliver pragmatic solutions
>

Why else you'll love it here
• Wondering what the salary for this role is? Just ask us! On a call with one of our recruiters it's something we always cover as we genuinely want to match your experience with the correct salary. The reason why we don't advertise is because we honestly have a degree of flexibility and would never want salary to be a reason why someone doesn't apply to Octopus - what's more important to us is finding the right octofit!
• Octopus Energy is a unique culture. An organisation where people learn, decide, and build quicker. Where people work with autonomy, alongside a wide range of amazing co-owners, on projects that break new ground. We want your hard work to be rewarded with perks you actually care about! We won best company to work for in 2022, on Glassdoor we we're voted 50 best places to work in 2022 and our Group CEO, Greg has recorded a podcast about our culture and how we empower our people
• Visit our perks hub - Octopus Employee Benefits

We would prefer someone who can work in our London office but will consider remote candidates (warning: the bar is much higher). You do need to be able to work in the UK without a VISA though.

Above all, we're looking for someone who thrives on providing alternative opinions, challenging those around them and being challenged.

If this sounds like you then we'd love to hear from you.

Studies have shown that some groups of people, like women, are less likely to apply to a role unless they meet 100% of the job requirements. Whoever you are, if you like one of our jobs, we encourage you to apply as you might just be the candidate we hire. Across Octopus, we're looking for genuinely decent people who are honest and empathetic. Our people are our strongest asset and the unique skills and perspectives people bring to the team are the driving force of our success. As an equal opportunity employer, we do not discriminate on the basis of any protected attribute. Our commitment is to provide equal opportunities, an inclusive work environment, and fairness for everyone.",London,GB,2023-12-19 11:22:00,http://www.octopusenergy.com,Consulting
59,FULLTIME,Data Scientist/ Engineer,https://uk.linkedin.com/jobs/view/data-scientist-engineer-at-blckbx-3790001099,"BlckBx is the leading personal assistant platform for busy employees and working families.

We are looking for technology talent to help develop our first to market, AI and ML personal assistant platform.
• BlckBx Senior Full Stack Developer
• Working from home with office meetings when required
• Full time
• We are an equal opportunities employer and looking to build a diverse team of people with fantastic personalities who are looking for a rewarding role

ABOUT BLCKBX
• We are passionate about making the world of work a better place for families.
• Our services help increase productivity and retention for businesses whilst also lowering stress and saving precious time for employees

WHERE WE'RE AT
• You will want to be part of a new exciting business, roll up your sleeves and get into the action!
• The exciting bit is that this role could lead to bigger and better career opportunities and you'll put your name to a new technology platform that is market leading

THE ROLE

You will be responsible for designing, building, and maintaining scalable data pipelines and infrastructure in the Google Cloud Platform (GCP) environment. This role requires a strong understanding of data warehousing, data modelling, statistical analysis, machine learning algorithms and proficiency in using GCP services like BigQuery, Dataflow, and Cloud Storage.

Key Responsibilities:
• Design, build, and maintain scalable data pipelines and infrastructure using GCP services.
• Develop, test, and deploy data processing logic and data models in BigQuery.
• Analyse and interpret complex data sets to uncover patterns and insights that inform business decisions.
• Develop statistical models, machine learning algorithms, and predictive models using GCP services.
• Optimise the performance of data pipelines and SQL queries to ensure efficient processing and fast response times.
• Troubleshoot and debug issues as they arise and ensure data accuracy and completeness.
• Develop and maintain documentation of data pipelines, data models, and workflows.
• Stay up-to-date with emerging GCP technologies and trends.

Skills and Knowledge:
• Proficiency in Google Cloud Platform services such as BigQuery, Dataflow, Cloud Storage, and Cloud Composer.
• Strong SQL skills and experience with data warehousing concepts and data modelling.
• Experience with Python or Java programming languages and data processing frameworks like Apache Beam or Spark.
• Familiarity with version control systems such as Git.
• Strong problem-solving skills and attention to detail.
• Excellent communication skills and the ability to work collaboratively in a team environment.

Experience:
• Bachelor's degree in Computer Science, Information Systems, or a related field.
• Proven experience building and maintaining scalable data pipelines and infrastructure in the GCP environment.
• Experience with agile development methodologies.
• Knowledge of data privacy and security regulations and be able to work independently, as well as part of a team.

HOW TO APPLY

Please apply for the role by sending your CV to tom@blckbx.co.uk who is our head of technology and development with a covering letter email explaining why you are a good fit for the role. Please do not email Kath Clarke.

Successful candidates will be invited to a My Interview video to answer key questions and then from there an interview with Kath and Tom.",Reading,GB,2023-12-19 12:58:00,http://www.bdo.com,Consulting
60,FULLTIME,Data Analyst/Data Scientist – Hedge Fund – London,https://uk.linkedin.com/jobs/view/data-analyst-data-scientist-%E2%80%93-hedge-fund-%E2%80%93-london-at-jobs-via-efinancialcareers-3784447900,"My client is seeking a Data Analyst within their London based Data Science Team. Within this role, you will be responsible for developing statistical models and assist in the development and implementation of statistical models to support investment strategies.

Qualifications:
• Bachelor's or Master's degree in a quantitative field such as Statistics, Mathematics, or Economics.
• Proven experience as a Data Analyst in the finance industry, preferably within a hedge fund or asset management firm.
• Strong proficiency in data analysis tools such as Python, R, or SQL.
• Knowledge of statistical analysis and modelling techniques.

To apply please send your cv to quantresearch@octaviusfinance.com",London,GB,2023-12-19 21:06:00,https://www.efinancialcareers.co.uk,Consulting
61,FULLTIME,Data Engineer,https://gb.bebee.com/job/20231219-fc0e5d131917b7508524dce1139409ef,"Job Description Avensys is a reputed global IT professional services company headquartered in Singapore. Our service spectrum includes enterprise solution consulting, business intelligence, business process automation and managed services.

Given our decade of success, we have evolved to become one of the top trusted providers in Singapore and service a client base across banking and financial services, insurance, information technology, healthcare, retail and supply chain.

We are currently looking for Data Engineer who has proven track record in IT Industry. This is an exciting opportunity to expand your skill set, achieve job satisfaction and work-life balance. Data Engineer
Job Type: 3 months contract

5 + Years of experience in Database BI Lead Engineer Azure Data platform, Business Intelligence (BI), Data Warehouse (DWH), Data analytics and Data Modeling, Data Vault Modeling/Architecture.
~ maintain Enterprise Data Models for Enterprise Class Data Initiatives.
~ Experience in HealthCare (NHS Acute Data Services & US Healthcare system), Finance, Audit, Retails domain verticals.
~ Data Warehouse (Ralph Kimball & Bill Inmon), Relational (SQL Server 2008R2 and Later Versions, PostgreSQL, Oracle, MySQL, and MS-Access) and Multi-Dimensional database, Data Migration, System & Data Integration, Reporting, Analysis and Data Management.
~ Strong Experience in implementing Data warehouse solutions in Confidential Redshift, Snowflake Multi-cluster Data platform worked on various projects to migrate data from on premise databases to Confidential Redshift, Azure Datawarehouse and Snowflake
~ Expertise in writing Packages, Stored Procedures, Functions, Views, and Database Triggers etc. Using SQL, PL/SQL, T-SQL, PL/pgSQL
~ Strong experience across entire Microsoft BI suite of products including SQL Server, SSIS, SSAS, SSRS and Power BI SDLC from prototyping to deployment.
~ Experience in Data Modeling, System/Data Analysis, Design and Development for both OLTP and Data warehousing environments.

To submit your application, please apply online or email your UPDATED CV in Microsoft Word format to seema@aven-sys.
We take your personal data protection seriously and adhere to both EU and local data protction regulations.

Upon submission of your CV, you grant Avensys Consulting permission to retain your personal information in our electronic database, unless you specify otherwise.
This data will be used to evaluate your suitability for current and potential job openings within our organization. Should you wish to have your personal data removed at any point, a simple notification to us will suffice.",London,GB,2023-12-19 16:10:00,http://www.bdo.com,Consulting
62,FULLTIME,Microsoft Data Engineer and Application Support,https://onlydatajobs.com/job/273667/Microsoft-Data-Engineer-Application-Support-Greater-Manchester-Manchester,"The BES Group are the leading end to end solution provider in the Testing, Inspection, Certification and Compliance sector. Our team of experts (hand-picked by our Careers Team) cover an extensive range of engineering services.

We've gone from strength to strength over recent years, welcoming the very best risk management businesses to our Group. As a result, we've grown both our team of experts and our suite of solutions in line with our customer's needs. We're private equity backed, which means we have the flexibility and support to move quickly and grow faster than any other company in our industry. We're innovative and forward thinking and have the awards to prove it, but most of all we're focused on helping make sure our customers leave nothing to chance.

Our head office is based in central Manchester and is the home to many of our central functions. To support our continued ambitious growth plans, we are delighted to be recruiting for a Microsoft Data Engineer and Application Support to join our fantastic IS team.

What are we looking for?

This is a fantastic opportunity to join our growing Data Engineering and BI team, in a role that will allow you to both apply and grow your skills through the delivery of data and insights to help drive change in all areas of our business. You will form a key part of the team to continually improve our Microsoft Azure based strategic data platform, from managing our integrations and wrangling data from Dynamics 365 to producing dashboards for key business decisions and supporting predictive analysis projects.

We are looking for a candidate with perhaps some commercial experience in a BI or Data Engineering with Database Administration experience supporting multiple applications / end points, who are vested in Microsoft technology, with proactive improvement and customer orientated mindset looking to grow their business and technical experience.

What will I be doing?

You will own the development and implementation of data and reporting solutions, integrations between applications and provide database administration working closely with our IT DevOps Team. You will do this using the latest Microsoft technologies: SQL Server Integration Services Azure Synapse Analytics, Azure Analysis Services, Azure Data Lake, Azure SQL Database, Azure Data Factory and Power BI (both dashboards and paginated reports)

Taking responsibility for the successful completion of our daily data processing routines and schedules and working with the wider development team to ensure that performance is maximised and sustained while providing high availability, scalability, and optimum performance for database servers through the setup, upgrade, migration, and installation of appropriate hardware.

You will lead with other key stakeholders the development of a fit for purpose architecture to deliver high availability, scalability, and optimal environments for performant data processing which supplies our reporting and applications to required quality and SLA's. You will undertake root cause analysis, advising remediation options and if required delivering a solution including delivering any early lifecycle support as needed.

You will work with other members of the team or directly with our business users to understand and document business requirements, evaluate options, research and propose suitable solutions. Using your stakeholder management skills to translate business requirements into design specifications.

What makes BES Group a great place to work?

We genuinely care. It's basic, human instinct that runs through every person that works at BES Group. Knowing we always do the best job we can with absolutely no compromise means everything.

If you work for us, you will get the below and, so much more:
• A competitive salary from £50,000 (negotiable, depending on experience)
• A flexible working approach, the role will be in our Manchester office with home based working available (you must have suitable Wi-Fi, and provide your own office set up).
• Amazing head offices in the heart of Manchester city centre
• Development opportunities across the business
• Discretionary annual company bonus and yearly salary review
• 25 days leave per year plus bank holidays (and an extra day off on your birthday to celebrate you!)
• Shiny new Surface Pro
• Access to lots of discounts and benefits via our company benefits portal including; retail, fitness, holiday and cinema discounts
• The support of a superb employee assistance programme
• Electric vehicle salary sacrifice scheme
• Opportunities to attend volunteer days
• Company contribution to charity fundraising you participate in; we want to support charities you are passionate about!
• Employee Suggestion programme, because we value input from everyone in the BES Group
• Up to 10% pension

What experience do I need?

To work for us you must have the right attitude, aptitude and appetite for what we do. As a minimum, you will have:
• Delivery of a modern data platform using relevant technologies and services in Microsoft Azure.
• Proven experience as a Microsoft SQL Server Database Administrator; with a good understanding of database standards, end user application integrations, security protocols, development standards and support for deployments of code.
• Strong architectural understanding of standard Microsoft Stack including SQL Server Database Engine and of Microsoft Azure Database components such as Azure SQL Database, Azure SQL Managed Instances, and Azure Data Factory
• Expert in T-SQL including stored procedures, temp tables & CTE's with performance tuning.
• Proficient in the development of SQL Server Integration Services (SSIS) solutions and Azure Data Factory
• Demonstrable experience in the use of GIT for CI/CD source control in azure across key areas of the stack
• Proficient in developing cascading, parameterized reports using SQL Server Reporting Service and report development of datasets and reporting in Microsoft Power BI
• Strong understanding of data modelling concepts
• Strong Customer focus, both internal and external with proven experience in gathering low level requirements
• Experience of interpreting and analysing complex data
• Knowledge and a proven track record in data / data quality management
• Code management & deployment tools
• Proficient in debugging, monitoring, tuning and troubleshooting BI solutions.
• Degree (or equivalent Level 6 qualification) in Computer Science, Maths, Physics or other technical subject (desirable but not essential)

To apply for this role, simply click ""Apply"". We ask for some basic contact information and a CV or your LinkedIn profile, it's that easy! Please keep in mind, successful candidates will be required to complete the relevant background checks as part of the recruitment process.

We want to inspire everyone to see how important safety is and we expect the same from our people. And if you're on the same page as us about that and you've got the right skills, experience and attitude, you'll fit right in. Simple. We're all about diversity and inclusion and that means we want our people to be themselves. We're delighted to be an equal opportunities employer and that will never change!

BES Group, Your Safety, Our Focus",Manchester,GB,2023-12-19 12:41:00,http://www.britishengineeringservices.co.uk,Consulting
63,FULLTIME,Data Engineer,https://uk.linkedin.com/jobs/view/data-engineer-at-tillo-3784466004,"Department: Tech

Employment Type: Full Time

Location: Brighton

Reporting To: Platform Manager

Compensation: £45,000 / year

Description

As a Data Engineer at Tillo you will look after the design and implementation of database clusters, tables, schemas, indexes, and ETL pipelines - this also includes database and query performance tuning.

Join a world-class team in the business of making people smile. Our Platform connects our customers to rewards and incentives from 2000+ brands that people love, all via our seamless, easy-to-use API. We're the market leader in the UK and are active in a number of other markets including Europe, Australia and India. This year we will continue to expand our presence in the US as well as setting up operations in new countries     

You will have the opportunity to work closely with (and learn from!) our Senior Data Scientist, Platform Manager and DevOps team.

If successful, you will
• Design database schemas and tables
• Build and maintain ETL pipelines
• Look after query and index performance tuning
• Manage database backup/recovery, monitoring and alerting
• Work in an agile way following DevOps principles
• Help developers with database related queries
• Mentor the wider team on best practices

About You

You'll be ideal for this role if you have a demonstrable passion for automation and collaboration. We are looking for experience with:
• Relational databases (MySQL, PostgreSQL, Oracle, or similar)
• No-SQL data stores (ElasticsSearch, Redis, DynamoDB, Cassandra, Presto, MongoDb, or similar.)
• ETL tools (preferably dbt)
• Git (or another source version control system)
• Python and development best practices
• Cloud Providers such as AWS, GCP, or Azure
• Linux and Bash

Although not essential, we'd love to hear if you have experience with:
• Building and deploying containers in Docker
• Deploying and operating applications on Kubernetes
• Python based data science tools (Pandas, NumPy, Matplotlib)
• MPP and columnar relational databases (Redshift, Snowflake, BigQuery, Vertica, Grenplum, or similar)
• Business intelligence and analytics tools such as Tableau, Power BI, Looker, or QuickSight
• CI/CD processes

Benefits

We offer all our employees trust and empower our team to work with flexibility and autonomy. We're a close-knit team and love working collaboratively, with our hybrid model, our team can come together at our fantastic office in Hove, but also focus in their own space. The Tillo team are a motivated bunch and we all work hard to push Tillo forwards, always innovating. We completely understand the importance of work/life balance and offer a supportive and collaborative working environment with the following benefits:
• 26 days annual leave plus Bank Holidays
• Annual Bonus Scheme
• Designated Shares Options for all employees
• Private healthcare
• Enhanced Family Leave Policy
• Quarterly staff engagement surveys - to listen and act on the employee voice.
• Regular employee wellbeing activities, including company lunches and away days where we do everything from helping local charities to traditional team building activities
• Retail discounts
• Raising money for a charity outside of work? We'll match your donation with our charitable matching contribution
• Well stocked drinks fridge and snack cupboards
• Cycle to work scheme",London,GB,2023-12-19 22:01:00,http://tillo.io,Consulting
64,FULLTIME,SQL engineer,https://gb.bebee.com/job/20231219-49ed8c4bd2fe92703a3b5aa9484ac192,"Permanent
Hybrid working - 3 days a week in London or Sheffield office
£Do you have strong experience with the modern data stack? Sentinel are working with a digital solutions provider who are looking for strong Data Analysts/Analytics Engineers to join their team and help to deliver clean, quality data to improve business decisions. This is an exciting time to join the company as they harness the latest technology and on their transformation journey. The role would suit a 'tech savvy' up-and-comer who has experience with the modern data stack.

Strong experience utilising the modern data stack including Fivetran, dbt and Looker
Core skills in coding with SQL and Python
As the Data Analyst you'll be responsible for:

Defining and maintaining data pipelines
Manipulating and visualising data
Analytics Engineer / Analytics specialist / Data Analytics Specialist / ETL Developer / Analytics Consultant / Data Analyst

Sentinel is an award-winning technology recruitment and consulting company with offices in the UK, USA, Czech Republic, and Switzerland.

We work with global brands, ambitious start-ups, and leading recruitment outsourcers, ensuring access to exceptional talent through permanent, contingent labour, and statement of work services.
If not, we'll keep you updated with other opportunities in your field.",London,GB,2023-12-19 16:06:00,http://www.bdo.com,Consulting
65,FULLTIME,Senior Analyst (Data Science),https://onlydatajobs.com/job/299391/Senior-Analyst-Data-Science,"OPEN TO NATIONALS OF NATO MEMBER STATES ONLY

Job Title: Senior Analyst (Data Science)

NATO Grade: NATO GRADE 17

NATO Body: Headquarters Allied Maritime Command (HQ MARCOM)

Location: Northwood, Middlesex, UK

SECURITY CLEARANCE: NATO SECRET (NS)

Basic Monthly Salary: £7,153.17 tax free

Contract Length: 3 Years (see Contract section below)

Closing Date: 07 January 2024

POST CONTEXT

Headquarters Allied Maritime Command is the Maritime Theatre Component Commander delivering 360 degree maritime focussed awareness and connectivity while planning and commanding the full range of maritime operations.

The Plans Directorate is responsible for the conduct and implementation of operational and tactical planning for maritime operations and exercises.

The N5 Division is responsible for the contribution to the development, review and implementation of NATO policies, strategies and concepts.

The Operational Assessment and Analysis Branch is responsible for providing advice to aid the operational decision making process.

The role of the Senior Analyst (Data Science) is to lead on the collection, management and application of analytics, using a variety of data sources, to extract value from NATO operational data and enable the HQ to make better, faster decisions, both within the assessment process and for other HQ needs.

DUTIES

The incumbent's duties are:
• Leads the data science team (under supervision of the Branch Head).
• Provides the Branch with analytics products through the application of data science techniques, including statistics, data mining and machine learning.
• Conducts analytical studies to support decision-making in areas such as hybrid threats and for customers such as N2, N3, MARAIR, SUBS, N4, NSC, COMMS Division.
• Advises and supports divisions in helping to prepare and store operational data in order to process, analyse and learn from the data.
• Ensures HQ processes and procedures related to data science are coordinated and aligned with all NATO policies and procedures.
• Works with NCIA staff to ensure operational data is available for analytical purposes.
• Contributes to the evaluation of data science analysis trials in ACO.
• Leads the identification of MARCOM requirements in support of NATO's data exploitation programme of work and other future data science & AI capabilities.
• Enables a data-driven culture in the HQ that uses analytics to generate insights, inform operational decisions and improve performance.
• Ensures that issues and lessons learned relating to data science are captured, managed, analysed and available as appropriate.

SPECIAL REQUIREMENTS AND ADDITIONAL DUTIES

The employee may be required to perform a similar range of duties elsewhere within the organisation at the same grade without there being any change to the contract

The incumbent may be required to undertake operational deployments and/or TDY assignments both within and without NATO's boundaries for up to 183 days in any period of 547 days.

The work is normally performed in a Normal NATO office working environment / Secure office environment with artificial light and air (e.g. Bunker).

Normal Working Conditions apply.

The risk of injury is categorised as: No risk / risk might increase when deployed

QUALIFICATIONS AND EXPERIENCE

Essential Professional Experience

(1) Military Operational Analysis

Activities involving the application of Operations Research (OR) techniques (see also 461G) specifically to Military issues. Military Operations Research is also known as Operational Analysis (OA). It is used to support military decision-making across the spectrum of military activities. It is especially relevant in; the assessment and analytical simulation of Courses of Action in operational planning and force mix studies, in support of collective HQ training and evaluation, cost effectiveness studies, risk management, logistical simulation and optimisation, organisational, business process analysis, manpower and other management tasks. The OA specialism is required where military knowledge is essential for rapid integration of scientific/analytical support into a civil/military analytical team or when filling a post within an operational HQ.

Experience
• Two years experience with AI and or Machine Learning Tools e.g. Watson, Microsoft Cognitive Toolkit, TensorFlow
• Two years experience in applying data science tools to support advanced data analytics, machine learning and data visualisation.
• Two years experience in planning and executing the data science lifecycle: ingestion, preprocessing, analysing, post-processing and visualisation.
• Experience applying data science, analytics and data integration tools/programming languages on real-world datasets e.g. Python, R, KNIME, Splunk.
• Proven knowledge of mathematical and statistical models.
• Experience of use of data visualisation tools e.g. Microsoft Power BI, Spotfire, Tableau.

Essential Education/Training

University Degree in information technology, economics, statistics, operations research or related discipline with 4 years related experience OR Higher Secondary education and completed advanced vocational training in related field/discipline leading to a professional qualification or professional accreditation with 5 years related experience.

Essential Language

English - SLP 3333 - (Listening, Speaking, Reading and Writing)

NOTE: The work both oral and written in this post and in this Headquarters as a whole is conducted mainly in English.

Desirable Professional Experience
• Practical experience using big data ecosystems e.g. Hadoop, Spark, MapReduce.
• Knowledge of NATO software application services used at operational level, e.g. TOPFAS, LOGFAS, NCOP, JOCWatch, AOSS, INTEL FS, EDMS.
• Advanced degree in data science/data analytics or closely related field.
• Knowledge of joint and/or combined operations at both operational and tactical levels.
• Recognition by / accreditation from relevant professional bodies

ATTRIBUTES/COMPETENCIES

- Personal Attributes: Excellent communication skills, both oral and written - able to communicate at all levels; very good interpersonal skills; innovative - driven - sound judgement; excellent organizational skills.

- Professional Contacts: Work with ACT and NCIA on the development and enhancement of Data Science Capabilities across NATO. Liaise with colleagues across the NATO Alliance on data science matters affecting nations and the NATO Enterprise. Maintain knowledge on state of the art tools and services available from commercial or academic sources.

- Contribution to the Objectives: As part of MARCOM's adaptation to a warfighting HQ the Command Group has identified Measurements of Effect as a new area of attention, to be assumed by the Operations Analysis and Assessment Branch. Operations Assessment is a data driven, evidence based process as described in the Comprehensive Operations Planning Directive, and the NATO Operations Assessment Handbook. This role will contribute to the achievement of that objective by making the data collection and management process more efficient through automation, and then in developing the role of data analytics and eventually, machine learning, in order to feed the Operations Assessment process.

- Problem Solving:

o Diversity and Range of Duties: A feature of Military HQs is the use of 'military data', which comes in a variety of unique and specialized formats which are not publicly used. Whilst there are a vast range of commercial data science techniques and tools available, the challenge will be to adapt and apply them in a military environment, and in particular to be prepared to do so at pace during live operations.

o Type of Problem/Degree of Challenge: Data science is a developing field within NATO, with little in the way of previous experience, knowledge amongst colleagues, or experienced leadership. There will be significant opportunities for this post to influence the way in which and the speed at which data science evolves within NATO.

o Degree of Guidance Available: Limited technical guidance is available within MARCOM. The incumbent will have to liaise with other NATO bodies to maintain coherence with organizational developments and to ensure products are in line with NATO requirements

CONTRACT

This post is approved for a 3-year duration.

It is currently unknown what will happen at the end of the 3-year period. Therefore, although there may be a possibility of an extension or even a permanent contract there is a very high risk that the post will not continue beyond the 3-year point and as such no guarantee of work beyond 3 years can be offered.

Newly recruited staff and currently serving NATO Civilian Staff with less than 10 years of service will be offered a definite duration contract of 3 years.

Serving NATO civilian staff with more than 10 years of service will be offered a contract according to the NATO Civilian Personnel Regulations.

The basic entry-level monthly salary for a NATO Grade 17 in the UK is £7,153.17 (tax free) which may be augmented by allowances based on the successful candidate's eligibility.

HOW TO APPLY

HQ MARCOM uses NATO Talent Acquisition Platform.

In order to apply for this vacancy, please visit the platform at:

https://nato.taleo.net/careersection/2/jobsearch.ftl?lang=en , and search for vacancies within HQ MARCOM.

Essential information must be included in the application form. Each question should be answered thoroughly. Expressions such as ""please see attached CV"", or invitations to follow links to personal webpages, are not acceptable, and will be disregarded. Application form must be filled out in English.

Applications are automatically acknowledged within one working day after submission. In the absence of an acknowledgment please make sure the submission process is completed or, re-submit the application.

Shortlisted candidates invited to the interview phase, will be requested to provide, where applicable, copies of Educational and Vocational training certificates.

Current and past civilians working for NATO or any Coordinated Organization, shall indicate their last grade and step held (next to the job title) and specify the name of employing NATO body or Coordinated Organization.

Qualified redundant staff of the same grade interested in this post should inform this office, via their own HR/Personnel Office by not later than the vacancy's closing date.

EMPLOYMENT PRE-REQUISITES:

Candidates are invited to submit their application if:
• They are national of a NATO member country
• They are over 21 and under 60 years of age at the time of taking up their appointments. Appointments of definite duration may be offered to candidates of 60 years of age or more, provided the expiry date of the contract is not later than the date at which the candidate attains the age of 65.

ADDITIONAL INFORMATION

A NATO security clearance of the level required by the position, and approval of the candidate's medical file by the NATO Medical Adviser are essential conditions for appointment to this post. Applicants are not required to possess a clearance at the time of applying, but must be eligible for a clearance. HQ MARCOM will take action to obtain the required security clearance from the successful candidate's national authorities.

Candidates must meet all the essential qualifications in order to be considered qualified. Should no qualified candidates be found, candidates not possessing all the essential qualifications may be considered. However, they will be appointed at a lower grade and their employment contract will stipulate the conditions under which the grade attached to post can be granted and the employment contract confirmed.",London,GB,2023-12-19 11:42:00,http://www.nato.int,Manufacturing
66,PARTTIME,Senior Data Engineer - Future Opportunities,https://uk.linkedin.com/jobs/view/senior-data-engineer-future-opportunities-at-avanade-3784428941,"Job Description

RECRUITING FOR THE FUTURE

This posting is for a future job opportunity.

To support the needs of our clients, Avanade is actively recruiting and interviewing for the role outlined below, as we continue to build on another year of growth in our business. Now, with more than 60,000 employees around the globe, we are positioning our organization to effectively prepare for the future. What does this mean for you? We encourage you to apply and interview for this role without the need to decide now. This allows you to connect with leaders and hiring managers at a pace that works for you and when roles become available, you will be the first to know.

Our talented Data Engineering team is made up of globally recognised experts—and there’s room for more analytical, innovative, client-driven data professionals. If you’re passionate about helping clients make better data-driven decisions to tackle their most complex business issues, let’s talk. Take your skills to a new level and launch a career where you can truly do what matters.

Come join us

As a member of the Data Engineering team, you’ll have access to the research, knowledge and tools to create leading-edge solutions across Avanade’s Data & AI practice. The role of Senior Data Engineer is perfect for ambitious technologists passionate about working with the latest Microsoft cloud technology and Microsoft experts. Our clients look to us for innovation, which means you’ll have early access to the newest Microsoft technologies so you can master them and stay ahead of the curve.

As you bring your skills and abilities to Avanade, you’ll get distinctive experiences, limitless learning and ambitious growth in return. As we continue to build our diverse and inclusive culture, we become even more innovative and creative, helping us better serve our clients and our communities. You’ll join a community of smart, supportive collaborators to lift, mentor and guide you, but to also lean on your expertise. You get a company purpose-built for business-critical, leading-edge technology solutions, committed to improving the way humans work, interact and live. It’s all here, so take a closer look! Together we do what matters.

What You’ll Do
• Architecture, design, development, and delivery of enterprise-grade analytics solutions based on Fabric, Azure and Databricks technologies
• Mentoring of more junior team members and supporting their personal development 
• Constantly developing technical skills in the latest Fabric, Azure and Databricks technologies - achieving & maintaining relevant certifications
• Working directly with high profile clients across a variety of sectors to understand their requirements and present solutions to customer sponsors

Skills And Experiences
• Demonstrable end-to-end experience in Data Engineering, including large-scale projects
• Experience in working with the latest Azure technologies, such as; Databricks, Synapse, Data Factory, Azure Data Lake Storage (Gen 2), Cosmos DB, Fabric
• Understanding of software engineering tools and concepts including experience in Python, Scala or PySpark
• Confident communicator who is able to explain technical terms to non-technical audiences and mentor junior colleagues
• Leads small development teams: track work, manage assignments, manage capacity, etc.

About You

Characteristics that can spell success for this role
• Analytical, curious, agile
• Team player and good communicator
• Problem-solver, patient, quality-driven
• Self-motivating
• Innovative mindset

Enjoy your career

Some of the best things about working at Avanade
• Opportunity to work for Microsoft’s 2023 Global Alliance Partner of the Year (winner 18 times), 2023 UK partner of year, Databricks Global partner of the year for the last 5 consecutive years.
• Exceptional development and training (minimum 80 hours per year for training and paid certifications)
• Real-time access to technical and skilled resources globally
• Collaborate with some of the brightest “Microsoft minds”
• Build your expertise, solve problems, learn, and develop

Find out more about some of our benefits here .

A great place to work

We work hard to provide an inclusive, diverse culture with a deep sense of belonging for all our employees. Visit our Inclusion & Diversity page.

Create a future for our people that focuses on
• Expanding your thinking
• Experimenting courageously
• Learning and pivoting

Inspire greatness in our people by
• Empowering every voice
• Encouraging boldness
• Celebrating progress

Accelerate the impact of our people by
• Amazing the client
• Prioritizing what matters
• Acting as one

Learn more

To learn more about the types of projects our Analytics team works on check out these case studies:

What matters to PageGroup is using AI to grow businesses and career opportunities

What matters to SSE Renewables is innovating for a sustainable future

Interested in knowing what’s going on inside Avanade? Check out our blogs:

Avanade Insights – exchange ideas that drive tomorrow’s innovation

Inside Avanade – explore what life is like working at Avanade

About Avanade

Avanade is the leading provider of innovative digital, cloud and advisory services, industry solutions and design-led experiences across the Microsoft ecosystem. Every day, our 59,000 professionals in 26 countries make a genuine human impact for our clients, their employees and their customers.

We have been recognized as Microsoft’s Global SI Partner of the Year more than any other company. With the most Microsoft certifications (60,000+) and 18 (out of 18) Gold-level Microsoft competencies, we are uniquely positioned to help businesses grow and solve their toughest challenges.

We are a people first company, committed to providing an inclusive workplace where employees feel comfortable being their authentic selves. As a responsible business, we are building a sustainable world and helping people from underrepresented communities fulfil their potential.

Majority owned by Accenture, Avanade was founded in 2000 by Accenture LLP and Microsoft Corporation. Learn more at www.avanade.com .",Newcastle upon Tyne,GB,2023-12-19 16:20:00,http://www.avanade.com,Consulting
67,FULLTIME,Data Visualisation Engineer,https://gb.bebee.com/job/20231220-b434b99aa7861633776e72497a589691,"Data Visualisation Engineer

Application Deadline: 27 November 2023

Department: Software

Employment Type: Full Time

Location: London, UK

Reporting To: Federico Cicchi
Description
XYZ Reality is a construction tech start-up based in London and is currently looking for a talented, passionate, and experienced Power BI Custom Visual Engineer.

XYZ is on a path to revolutionise the construction industry with custom augmented reality hardware and innovative software. Our Team are highly motivated, professionally qualified engineers specialising in industrial and mechanical design, software, and electronic design and manufacture. The quality and innovativeness of the products we design are critical to our customers and our company.

Key Responsibilities
· Develop, test, and maintain custom visuals for Power BI using the Power BI Custom Visuals SDK,· Utilize TypeScript/JavaScript and for custom visual development,
· Work closely with Power BI developers to integrate custom visuals into reports and dashboards,
· Optimize custom visuals for performance, including mobile compatibility,
· Provide technical documentation and training for both internal teams and clients,· Willingness to learn new things and to help out in other areas within the company when needed.
Skills, Knowledge & Expertise
• Degree in Computer Science or similar technical field of study,
• 3+ years of professional experience writing Custom Visuals for Power BI,
• 3+ years of professional experience with TypeScript/JavaScript and ,
• Solid understanding of Power BI's data model, capabilities, and best practices,
• Familiarity with and development tools like npm,
• Deep understanding of software engineering best practices,
• Excellent communication skills in spoken and written English, with the ability to explain complex technical concepts to non-technical stakeholders,
• Able to plan and estimate your own tasks and ensure timely delivery of work,
• Experience with Azure Cloud development and DevOps,
• Bonus: Knowledgeable about construction BIM standards.
Benefits
· Competitive Salary,· 25 days paid holidays plus bank holidays,· Company pension,· Private Healthcare,· Bi-weekly free lunch,· Fresh fruit every week,· Unlimited tea, coffee and soft drinks in the office,· Office drinks every Thursday evening,· Cycle to work scheme,· Flexible working hours,· Summer and Christmas parties,· Easily accessible location,· Casual dress code,· Modern, friendly environment,· Start-up culture,· Playing a valuable part in revolutionising the industry.

#J-18808-Ljbffr",London,GB,2023-12-20 06:57:00,http://www.bdo.com,Consulting
68,FULLTIME,"Senior Data Engineer (Part-Time, Job-Share, Full-Time)",https://uk.linkedin.com/jobs/view/senior-data-engineer-part-time-job-share-full-time-at-zurich-insurance-3788127587,"Salary: £50,000 - £70,000 depending on experience plus an excellent benefits package

Location: Whiteley or Swindon. We offer hybrid working so you’ll have the option to work from home as well as join our colleaugues in our Whitely or Swindon office.

Closing date for applications: 7th January 2024

The opportunity:

Are you a motivated, hands-on, and innovative person, interested in working for one of the largest global insurers? Are you obsessed with developing great analytical software, which helps addressing daily business challenges of one of the biggest global insurers? Then this role could be for you!

We’re looking for a Senior Data Engineer to join the global Commercial Insurance team. In this role, you will:
• Solve high impact business problems with a particular focus on Underwriting, for example: understanding claims drivers, portfolio optimization or improving our risk selection,
• Learn how Commercial Insurance works at its core, including dedicated training,
• Be part of a fast-paced entrepreneurially minded global team, which is daring to challenge the status quo,
• Developing and driving adoption of our main global Underwriting analytical product suite,
• Excelling on your technical skills by working with internal and external experts.

Many of our employees work flexibly in a variety of different ways, including part-time, flexible hours, job share, an element of working from home or compressed hours. This is because we want the best people for our roles, and we recognise that sometimes those people aren’t available full-time. Please talk to us at interview about the flexibility you may need.

What will you be doing?

As a Senior Data Engineer, your main responsibilities will involve:
• Working on high impact projects with end-to-end responsibility for their success
• Experimenting with the right cloud-based technology to solve specific business problems
• Generating insights from internal and external data sources, using a wide range of tools and methodologies, e.g., from building complex big data pipelines in Spark and Scala to applying Semantics and/or Machine Learning and extending our front-end applications
• Building applications loved by internal and external users: from implementing proof of concepts to full-scale solutions; from portfolio management applications used by senior Zurich executives to Applications Programming Interfaces embedded into the core Underwriting processes
• Making sure our platform expands and runs reliably in Production: build or help build AI models, add new and further optimise existing data pipelines, expand our automation architecture (e.g., web scrapers, automated user alerts)
• Coordinating directly with product managers and application users globally (with particular focus on adoption)
• Mentoring and developing more junior team members on all matters above

What are we looking for?
• Technically strong:
• Has professional experience with data engineering
• Any Dataframe API (like Spark or Pandas) and SQL
• Query optimizations (RDBMS or Spark) and indexing
• Knows Java and/or Scala well, functional programming experience is a plus
• Knowledge of scripting languages, such as Python, R, bash
• Experience working on all stages of the software development lifecycle
• Can-do attitude, with a clear focus on the end-product and user experience and the specific business use case
• Passion to tackle real business problems and persistence to follow through with your recommendations
• Good team player and communicator

Preferred skills/experience:
• Experience with cloud-based technology and solution design: e.g., experience with Microsoft Azure Products, Databricks, Kubernetes, Docker
• Front-end development experience is a strong plus
• Experience in geospatial data modelling and data manipulation at large scale
• Good working knowledge of Redis, Elastic suite product, and NoSQL
• Experience in designing, running, and expanding AI models (in particular, text classification, entity extraction, clustering & topic modeling) in production; with a main focus on Natural Language processing
• Experience with web scraping, e.g., Selenium
• Prior work experience in (re)-insurance

As an inclusive employer we want to ensure that all candidates feel comfortable and are able to perform at their best during the interview. You’ll have the opportunity to let us know of any reasonable adjustment or practical support needed when you apply.

Who we are:

At Zurich we aspire to be one of the most responsible and impactful businesses in the world and the best global insurer. Together we’re creating a brighter future for our customers, our people and our planet.

With over 55,000 employees in more than 170 countries, you’ll feel the support of being part of a strong and stable company who are a long-standing player in the insurance industry.

We’ve made a promise to each other and every employee; to focus on sustainable impact, to care about each other’s wellbeing, to use our diverse expertise to be curious and optimistic and to develop the skills needed for our future.

If you're interested in working in a dynamic and challenging environment for a company that recognises and rewards your creativity, initiatives and contributions - then Zurich could be just the place for you. Be part of something great.

Our Culture:

At Zurich, our sense of community is strong and we’re particularly passionate about diversity and inclusion, which we’ve won numerous awards for. We want our people to bring the whole of themselves to work and ensure everybody is made to feel welcome, regardless of their background, beliefs or culture. We want our employees to reflect the diversity of our customers, and so are committed to treating all of our applicants fairly and with respect, irrespective of their actual or assumed background, disability or any other protected characteristic.

We’ve an environment that places a real importance on our people’s wellbeing from a physical, mental, social and financial perspective. We work with our wellbeing partners and industry experts to provide the best advice and access to a wealth of lifestyle support. We’re also committed to continuous improvement and we offer access to a comprehensive range of training and development opportunities.

We’re passionate about supporting employees to help others by getting involved in volunteering, charitable and community activity. Our charitable arm, Zurich Community Trust, is one of the longest-established corporate trusts in the UK. In that time, we’ve awarded grants and volunteered time to deserving causes in the UK valued at over £90 million.

So make a difference. Be challenged. Be inspired. Be supported, Love what you do. Work for us.",Fareham,GB,2023-12-19 15:50:00,http://www.zurich.com,Finance
69,FULLTIME,Senior Data Engineer,https://uk.linkedin.com/jobs/view/senior-data-engineer-at-dstl-3790030499,"In This Role You Will
• Lead small teams to undertake a range of tasks across a range of stakeholders to deliver high impact outcomes.
• Work with others to deliver to projects solving difficult technical problems and presenting to technical leaders in the most appropriate format
• Exercise good judgement to reach evidence based conclusions and decisions supported by analysis.
• Keep abreast of the latest developments in data science & engineering to actively contribute to capability development.
• Support customers and project teams to understand where data science and engineering can enable projects to add new value and promote innovation.
• Collaborate with Industry and Academia to ensure that the tasks we place remain on track, are of high quality and receive the benefit of internal expertise.
• Guide and direct the work of others, through technical leadership, to ensure delivery of high impact science and technology.
• Review approaches and outputs ensuring they are technically robust, and follows legal and ethical requirements.

We Will Support Your Career Development By

Offering a variety of opportunities to keep up-to-date with the latest developments, through training and development, attending and presenting at conferences, and working closely with industry and academic colleagues to deliver cutting edge, novel tools and techniques.",Porton Down,GB,2023-12-19 14:44:00,http://www.dstl.gov.uk,Computer Services
70,CONTRACTOR,Data Scientist,https://uk.linkedin.com/jobs/view/data-scientist-at-elgebra-3790076871,"We are seeking an experienced and passionate Data Scientist to join our dynamic team in the UK. If you have a minimum of 8 years of total IT experience and a strong background in Python, ML, Azure Data Bricks, NLP, SQL, and MLOps, we want to hear from you!

Key Responsibilities:
• Utilize your expertise in Python, ML, and Azure Data Bricks to develop and deploy advanced machine learning models.
• Apply Natural Language Processing (NLP) techniques to extract insights from unstructured data sources.
• Collaborate with cross-functional teams to understand business requirements and translate them into data science solutions.
• Proficiently use SQL for data extraction, transformation, and loading (ETL) processes.
• Implement MLOps practices to streamline and automate the end-to-end machine learning lifecycle.

Qualifications:
• Minimum 8 years of total IT experience, with a focus on data science.
• Proven experience in Python, ML, Azure Data Bricks, NLP, SQL, and MLOps.
• Strong analytical and problem-solving skills with the ability to work on complex data sets.
• Excellent communication skills to convey complex findings clearly and understandably.
• Ability to work onsite in the UK.

Warm regards

Yogesh Pratap Singh

Direct – (205)-775-0773

244 Fifth Avenue, Suite R295,

New York, NY – 10001

Email: Yogesh_s@elgebra.com",London,GB,2023-12-19 16:21:00,http://www.bdo.com,Consulting
71,FULLTIME,Data Engineer,https://uk.linkedin.com/jobs/view/data-engineer-at-loyaltylion-3787694613,"LoyaltyLion is a data-driven loyalty and engagement platform trusted by thousands of ecommerce brands worldwide. Merchants use LoyaltyLion when they want a loyalty program that is proven to increase customer engagement, retention and spend. Stores using LoyaltyLion typically generate at least $15 for every $1 they spend on the platform.

Today LoyaltyLion works with over 10,000 small and medium sized retailers. Our mission is to help them succeed in the age of Amazon, where they may not be able to compete on price and logistics but can offer a better customer experience. An experience where customers feel valued, rather than just another number.

It’s been an incredible two years for LoyaltyLion. We closed $12.5m early last year and another $12m this year, and we’ve grown from 40 employees to over 100. We’ve built out our Leadership team, recruiting a CTO, CFO and Director of Product amongst other senior hires and we continue to scale quickly, achieving spots in both the Deloitte Fast 50 and the FT1000. This is just the beginning of our inflection point.

The Role

As a Data Engineer you will be building data applications, delivering high quality code with performance and scalability in mind. Eventually, mentoring more junior engineers. Working with the Tech Lead on designing architecture. Continuously improving your own skills to get the team and self to achieve best results. We are looking for an individual to take part in the building of our data platform and support the team’s and company’s growth. Our data stack will rely mostly on the Python & SQL language and it includes technologies like Apache Airflow, Docker, Rabbit MQ, dbt, Superset, Cube etc. and we’re looking to deploy AWS products like S3, Redshift, and Athena.

Company Benefits

We’re currently operating on a hybrid model, with a mix of home and office-based work from our new HQ on Farringdon In addition to this we offer:
• Remote and flexible working
• 25 days holiday + bank holidays + carry 5 days holiday over into the next holiday year
• Length of service leave (+1 day for every year, up to 5 years)
• All permanent employees get equity to recognise the valuable contribution you'll make to our growth (UK & US employee only)
• International Remote Working Policy (up to 30 days per holiday year)
• Company days out and events, and team socials
• Home office budget
• Cycle scheme
• Employee Assistance Program
• Private medical insurance
• Life Assurance (upto 4 x annual salary)
• Learning and development budget
• The opportunity to join at a major inflection point – ecommerce is booming and with it, the demand for loyalty software like LoyaltyLion
• Macbook, magic keyboard, and any other tech or equipment you need to do a great job

Interview Process
• TA Screen
• Technical Overview + Value based interview
• Tech Session + Q&A with Engineering Team
• Meet the CTO",London,GB,2023-12-19 11:50:00,http://loyaltylion.com,Consulting
72,FULLTIME,Entry Level Data Analyst (Night Shift),https://uk.linkedin.com/jobs/view/entry-level-data-analyst-night-shift-at-careeraddict-3788416180,"Your new role

Our client is looking for a junior data admin to join their UK team in an exciting rollout project in North America. This means you will be working alongside their timezone and will be working during unsociable hours.

Your Responsibilities Include (but Are Not Limited To)
• Acting out as the main point of contact for the technicians based in North America with any installation queries
• Undertake data configuration changes on their software
• Checking system reports, identifying any anomalies and troubleshooting accordingly
• To provide a validation and sign off for successful installation
• Maintain the Master sign off sheets for customer rollouts.

What You/'ll Need To Succeed
• Able to work in unsociable hours (can range from 5pm - 1am)
• Excellent communication skills
• Excel Knowledge
• Willingness to learn
• Ability to be proactive and take initiative
• Right to work within the UK
• 5 GCSEs minimum including English and Maths

What You/'ll Get In Return
• £25,000 per annum salary
• 30 Days Holiday
• Remote working (but an odd day in the Milton Keynes office now and then)
• Great starting point in your IT career with many opportunities for progression

What You Need To Do Now

If you/'re interested in this role, click 'apply now' to forward an up-to-date copy of your CV

Hays EA is a trading division of Hays Specialist Recruitment Limited and acts as an employment agency for permanent recruitment and employment business for the supply of temporary workers. By applying for this job you accept the T&C's, Privacy Policy and Disclaimers which can be found on our website.",Milton Keynes,GB,2023-12-19 21:57:00,https://www.careeraddict.com,Consulting
73,FULLTIME,Senior AI Data Engineer (UK REMOTE),https://uk.linkedin.com/jobs/view/senior-ai-data-engineer-uk-remote-at-turnitin-3718257764,"Company Description

100% REMOTE MUST BE UK BASED

At Turnitin, an AI-centric leader in the educational and research sectors, we've been innovating and promoting academic integrity for over two decades. We have an established reputation for our advanced solutions, utilized by numerous academic institutions, corporations, and publishers worldwide.

Offering remote work as a default arrangement, we honor individual choices, value diversity, and respect local cultures. However, for those who prefer the office environment, we have multiple locations across the globe including Oakland, Dallas, Pittsburgh, Kyiv (Ukraine), Newcastle (UK), and Utrecht (Netherlands). Our team is diverse, but unified by our commitment to significantly impacting the realm of education.

As a Senior Data Engineer at Turnitin, you will be part of a global team of proactive, supportive, and independent professionals, striving to deliver sophisticated, well-structured AI and data systems. Collaborating closely with different teams within Turnitin, you'll integrate AI and data science across our broad suite of products, further enriching learning, teaching, and academic integrity.

Job Description

Your role as a Senior Data Engineer entails a range of responsibilities, necessitating a balanced skillset:
• AI Data Engineering: Design, build, operate and deploy real-time data pipelines at scale using AI techniques and best practices. Support Turnitin's AI R&D efforts by applying advanced data warehousing, data science, and data engineering technologies. Aim for automation to enable a faster time-to-market and better reusability of new AI initiatives.
• Collaboration: Work in tandem with the AI R&D teams and the Data Platform Team to collect, create, curate and maintain high-quality AI datasets. Ensure alignment of data architecture and data models across different products and platforms.
• Innovation: Unearth insights from Turnitin's rich data resources through innovative research and development.
• Hands-on Involvement: Engage in data engineering and data science tasks as required to support the team and the projects. Conduct and own external data collection efforts - including state of the art prompt engineering techniques - to support the construction of state of the art AI models.
• Communication: Foster clear communication within the team and the organization, and ensure understanding of the company's vision and mission.
• Continuous Learning: Keep abreast of new tools and development strategies, bringing innovative recommendations to leadership.

Qualifications
• At least 4 years of experience in data engineering, ideally focused on enabling and accelerating AI R&D.
• Strong proficiency in Python, Java, and SQL.
• Proficiency with Redshift, Hadoop, Elasticsearch, and cloud platforms (AWS, Azure, GCP).
• Familiarity interacting with AI frameworks including PyTorch and TensorFlow and AI libraries such as Huggingface and Scikit-Learn.
• Experience with Large Language Models (LLMs) and LLM APIs.
• Strong problem-solving, analytical, and communication skills, along with the ability to thrive in a fast-paced, collaborative environment.

Desired Qualifications
• 6+ years of experience in data engineering with a focus on AI and machine learning projects.
• Experience in a technical leadership role.
• Familiarity with natural language processing (NLP) techniques and tools.
• Experience in the education or education technology sectors.
• Experience with data visualization and data communications.

Characteristics for Success
• As a Senior Data Engineer, you should possess:
• A passion for creatively solving complex data problems.
• The ability to work collaboratively and cross-functionally.
• A continuous learning mindset, always striving to improve your skills and knowledge.
• A proven track record of delivering results and ensuring a high level of quality.
• Strong written and verbal communication skills.
• Curiosity about the problems at hand, the field at large, and the best solutions.
• Strong system-level problem-solving skills.

Additional Information

Total Rewards @ Turnitin

Turnitin maintains a Total Rewards package that is competitive within the local job market. People tend to think about their Total Rewards monetarily – solely as regular pay plus bonus or commission. This what they earn in exchange for what they do. However, Turnitin delivers more than just these components. Beyond the intrinsic rewards of making a difference in the lives of educators, administrators, learners and researchers around the world, and thriving in an organization that is free of politics and full of humble, inclusive and collaborative teammates, the extrinsic rewards at Turnitin include generous time off and health and wellness programs that offer choice and flexibility and provide a safety net for the challenges that life presents from time to time. In our Remote-First approach to collaborating, you are also able to work the way that best fits your style and situation – whether that be remote, in one of our offices/rented spaces or hybrid.

Our Mission is to ensure the integrity of global education and meaningfully improve learning outcomes.

Our Values underpin everything we do.
• Customer Centric - We realize our mission to ensure integrity and improve learning outcomes by putting educators and learners at the center of everything we do.
• Passion for Learning - We seek out teammates that are constantly learning and growing and build a workplace which enables them to do so.
• Integrity - We believe integrity is the heartbeat of ExamSoft. It shapes our products, the way we treat each other, and how we work with our customers and vendors.
• Action & Ownership - We have a bias toward action and empower teammates to make decisions.
• One Team - We strive to break down silos, collaborate effectively, and celebrate each other’s successes.
• Global Mindset - We respect local cultures and embrace diversity. We think globally and act locally to maximize our impact on education.

Global Benefits
• Flexible/hybrid working
• Remote First Culture
• Health Care Coverage*
• Tuition Reimbursement*
• Competitive Paid Time Off
• 4 Self-Care Days per year
• National Holidays*
• 3 all-company global holidays (Juneteenth + 2 Founder’s Days)
• Paid Volunteer Time*
• Charitable cContribution Match*
• Monthly Wellness Reimbursement/Home Office Equipment*
• Access to Modern Health (mental health platform)
• Parental Leave*
• Retirement Plan with match/contribution*
• varies by country

Turnitin, LLC is committed to the policy that all persons have equal access to its programs, facilities and employment. We strongly encourage applications from people of color, persons with disabilities, women, and the LGBTQ+ community, regardless of age, gender, religion, marital or veterans status.",London,GB,2023-12-19 12:19:00,http://www.turnitin.com,Consulting
74,INTERN,Graduate Data Science Researcher - 2024,https://onlydatajobs.com/job/299219/Graduate-Data-Science-Researcher-2024,"BAE Systems Digital Intelligence is home to 4,500 digital, cyber and intelligence experts. We work collaboratively across 10 countries to collect, connect and understand complex data, so that governments, nation states, armed forces and commercial businesses can unlock digital advantage in the most demanding environments.

BAE Systems Digital Intelligence

Graduate Data Science Researcher

Start Date: 2024 (July or September)

Base location: Great Baddow

Here at BAE Systems Digital Intelligence, we are committed to helping governments, organisations and society navigate digital threats and opportunities. Whether it's leveraging data to digitally transform operations or securing organisations and nations from cyber threats, we combine our unrivalled security and engineering heritage to help our clients navigate the data-reliant digital landscape.

As the cyber and intelligence arm of BAE Systems, we employ over 4,500 people across 16 countries in North America, APAC, Europe and the Middle East. With our distinguished heritage, we relish the opportunity to transform digital and data practices, defence, intelligence, security and society for government agencies, law enforcement, financial services, and critical infrastructure.

The graduate programme is designed to give you ownership of your career aspirations, supported by training and practical experience to help you succeed. You will be part of our Future Talent Community and be assigned a Career Manager, who will support and guide you throughout your career with us. All of this is designed to complement your career development, fuel your ambition, and give depth to your training and career.

Role Profile

BAE Systems Digital Intelligence Laboratories is seeking to recruit researchers to join our rapidly expanding Data Research group. You will have the opportunity to work on a wide range of Data science research topics for customers across the defence, security and commercial sectors. The Data Research group has a diverse range of teams working in: reinforcement learning, NLP, knowledge graphs and graph based neural nets, AI for RF and EW, sonar and acoustics and you will have the opportunity to work with these colleagues in multi-disciplinary teams. Candidates will have the opportunity to mix technical challenges with customer-facing and project support tasks

This role will involve the following general responsibilities:
• Conduct novel research in given topic areas, often in partnership with leading UK Universities.
• Develop prototypes and proof of concept demonstrator.
• Work effectively both on self-directed projects and in larger project teams.
• Preparation of technical reports and technical proposals.

Who are we looking for?

We are looking for candidates who are adaptable, enthusiastic and highly motivated. You should be keen to develop skills in Artificial Intelligence and Machine Learning and will need to be a proficient programmer, preferably in Python. Ideally you will have an MSc or an equivalent level of expertise, with some existing experience in the application of deep learning. An appetite for working in a secure environment is desirable but not essential. Experience in software development in Python is essential and some experience with machine and deep learning frameworks (TensorFlow, Pytorch, scikit-learn, etc.) is desirable. In addition to a solid academic background and excellent written and verbal communication skills, we are interested in candidates with experience in disciplines such as Mathematics, Computer Science, Data Science, Statistics, Economics, Theoretical Physics and Biosciences with statistics.

What's in it for you?
• Work-life balance is important; you'll get 25 days holiday a year and, via our flexible benefits package the option to buy/sell and carry over from the year before
• Our flexible benefits package includes; private medical and dental insurance, a competitive pension scheme, cycle to work scheme, taste cards and more
• You'll have a dedicated Career Manager to help you develop your career and guide you on your journey through BAE
• You are welcome to join any/all of our Diversity and Support groups. These groups cover everything from gender diversity to mental health and wellbeing.
• £34,000 starting salary, rising over the course of the programme
• £2,000 welcome payment

Entry Requirements
• On track to achieve/ already achieved a 2:2 or above in a Science, Technology, Engineering or Maths subject
• You will need to have graduated within the last 3 years

Security Clearance

Only those with the permanent and unrestricted right to live and work in the UK will be considered for a position within BAE Systems Digital Intelligence. Due to the nature of our work, successful candidates for this role will be required to go through Government SC clearance prior to starting with us. https://www.gov.uk/guidance/security-vetting-and-clearance

What are the next steps?
• CV submission & review
• Digital assessment
• Live Interview

Life at BAE Systems Digital Intelligence

We are embracing Hybrid Working. This means you and your colleagues may be working in different locations, such as from home, another BAE Systems office or client site, some or all of the time, and work might be going on at different times of the day.

By embracing technology, we can interact, collaborate and create together, even when we're working remotely from one another. Hybrid Working allows for increased flexibility in when and where we work, helping us to balance our work and personal life more effectively, and enhance well-being.

Diversity and inclusion are integral to the success of BAE Systems Digital Intelligence. We are proud to have an organisational culture where employees with varying perspectives, skills, life experiences and backgrounds - the best and brightest minds - can work together to achieve excellence and realise individual and organisational potential.

Division overview: Capabilities

At BAE Systems Digital Intelligence, we pride ourselves in being a leader in the cyber defence industry, and Capabilities is the engine that keeps the business moving forward. It is the largest area of Digital Intelligence, containing our Engineering, Consulting and Project Management teams that design and implement the defence solutions and digital transformation projects that make us a globally recognised brand in both the public and private sector.

As a member of the Capabilities team, you will be creating and managing the solutions that earn us our place in an ever changing digital world. We all have a role to play in defending our clients, and this is yours.

Job Title: Graduate Data Science Researcher - 2024

Job City: Great Baddow

Professional Area: Graduates and Students

Job Req ID: 120387",London,GB,2023-12-19 12:18:00,http://www.baesystems.com,Manufacturing
75,FULLTIME,Lead Data Analyst,https://gb.bebee.com/job/20231220-31189d42b9b8ef48a852fa3ed81fa26f,"We are currently seeking a Lead Data Analyst to join the Data & Analytics Team located in our RDD office. We are responsible for global reporting and analysis of projects during product development. The team play a vital role in supporting the engineering function of approx. 4000 technicians, scientists and engineers worldwide.

The Data & Analytics Team enable data driven decisions within Product Development using visual analytics. We specialise in data modelling, data engineering, data analysis and reporting. Ultimately, we want to empower everyone in Product Development to have access to data at their fingertips to answer any question they pose.

This is what we need you to do

The Lead Data Analyst will be the first member of the Data & Analytics team based in the Philippines, so we are looking for a strong leader to establish the teams presence and ensure the reporting needs of the local business stakeholders are met and surpassed. They will drive end to end delivery and have responsibility for delivery of insightful data and analysis.

The role requires a candidate who displays excellent business focus, sound technical skills as well as clear leadership qualities.
• Lead concurrent projects on behalf of the data and analytics team in the country
• Develop great relationships with business teams by fully empathising with their needs
• Mentoring and supporting more junior team members as the team grows
• Support and maintain existing reports and dashboards
• Capture clear requirements and Iterate report solutions by design, build and test methodology
• Contribute to the strategy of the data team
• Collaborate with the data Modelling and IT team members to enhance the data platform

This is what we need you to have
• Experience of successful leadership of data teams
• 5 years+ developing business reports and providing analytical support to business functions.
• Experience of working with large and complex data sets Data warehouses, Cloud Data Analysis (BigQuery) and using visualisation software ( Tableau).
• Familiar with ETL and data science pipelines, confident and competent with SQL
• Excellent communication skills & creative problem solving approach
• An understanding of how to interpret customer business needs and translate them into technical requirements
• Enthusiasm to analyse data and drive actionable insight
• Examples of leading data initiatives that have delivered clear benefit
• Interest in how business works and desire to improve our performance
• Self-motivated, dynamic and results-driven
• Team player, comfortable dealing with all business levels and external suppliers
• Ability to deliver under pressure and within a changing landscape

Dyson Benefits:

At Dyson we combine work life balance, with the latest devices, a relaxed dress code reflecting our engineering spirit. It's an exciting team environment geared to fueling and realizing ambition. Benefits include:
• All benefits are accessible from day 1
• HMO coverage. Health & wellness is one of our priorities, immediately available for you & dependents so no waiting for employment regularization
• Up to 20 days annual leave based on employment service + 15 days medical leave
• Dyson product gift upon employment regularization, and discounts on Dyson machines
• Exposure to a broad and diverse range of Dyson activities from research through manufacturing and global sales for Dyson projects
• Career development and growth in a global team",Malmesbury,GB,2023-12-20 02:07:00,http://www.dyson.co.uk,Manufacturing
76,FULLTIME,Data Engineer,https://gb.bebee.com/job/20231220-96695f74a79ba7651902ea892858b45a,"Software Developer
• CONTRACTLondon (Hybrid)Data warehousing
• Databricks
• Trading
• Credit/Market RiskHarrington Starr is working with a leading Energy trading firm in London on an initial 6 month contract for a market leading project.
The project is signed off and they are looking to start interviewing ASAP.

Responsibilities:
Azure Cloud Data Engineering using Azure DatabricksData WarehousingData EngineeringVery strong with the Microsoft StackESSENTIAL knowledge of PySpark clustersPython & C# Scripting experienceExperience of message queues (Kafka)Experience of containerization (Docker)FINANCIAL SERVICES EXPERIENCE (Energy/commodities trading)If you have the above, please do apply right",London,GB,2023-12-20 02:50:00,http://www.harringtonstarr.com,Consulting
77,FULLTIME,Data Engineer,https://uk.linkedin.com/jobs/view/data-engineer-at-newday-3755720508,"Your new role At NewDay

This position needs someone with energy and passion to complement our existing development team, to contribute to our existing projects as well as work on strategic new projects. In this role you must have a desire to deliver high quality output within challenging timeline. The ability to hit the deck running and make valuable contributions quickly will be critical.

0-12 months you’ll deliver
• Hands on development on Nexus Platform
• Monitoring daily BAU data pipelines and ensure our data solution is refreshed up to date every day
• Enhance the daily BAU process. Making it easier to monitor and less likely to fail and hands on development on Data Lake build, change and defect fix
• Building new data pipelines using existing frameworks and patterns
• Working with the team within an Agile framework using agile methodology tooling that controls our development and CI/CD release processes
• Contributing to the new Data Lake technology across the organisation to address a broad set of use cases across data science and data warehousing

What You’ll Bring
• Experience with data solution BAU processes (ETL, table refresh etc.)
• Experience with integration of data from multiple data sources
• Experience in Big Data data integration technologies such as Spark, Scala, Kafka
• Experience in programming language such as Python or Scala.
• Analytical and problem-solving skills, applied to data solution
• Experience of CI/CD
• Good aptitude in multi-threading and concurrency concepts
• Familiarity with the fundamentals of Linux scripting language

And would love you to know or learn:
• Experience of ETL technologies
• AWS exposure (Athena, Glue, EMR, Step functions)
• Experience of Snowflake and DBT
• Experience with data solution BAU processes (ETL, table refresh etc
• Previous proficiency with ETL technologies (e.g. Talend, Informatica, Abinitio)
• Previous exposure to Python
• Previous exposure to own data solution BAU monitoring and enhancement
• Exposure to building applications for a cloud environment

About NewDay

We help people move forward with credit,

and help our colleagues to move their careers forward too.

We use our highly flexible, scalable, and multi-product digital credit engine to power over 120 million transactions every year. Our brands include Aqua, marbles, fluid and Bip. We partner with leading brands such as John Lewis, AO, Argos and DEKO.

Over 5 million UK customers are supported by our award-winning customer service.

At NewDay, we value all types of diversity. We’re an equal opportunity employer and believe that our differences create a vibrant, authentic working culture. We want all our colleagues to feel able to bring their whole selves to work. We don’t discriminate on the basis of age, physical or mental disability, gender reassignment, marriage and civil partnership, pregnancy and carer status, race (including colour, nationality, and ethnic or national origin), religion or belief, sex and sexual orientation. We make sure that every job is crafted to be inclusive and that people with disabilities or caring responsibilities can take part in the application and interview process. Tell us if you need accommodations: we’ll put reasonable adjustments in place to support you.

Our dynamic NewDay culture

We’re focused on what will drive impact in helping people move forward with credit. Our distinctive culture is geared to spark innovation and team working – with lots of open doors for development. Our customers can rely on us because we aim high, support each other, do the right thing and build for the future.

We invest in our colleagues. On top of a strong market competitive salary, you get a bonus opportunity that matches the impact (delivery + values) you drive in your role. We also help you retire better with market leading pensions.

At NewDay, #yourwellbeing matters: You get 26 days holiday and can buy up to 5 more after probation. Then you’ll get extra days as you build your career with us.

NewWork, our flexible, hybrid working approach, helps you to manage your work/life balance - and even bolt on work time in other countries before or after your holiday. And when you’re in the office, you get free healthy breakfast, fresh juices, lunch, barista coffee etc

Our tax efficient green car and cycle to work schemes save you money (and help the planet).

Ask your Talent Acquisition Partner to tell you more about any of our perks.

Where next?

We work with Textio to make our job design and hiring inclusive

In the NewDay Tech team, you’ll join an Expert or Leader career pathway. This will guide you on what your next step here could look like, with regular and open feedback to help you build capabilities to move forward.

Let’s talk about this role – contact talent@newday.co.uk",London,GB,2023-12-19 14:32:00,http://newday.co.uk,Finance
78,FULLTIME,Data Engineer,https://uk.linkedin.com/jobs/view/data-engineer-at-rs-uk-ireland-3771282765,"We are looking for an exceptional Senior Data Engineer to join our team and help us achieve our ambitious growth targets. As part of our dynamic and collaborative Marketing community, you will have the opportunity to work within our Commercial Insights team, helping to deliver decision science solutions to RS Group Marketing and Sales.

You will be responsible for designing, building, and maintaining the infrastructure necessary to unlock the full potential of our data sources. This includes working closely with stakeholders to understand their requirements and ensuring the accurate collection, processing, and accessibility of data.

By joining our team, you will play a crucial role in enabling our Data Scientists to extract maximum value from the available data sources. You will also support the wider Commercial Insights team and contribute to our goal of delivering sustainable and profitable growth while driving down costs.

What you will be doing:
• Design and implement data engineering solutions based on requirements from the Data Scientists and Analysts or directly from stakeholders.
• Building highly scalable data pipelines leveraging online, offline and 3rd party data sources.
• Processing large amounts of data using appropriate technology (e.g. SQL, Python, Hadoop, Spark, etc).
• Optimising and maintaining existing data pipelines to improve performance, data quality and increasing business impact.
• Become a subject matter expert on available data within the business.
• Understanding data requirements, adding value where possible.
• Explore new data management and processing techniques, making recommendations where appropriate.
• Follow best practices to ensure pipelines are scalable and automated in a production environment.
• Work closely with the Martech team on the integration of data across our technology platforms identifying and fixing errors and blockers as they occur.
• Identify new ways to automate processes through ETL and data management to support the required levels of operational stability and scalability.
• Implement and maintain data security and privacy measures.
• Take data briefs from non-technical colleagues and translate these into data supply and pipelines sufficient to support Data Science and analytics.

What we are looking for from you :
• Minimum of 5 years’ experience in ETL design, implementation, and maintenance.
• Strong SQL Skills and robust knowledge of data wrangling techniques.
• Knowledge of data development in a big data environment, and/or traditional data warehouses/toolsets using SQL based ETL capabilities (e.g., SSIS)
• Hands-on experience with big data application development and/or with cloud data warehousing (e.g., Hadoop, Spark, Redshift, Snowflake, GCP BigQuery)
• Hands-on project experience with scripting/programming languages and supporting languages such as Python
• Hands on experience with Data science platforms, such as Dataiku, Syntasa, KNIME, Alteryx.
• Hands on experience with data integration products e.g., Talend.
• Experience in optimisation and improving existing data pipelines and BI solutions.
• Experience and understanding of cloud data engineering e.g., Azure, AWS, GCP.
• Experience of the usage of API’s and consuming data for analysis purposes.
• Experience working with cloud data warehouses such as Redshift, Snowflake, or BigQuery.

Who are we?

RS Group is a global omni-channel solutions partner for industrial customers and suppliers. Our business has operations in three geographical regions – the Americas, EMEA and APAC, supported by global organisations for supply chain, corporate functions, marketing, and product & supplier management.

Our market today is large, fragmented, local in nature and digitally immature. Only a few international distributors serve it, with many regional and local providers, who largely trade offline. Currently we estimate the global market value to be c.£400bn, with our global market share <1%. We stock over 2,500 supplier brands, 500k products and 63% of our sales are digital.

We are going through a period of change, as part of our Destination 2025 strategy, which positions us as becoming first choice for customer, suppliers, people, and communities. Our strategic priorities are:
• Best customer and supplier experience
• High-performance team
• Operational excellence
• Innovation
• Reinvestment to accelerate growth

We’ve been on an incredible journey, but the best is yet to come; are you ready to join us?

Benefits

At RS, as well as the usual employee benefits that you’d expect from a FTSE listed company which include annual performance bonus, private healthcare and generous holiday entitlement, in the UK&I, we’ve just introduced a number of new Family Friendly Policies including:
• Help for people to take control of ongoing Health conditions such as diabetes or asthma with £500 a year available for monitoring & consultation
• Support for Neurodiverse colleagues and families with neurodiverse members with needs assessment, diagnosis and post diagnostic support for autism spectrum, ADHD and Tourette’s syndrome
• Support for Women at different life stages from streamlined fertility support through to diagnosis and monitoring of both endometriosis and menopause
• Helping our LGBTQ+ community through enhanced coverage for trans colleagues, including voice coaching, facial surgery and gender confirmation surgery

Additions to Fertility coverage including IVF for lesbian couples and information/support around surrogacy and adoption for all

We are RS Group.

Our Vision is to be first choice for all our stakeholders, and we know that starts with our people. At RS we want everyone to show up to work as themselves and know that they will be supported and encouraged to develop and grow. We want work to be a place that excites and empowers, a place where you can be passionate and challenge people to think differently.

We want to hire the best talent, people who share our values and understand that when we act with respect and humility, we can do great things. That’s why we’ve put our purpose at the heart of our organisation, we want to make amazing happen for a better world. We empower our people to make a difference, innovate to make more possible and deliver to make it happen.

Are you ready to explore the possibilities?",London,GB,2023-12-19 13:27:00,http://www.bdo.com,Consulting
79,FULLTIME,Data Scientist,https://gb.bebee.com/job/20231219-4b124c77b8c0fb0eb076995e5f985a13,"I'm working with a 60BN$ alternative hedge fund who have become known as one of Londons best destinations for technologists. They strive to integrate technology and trading so that the firm is governed by the latest technological and financial tools.

Symptomatically of this, they're looking for a Data Engineer to come into their ingestion team, to work with large scale and varied data-sets needed by the firm. The team are ingesting these data-sets from market data providers and working closely with cloud and investment teams to build a bespoke platform.

Stack: Python, ETL, Spark, Airflow, AWS

The team have hired from rival funds, and also start ups and large tech firms. The emphasis is ability with back-end/data engineering and a passion for data sets, rather than industry background.

If you would like the chance to work with some of the worlds best technologists and investment professionals, then please apply",London,GB,2023-12-19 19:45:00,http://www.bdo.com,Consulting
80,FULLTIME,Freelance/Consultant - Data Engineer,https://uk.linkedin.com/jobs/view/freelance-consultant-data-engineer-at-pastest-3788152850,"We're looking for a freelance/consultant ""Data Engineer"" to join our team.Must be based in the UK, as travel to our Knutsford offices may be required.Key Requirements:Proficient in Power BI: Demonstrated experience in working with Power BI to create, customise, and update data reports.

Data Visualisation: Strong ability to design and implement visually appealing and insightful data visualisations within Power BI.

Data Integration: Experience in integrating data from various sources into Power BI for comprehensive reporting.

Troubleshooting and Maintenance: Capability to troubleshoot issues within Power BI reports and perform routine maintenance to ensure smooth operation.

Must Have Knowledge Of

Power BI - (Creation and maintenance of reports/workspaces)

Python/SQL

Please email us with your CV/Qualifications, availability and your hourly rate.",Knutsford,GB,2023-12-19 17:54:00,http://www.bdo.com,Consulting
81,FULLTIME,Data Analyst,https://uk.linkedin.com/jobs/view/data-analyst-at-black-sheep-coffee-3754915793,"Contract type: Permanent

Location: SE1, London

Reports to: Data Analyst

Department: Finance

Position Overview

An exciting and wide-ranging opportunity for a proven data analyst in a rapidly scaling retail business to enable data-driven strategic decision making.

This role works across many data sources, including inventory, workforce, sales, products and socials with this list continuously growing! This role requires partnering with all aspects of the business, deriving insights from our data sources and presenting this back to inform our leaders with the quality information they need to make important strategic and day to day decisions. This role is fundamental to our growth and ability to change and react quickly and you have a direct impact on our direction, decisions and growth.

Role responsibilities
• Utilise Power BI to design, develop, and implement visually appealing and interactive reports, dashboards, and data visualizations based on diverse data sources.
• Collaborate with cross-functional teams to understand reporting requirements and translate them into effective visualizations and reporting solutions.
• Extract and manipulate data from different sources to ensure accuracy, consistency, and reliability of reports.
• Maintain and optimize existing Power BI reports, continuously improving data visualisation techniques and report performance.
• Identify trends, patterns, and opportunities within the data to provide actionable insights for various business functions.
• Support stakeholders by presenting and explaining the insights derived from the reports, helping them make informed decisions.
• Proactively monitor data quality and integrity, resolving issues and ensuring data accuracy.

Essential requirements – Skills, Qualifications & Experience
• Proven experience (1 year) working with Power BI and creating reports, dashboards, and data visualizations.
• 2:1 or higher in a STEM degree
• Strong understanding of data analysis, data visualization principles, and statistical methodologies.
• Proficiency in SQL and data querying, extracting, and manipulation skills.
• Familiarity with various data sources and data modelling.
• Excellent analytical and problem-solving skills.
• Ability to communicate complex findings and insights to non-technical stakeholders.
• Detail-oriented with a strong sense of ownership and accountability.
• Proactive and able to work independently or in a team environment.

About Black Sheep Coffee…

Join the thriving team at Black Sheep Coffee, the rapidly expanding 4th largest coffee chain in the UK. With our sights set on further growth, this is an exciting opportunity to be part of our success story.

Since our establishment in 2013, we have captivated coffee lovers with our commitment to quality and innovation. As a testament to our dedication, we have risen to become one of the leading players in the UK coffee scene.

With our continuous expansion plans, there has never been a more exciting time to join us. As a member of our team, you will have the chance to contribute to our upward trajectory and be part of our ambitious journey towards shaping the future of the coffee industry.

We foster a dynamic and collaborative work environment where your ideas are valued, and your professional growth is encouraged. With a strong emphasis on teamwork and a passion for excellence, we provide a supportive platform for you to thrive and make a meaningful impact.

Don't miss the opportunity to be part of a rapidly growing company that values innovation, quality, and the power of exceptional coffee. Join Black Sheep Coffee today and embark on a rewarding career that offers unlimited potential.",London,GB,2023-12-19 15:34:00,http://www.leavetheherdbehind.com,Consulting
82,FULLTIME,Financial Services - Data Consultants/Data Governance Consultants/Data Engineers,https://uk.linkedin.com/jobs/view/financial-services-data-consultants-data-governance-consultants-data-engineers-at-baringa-3667453239,"Overview:

We set out to build the world’s most trusted consulting firm – creating lasting impact for clients and pioneering a positive, people-first way of working. We work with everyone from FTSE 100 names to bright new start-ups, in every sector.

You’ll find us collaborating shoulder-to-shoulder with our clients, from the big picture right down to the detail: helping them define their strategy, deliver complex change, spot the right commercial opportunities, manage risk or bring their purpose and sustainability goals to life. Our clients love how we get to know what makes their businesses tick – slotting seamlessly into their teams and being proudly geeky about solving their challenges.

We have hubs in Europe, the US, Asia and Australia, and we work all around the world – from a wind farm in Wyoming to a boardroom in Berlin. Find us wherever there’s a challenge to be tackled and an impact to be made.

Baringa believe that diversity is paramount to driving creativity, innovation, and value for our clients and for our people, and creating an environment where everyone feels a sense of belonging is central to our culture.

Our Data Data Analytics & AI practice

Our Data Analytics & AI team really likes helping our clients solve their complex problems with data, by implementing controls and governance of data, creating actionable insights, embedding machine learning solutions or building data platforms. We bring the right team and skills on the table and can offer deep expertise across Data Strategy, Data Science & Engineering, Data Visualisation, Data Management, Data Architecture and Software Development.

We are looking for Data Consultants, Data Governance Consultants and Data Engineers with experience or keen interest in the Financial Services Industry to join our growing Data Analytics & AI practice. This is a unique opportunity to join an exciting, growing team but with the backing of a much larger and more established business. You will have the opportunity to work on a wide range of exciting and innovative projects, all whilst playing an integral role in growing our data practice.

What will you be doing?

Typical Engagements Include:
• - Solving problems end to end: from working with C-level executives on strategy around a particular business problem, such as understanding customers better, all the way down to designing and building a technical solution that helps realise that strategy
• Defining operating models for data oriented functions, like data engineering teams, data science teams or teams focused on data visualisation
• Perform maturity assessments across our clients’ data capabilities and recommending changes to improve their capabilities.
• Defining and implementing cloud solutions. Examples of these architectures could be to implement a cloud data warehouse, data lake or a data platform to enable digital transformation
• Define and implement end to end data architecture including data pipelines and data models
• Build technology blueprints and provide guidance on different technology options
• Help our clients to identify risks and mitigations for their complex data programmes and problems

So, what are we looking for?

We are looking to fulfil three separate profiles.

We’re looking for experienced consultants (or those with consulting skills gained in industry) who can both advise our clients and, when needed, get hands on in bringing a solution to life.

If the below roles are of interest to you, but you don’t meet the majority of the below requirements or do not have 3 years of relevant experience, please do apply anyway. We are always on the lookout for high potential individuals earlier in their career who we can invest in, over time.

Financial Services Data Consultants (Senior Consultant and Manager grade, 3-8 years of experience)
• You have some background within the Financial Services industry or a keen interest in it
• You bring mix of technical and core consulting skills
• You are a passionate and dynamic individual who is excited by how you can solve problems with data
• You are a ‘life long learner’ and can demonstrate a drive to always be learning and developing your skillset
• You lead from the front and can demonstrate your ability to own and run complex client engagements (or workstreams), interacting with leaders across industry

Additionally You:
• Are a technologist at heart and live and breathe learning new things within this space
• You work independently and have experience leading workstreams or small consulting teams
• Have a track record of working on data strategy, operating model design and programme delivery within data
• Strong understanding of modern data best practices, engineering best practices as well as solution design
• You can advise on critical topics within the data space such as big data, modern architecture (such as service oriented architectures), as well as cloud and data science
• Have working knowledge of common data governance approaches and controls
• You are comfortable advising senior clients on data oriented business problems
• You have some past or present experience being “hands on” with data, in any technology or language

Great If You Are Also:
• Proficient in a modern programming language such as Python
• Past experience working with the Spark framework or other “Big Data” frameworks
• Hands-on experience with AWS, Azure or GCP
• Experience with business development, proposal writing and commercial discussions

Financial Services Data Engineers (Senior Consultant and Manager grade, 3-8 years of experience)
• You have some background within the Financial Services industry or a keen interest in it
• You bring mix of technical and core consulting skills
• You are a passionate and dynamic individual who is excited by how you can solve problems with data
• You are a ‘life long learner’ and can demonstrate a drive to always be learning and developing your skillset
• You lead from the front and can demonstrate your ability to own and run complex client engagements (or workstreams), interacting with leaders across industry

Additionally You:
• Are a technologist at heart and live and breathe learning new things within this space
• You work independently and have experience leading engineering teams and developing more junior engineers
• Are proficient in Python and SQL
• Are keen on engineering hygiene such as, such as common workflows with git, writing proper unit tests, integration tests and regression tests
• Can write code which is fit for automated deployment and build
• Have experience working with the Spark framework in platform such as Glue, Databricks, EMR or Hadoop
• You can work with IAAS systems such as Terraform, CloudFormation or ARM
• Are proficient in defining a software architecture
• Not afraid of trying and learning new frameworks
• Hands-on experience with AWS, Azure or GCP

Great If You Also:
• Can show experience in advising clients on what best practice looks like in engineering and/or data science teams
• Can advise clients on solution architecture and design
• Experience building CI/CD pipelines in Azure DevOps or another comparable system (Jenkins, CodePipelines etc.)
• Can work in Serverless (Lambda, Azure Functions) or other similar light weight execution environments
• Proficient in working with REST APIs and are familiar with common architectures and software solutions for APIs of this type
• Have experience building real-time or event driven solutions
• Proficient in containerised architectures and container orchestration solutions such as Kubernetes

Financial Services Data Governance Consultant (Senior Consultant and Manager grade, 3-8 years of experience)
• You have some background within the Financial Services industry or a keen interest in it
• You bring mix of data management subject matter expertise and core consulting skills
• You are a passionate and dynamic individual who is excited by how you can solve problems with data and deliver value through data governance
• You are a ‘life-long learner’ and can demonstrate a drive to always be learning and developing your skillset
• You lead from the front and can demonstrate your ability to own and run complex client engagements (or workstreams), interacting with leaders across industry

Additionally You:
• Have experience in the practical application of several of the following disciplines, including people, processes and technology solutions:
• Data Management, Data Governance, Data Architecture, Data Quality, Metadata, Data lineage, Financial Reporting, Risk Reporting, Liquidity Reporting, Controls Automation, - Data Literacy, Data Culture
• Have worked on regulatory project and understand how to deliver in a way that meets the expectations of second line of defence, internal audit and regulators, such as the PRA, FCA, Fed, OCC and others
• Are familiar with how to build and operate data risk management control environments in financial services, to meet requirements such as GDPR/Data Protection, Data Retention and Deletion, BCBS239 Risk Data Aggregation & Risk Reporting, responses to regulatory requests relating to data
• Are adept at engaging with stakeholders at various different levels, from senior executives to practitioners and technical staff
• Focus on delivering value through data management – not just tick-box approaches
• Seek opportunities to leverage technology to deliver business benefit, such as through automation
• Work independently and have experience leading data management teams and developing more junior data management team members

Great If You Also:
• Have a technical background and can advise on data architecture
• Have experience in implementing Data Management in the Cloud (e.g. AWS, Azure, GCP)
• Have experience working across several financial services functions, from customer-facing and front office functions, to central functions such as marketing, HR, finance, risk, treasury and financial crime

So, what's in it for you?

Well, it’s up to you. Baringa is what you make it.
• - Promotion is solely based on your own performance, and we give you every opportunity to progress by having four promotional reviews a year
• - We’re proud to put people first with wellbeing at the forefront of our culture, one example of this is that every employee receives £300 a year to put towards their wellbeing! In 2022 this was recognised in our #1 ranking in the UK’s Great Place To Work 'Best Workplaces for Wellbeing'.
• - All employees participate in the Baringa Group Profit Share Scheme, which seeks to ensure that everyone has a stake in the success of the company.
• - We recognise everyone needs a well-deserved break - As such we have introduced the ‘Re-charge’ benefit meaning Baringa will offer all employees an additional 2 weeks of paid leave after 5 years continuous service.
• - Lastly, we recognise the importance of work-life balance and we know that the ‘ideal’ balance will vary from person to person and will change at different stages of our working lives. If you require flexible working, please talk to one of our Recruiters about the flexibility you may need.

Diversity & Inclusion

All applications will receive consideration for employment without regard to race, ethnicity, religion, gender, gender identity or expression, sexual orientation, nationality, disability, age, faith or social background. We are proud to be an Equal Opportunity Employer.

We would like to actively encourage applications from those who identify with less represented and minority groups. We do not filter applications by university background and encourage those who have taken alternative educational and career paths to apply.",London,GB,2023-12-19 13:21:00,http://www.baringa.com,Consulting
83,FULLTIME,Senior Data Engineer,https://uk.linkedin.com/jobs/view/senior-data-engineer-at-kraken-3736309740,"The energy industry is undergoing the largest transformation since industrialisation at an unprecedented rate of change and we are positioning ourselves to be at the heart of that change.

Our aim is to be the leading global provider of solutions that enable customers to release £30bn of value per annum from distributed energy resources (DERs). We are building a Software as a Service (SaaS) subscription business with a global addressable market of £2.4 billion per annum, by digitally connecting hundreds of thousands of DERs with energy markets.

We have already attained a market leading position and KrakenFlex is a recognised thought leader and innovator in the industry. Our efforts have not gone unnoticed and we are pleased to announce that we now have the full support and backing of Octopus Energy, an award-winning UK energy supplier who share our passion and values.

As we enter the stage of rapid commercialisation and customer account growth, we have a number of exciting new offerings to launch to customers. We’re looking for an exceptional person to help us continuously deliver features that provide value to our customers. Our ideal engineer would be an individual who loves to engage with interesting software problems, with deep experience building, deploying and scaling data-intensive systems and the passion to build and shape the future within a collaborative, community-based environment. We operate a highly agile development approach, giving wide scope to be involved with hands-on system-design, test driven development, deployment and operations.

Our data sources and problems are many and varied. We have some simple but high throughput data sources (e.g. nearly 2,000,000,000 rows a day and growing rapidly), complex unstructured and semi structured data and complex application data from our various microservices.

Our aim is to allow our business and our customers to answer increasingly complex questions, and gain new insights, based on our data, additional external data, and things we can learn and models we can extract from our data.

What You'll Do
• Build, maintain and scale data ingestion and transformation processes in Databricks and AWS Glue that deliver key data and insights to the business and our customers
• Be involved in all stages of the development of innovative data-driven products
• Advocate for best data practices throughout the organisation
• Integrate new data sources into the data platform through APIs or bulk data transfer
• Build and maintain testing and documentation frameworks for our data sources
• Work with the business to scope and deliver new data engineering projects and requirements
• Maintain and build on our existing data infrastructure and tools
• Support the internationalisation of our data infrastructure as we continue to grow globally
• Contribute to the software engineering and data engineering culture here at KrakenFlex
• Collaborate regularly with colleagues with many different professional specialities, including software engineers and data scientists, to create innovative solutions that delight our customers and colleagues
• Work as part of a team of engineers, regularly seeking feedback and growing your skills as technical professionals

What You'll Need
• In depth industry experience in data engineering, software development & design
• Experience in Python and modern SQL analytics environments
• Experience with modern technologies for managing data lakes at scale
• e.g. Databricks, dbt, Spark, Snowflake, Airflow
• A record of getting things shipped in a collaborative, agile development environment
• A desire to mentor and pair with more junior engineers
• Proven experience working with data, both processing and analysing
• A proven ability to perform well in a fast-paced environment
• Excellent analytical and multitasking skills

It would be great if you had
• Experience with BI and/or Analytics tools, e.g. Athena, Tableau, Quicksight
• Experience with AWS or similar cloud providers, and serverless technologies e.g. AWS Lambda, Kinesis, DynamoDB, API Gateway
• Experience developing, securing or operating cloud scale applications or infrastructure; ideally terraform or cloudformation

Ideally you will be based in the Greater Manchester and happy to come into the office a couple of days per week! But we appreciate that things have changed and flexibility is at the top of everyone's agenda, so if you would rather be remote please let us know.

If this sounds like you then we'd love to hear from you.

Studies have shown that some groups of people, like women, are less likely to apply to a role unless they meet 100% of the job requirements. Whoever you are, if you like one of our jobs, we encourage you to apply as you might just be the candidate we hire. Across Octopus, we're looking for genuinely decent people who are honest and empathetic. Our people are our strongest asset and the unique skills and perspectives people bring to the team are the driving force of our success. As an equal opportunity employer, we do not discriminate on the basis of any protected attribute. Our commitment is to provide equal opportunities, an inclusive work environment, and fairness for everyone.",Manchester,GB,2023-12-19 14:31:00,http://www.bdo.com,Consulting
84,FULLTIME,Senior Data Engineer,https://uk.linkedin.com/jobs/view/senior-data-engineer-at-oaknorth-3737910270,"We're looking for senior engineers who are particularly passionate about the back-end and data engineering to join our data platform team. We're looking for someone who can work - or is comfortable in learning to work - just about anywhere in the stack. You'd use both your generalist and specialist skills to better our products and our team. You'd join our data platform squad as an immediate contributor. On day 1, expect to write your first lines of code on your local machine, and get that code deployed to production. In month 1, expect to break something in production - and quickly fix and learn from it! Our squads are cross-functional, mission driven, and autonomous, solving specific user and business problems. We have several product squads - you would initially join data platform but may move around based on squad needs and your fit.

What you’d work on ⛏️

Our squads are cross-functional, mission driven, and autonomous, solving specific user and business problems. We have several product squads that you may rotate through but, initially, this role is on the Data Platform squad. The Data Platform squad look after all internal data products and the data warehouse. It’s a new team which is driving the ONB data strategy and has many opportunities for exciting, greenfield projects.

Technology   
• We're pragmatic about our technology choices. These are some of the things we use at the moment:
•    TypeScript, React, styled-components
•    Python, NodeJS
•   ️ PostgreSQL, BigQuery, MySQL
•    Jest, React Testing Library, Cypress, pytest
• ☁️ AWS, GCP
•    Kubernetes, Docker, Terraform, GitHub, CircleCI

How We Expect You To Work   ♀️
• We expect you to work in these ways, as well as encouraging and enabling these practices from others:
• Collaborate    - We work in cross-functional, mission driven, autonomous squads that gel over time. We pair program to work better through shared experience and knowledge.
• Focus on outcomes over outputs ✅ - Solving a problem for users that translates to business results is our goal. Measurements focused on that goal help us to understand if we are succeeding.
• Practice continuous improvement    - We optimise for feedback now, rather than presume what might be needed in the future and introduce complexity before it will be used. This means we learn faster. We share learnings in blame-free formats, so that we do not repeat things that have failed, but still have confidence to innovate.
• Seek to understand our users    - We constantly seek understanding from data and conversations to better serve our users' needs, taking an active part in research to hear from them directly and regularly.
• Embrace and enable continuous deployment    - Seamless delivery of changes into an environment - without manual intervention - is essential for us to ensure that we are highly productive; consider resiliency; and practice security by design.
• Test outside-in, test first    - TDD keeps us confident in moving fast, and deploying regularly. We want to solve user problems, and so we test with that mindset - writing scenarios first, then considering our solution; coupling tests to behaviour, rather than implementation.
• You build it, you run it ⚙️ - We embrace DevOps culture and end-to-end ownership of products and features. Every engineer, regardless of their role, has the opportunity to lead delivery of features from start to finish.
• Be cloud native ☁️ - We leverage automation and hosted services to deliver resilient, secure services quickly and consistently. Where SaaS tools help us achieve more productivity and better quality results for a cheap price, we use these to automate low value tasks.

How We Expect You To Behave ❤️
• We embrace difference and know that when we can be ourselves at work, we are happier, more motivated and creative. We want to be able to bring our whole selves to work, have our own perspectives and know that we belong. As such, through your behaviours at work, we expect you to reflect and actively sustain a healthy engineering environment that looks like this:
• A wide range of voices heard to the benefit of all
• Teams that are clearly happy, engaged, and laugh together
• Perceivable safety to have an opinion or ask a question
• No egos - people listen to and learn from others at all levels, with strong opinions held loosely

What Makes Working Here Better   
• Flexible working    - A flexible, hybrid team with a dedicated London office available 5 days a week to use as we want to.
• Work-life balance    - 25 days holiday (plus bank holidays) each year, and enhanced family leave allowances.
• Competitive salary & equity    - We want people to have a serious stake in the business.
• Good kit    - Your choice of the best laptop, running macOS or Ubuntu.
• Team socials    - The opportunity to get to know each other outside of work.
• Company socials    - A chance to catch up and meet new colleagues weekly over informal office breakfasts and dinners on OakNorth - or at our free barista bar every day.
• Commuter support    - We offer the cycle to work scheme.

About Us

We’re OakNorth Bank and we embolden entrepreneurs to realise their ambitions, understand their markets, and apply data intelligence to everyday decisions to scale successfully at pace.

Banking should be barrier-free. It’s a belief at our very core, inspired by our entrepreneurial spirit, driven by the unmet financial needs of millions, and delivered by our data-driven tools.

And for those who love helping businesses thrive? Our savings accounts help diversify the high street and create new jobs, all while earning savers some of the highest interest on the market.

But we go beyond finance, to empower our people, encourage professional growth and create an environment where everyone can thrive. We strive to create an inclusive and diverse workplace where people can be themselves and succeed.

Our story

OakNorth Bank was built on the foundations of frustrations with old-school banking. In 2005, when our founders tried to get capital for their data analytics company, the computer said ‘no’. Unfortunately, all major banks in the UK were using the same computer – and it was broken.

Why was it so difficult for a profitable business with impressive cashflow, retained clients, and clear commercial success to get a loan?

The industry was backward-looking and too focused on historic financials, rather than future potential.

So, what if there was a bank, founded by entrepreneurs, for entrepreneurs? One that offered a dramatically better borrowing experience for businesses?

No more what ifs, OakNorth Bank exists.

For more information regarding our Privacy Policy and practices, please visit: https://oaknorth.co.uk/legal/privacy-notice/employees-and-visitors/",London,GB,2023-12-19 16:50:00,http://www.oaknorth.co.uk,Consulting
85,FULLTIME,Senior Data Engineer,https://uk.linkedin.com/jobs/view/senior-data-engineer-at-blend-3766651166,"Company Description

We are looking for a Senior Data Engineer to join the Data Engineering practice for Forth Point which is a Data Science and Engineering company headquartered in Edinburgh UK with plans to grow a large team across EMEA in the next 5 years.

At Forth Point, we are award-winning experts who transform businesses by delivering valuable insights that make a difference. From crafting a data strategy that focuses resources on what will make the biggest difference to your company, to standing up infrastructure, and turning raw data into value through data science and visualisation: we do it all.

We believe that data that doesn't drive value is lost opportunity, and we are passionate about helping our clients drive better outcome through applied analytics.

We are obsessed with delivering world class solutions to our customers through our network of industry leading partners. If this sounds like your kind of challenge, we would love to hear from you.

Job Description

Life as a Senior Data Engineer at Forth Point

We are looking for someone who is ready for the next step in their career and is excited by the idea of solving problems and designing best in class.

However, they also need to be aware of the practicalities of making a difference in the real world – whilst we love innovative advanced solutions, we also believe that sometimes a simple solution can have the most impact.

Our Data Engineer is someone who feels the most comfortable around solving problems, answering questions and proposing solutions. We place a high value on the ability to communicate and translate complex analytical thinking into non-technical and commercially oriented concepts, and experience working on difficult projects and/or with demanding stakeholders is always appreciated.

Reporting to a Lead Data Engineer and working closely with the Data Science and Business Development teams, this role will be responsible for driving high delivery standards and innovation in the company. Typically, this involves delivering data solutions to support the provision of actionable insights for stakeholders.

What can you expect from the role?
• Own tasks end-to-end and lead on project delivery and project governance.
• Management of Data Engineer(s).
• Preparing and presenting data driven solutions to stakeholders.
• Design, develop, deploy and maintain ingestion, transformation and storage solutions.
• Use a variety of Data Engineering tools and methods to deliver.
• Contributing to solutions design and proposal submissions.
• Supporting the development of the data engineering team within Forth Point.
• Maintain in-depth knowledge of data ecosystems and trends.
• Mentor junior colleagues.
• Contributing to proposal submissions and business development initiatives under the direction of the Leadership team.

Qualifications

What you need to have?
• Proven track record of designing, building, deploying an analytical data infrastructure.
• Working knowledge of large-scale data such as data warehouses and their best practices and principles in managing them.
• Experience with development, test and production environments and knowledge and experience of using CI/CD.
• ETL technical design, development and support.
• Advanced level understanding, both conceptually and in practice of Python.
• Traditional relational database and distributed data lake architecture experience.
• Advanced SQL skills both conceptually and in practice.
• Experience of build and delivering a solution in at least one of the cloud platforms (AWS, Azure or GCP).
• Good understanding of enterprise coding best practices as well as general CI/CD practices.
• Top tier Git practices with experience managing repositories with many contributors.
• Self-starter and strong interpersonal skills.
• Effective communication and coaching skills.

Nice to have
• Knowledge in container deployment.
• Experience of creating ARM template design and production (or other IaC, e.g., CloudFormation, Terraform).
• Experience in cloud infrastructure management.
• Experience of Machine Learning deployment.
• Experience in Azure tools and services such as Azure ADFv2, Azure Databricks, Storage, Azure SQL, Synapse and Azure IoT.
• Strong understanding and experience with Scala, Spark, PySpark.
• Experience of leveraging data out of SAP or S/4HANA.
• Management experience.
• Previous experience setting up code review frameworks.
• Good understanding of API connectivity.
• Proven ability to prioritize work and projects.
• Good appreciation for the Agile/Scrum methodology.
• Accustomed to working on multiple projects simultaneously.

Additional Information
• No agencies please.
• Must be eligible to work in the UK, we are currently not able to provide sponsorship.",Edinburgh,GB,2023-12-19 17:38:00,http://www.bdo.com,Consulting
86,FULLTIME,Data Scientist Industrial Placement - ESO,https://uk.linkedin.com/jobs/view/data-scientist-industrial-placement-eso-at-national-grid-eso-3759416450,"About Us

As Great Britain’s electricity system operator (ESO), we sit at the heart of the electricity system, using our outstanding engineering and commercial expertise to balance electricity supply and demand. Ultimately, we keep the electricity flowing directly to where it’s needed, second by second.

Our values and principles

Diversity, equity, and inclusion are at the heart of who we are and what we do. Our commitment to these values is unwavering and they are central to our mission. We encourage applications from all backgrounds, communities and industries and we are happy to discuss any reasonable adjustments that you require.

About The Role

Join us on a 12-month industrial placement to work with and learn from some of the best people in the energy industry! 

 

As an undergraduate with the Electricity System Operator (ESO), you’ll collate, manipulate and interpret real-time (and closer to real-time) data as well as short and long-term forward-looking data to drive efficient resolutions on behalf of consumers. You’ll become a thought-leader on data analytics practices and an inspiration to colleagues and peers right across the industry. 

 

You’ll do vital work at the heart of GB's energy industry, ensuring our high voltage electricity system and the commercial infrastructure that underpins it meet the fast-growing needs of consumers.  

Key Accountabilities
• Collaborate with industry stakeholders to undertake analysis to predict the nation's energy needs in the medium and long term  
• Use and work to improve some of our existing ESO-specific models  
• Interrogate, interpret and visualise large volumes of data, with a view to improving the quality of the data we manipulate and the models we use, bringing in new and innovative techniques as appropriate 
• Investigate the root causes of performance issues, identify and analyse opportunities to improve processes, then recommend and implement sustainable developments 
• Articulate complex situations and technical work to a non-technical audience, and develop your influencing and stakeholder management skills  

What You'll Need

You’re on track to achieve a minimum 2.2 in any STEM or any Data Scientist related degree. 

You must be in your penultimate year at university.

Ideally, you’ll have a valid full UK Driving License. 

Location

This role is based in Wokingham, hybrid working options available and dependent upon business requirement.

Application Deadline

We recruit on a rolling basis and reserve the right to close our vacancies once we have enough applications. We encourage you to apply as early as possible to ensure you obtain the place you want in the application process.

Assessment centres will be held from December 2023 onwards.

What You'll Get

Whatever your specific responsibilities, you'll be surrounded by the leading experts in the industry who are solving some of the biggest energy challenges we have ever seen. The knowledge and understanding of how we keep the lights on that can be understood only within the Electricity System Operator have been the foundations for the careers of many of our company leaders.

We are proud to offer a starting salary of £22,906.

As a first step to your career in the energy industry, our 12-month Undergraduate Programmes are like no other! You’ll gain an insight into how we work at the ESO, exposure to the energy and power industry, develop hands-on experience, and understand what a career with us can offer.

You’ll receive some great rewards and benefits including 26 days’ annual leave plus statutory holidays (pro-rata for 12-week placements), a buddy to support you during your placement, and a Graduate Development Programme opportunity.

#Industrialplacementopportunities2024

More Information

The Government and Ofgem have asked the ESO to take on new roles and responsibilities.

Becoming the Energy Future System Operator is a critical step to help deliver a reliable and clean energy transition for all. The ESO, including all of its existing roles, will be at the heart of the new Future System Operator, taking on additional roles with a whole energy system mindset to drive progress towards net zero while maintaining energy security and minimising costs for consumers.

The new organisation will be set up as a public corporation with operational independence from government – bringing parties together to support optimised decision making and action. As now, it will be licensed and regulated by Ofgem through price control agreements. It is anticipated that the new organisation will be up and running by or in 2024.

The time to act on climate change is now. As part of the team, you won’t just be touching the lives of almost everyone in Great Britain – you’ll be shaping the way we use and consume energy for generations to come.

#Industrialplacement2024

At National Grid, we work towards the highest standards in everything we do, including how we support, value and develop our people. Our aim is to encourage and support employees to thrive and be the best they can be. We celebrate the difference people can bring into our organisation, and welcome and encourage applicants with diverse experiences and backgrounds, and offer flexible and tailored support, at home and in the office.

Our goal is to drive, develop and operate our business in a way that results in a more inclusive culture. All employment is decided on the basis of qualifications, the innovation from diverse teams & perspectives and business need. We are committed to building a workforce so we can represent the communities we serve and have a working environment in which each individual feels valued, respected, fairly treated, and able to reach their full potential.",Wokingham,GB,2023-12-19 13:27:00,https://www.nationalgrideso.com,Consulting
87,FULLTIME,Undergraduate Data Analyst Industrial Placement,https://uk.linkedin.com/jobs/view/undergraduate-data-analyst-industrial-placement-at-lexisnexis-risk-solutions-3735937520,"Undergraduate Data Scientist Placement

The Placement

You will join a structured and well-developed 13-month, non-rotational placement within our Risk Solutions business (www.risk.lexisnexis.co.uk). LexisNexis Risk Solutions is a leader in providing essential information to help customers across industry and government assess, predict and manage risk. We are excited to be seeking a Fraud Analyst placement candidate to join our London based ThreatMetrix® Professional Services team for 13 months, starting July 2024. Whether your specialism is Statistics, Machine Learning or Applied Mathematics our internship is an ideal introduction to how we apply cutting edge technologies to our data in order to provide valuable insight for our customers.

The Role

The goal of the placement is to develop your knowledge and analytical skills so that you are able to contribute to solving real world, end customer problems as part of our ongoing engagements with a wide range of tier 1 global customers. During the placement, you will also gain valuable business insight and core consulting skills that will help them develop into a well-rounded team member.

As a Fraud Analyst intern, you’ll have the opportunity to use global data from the largest real-time digital fraud detection platform to craft solutions for a range of customers. You’ll experience how to leverage real-time digital identity intelligence, analyzing billions of transactions per month for some of the largest companies operating in Financial Services, Insurance, and e-Commerce. These tools will allow you to attain a unique perspective of the Internet and every persona connected to it. You’ll work within a collaborative and supportive environment to grow your personal and problem solving skills and help deliver solutions that will go head-to-head against some of the most motivated attackers in the world to protect billions in revenue.

Apply if you are a:
• Data Programmer: You will need good programming skills in analytical packages to leverage our real time data platform (Python, SQL and R preferable);
• Critical Thinker: A keen eye for detail, accuracy and strong critical thinking skills with advanced judgment capability is needed;
• Analytical problem solver: Strong analytical and problem solving skills are required to solve the challenges facing our customers in an ever changing fraud and risk landscape - numerical degree required;
• Enthusiastic Team Player: We are looking for a candidate who is comfortable working in a collaborative and inclusive team environment.
• Interested in Cybercrime prevention– a desire to understand the latest cybercrime trends and attack methods is required to deliver meaningful and effective risk models
• Studying STEM degrees (All Sciences, Technology, Economics or Maths)

All applicants must have the right to work full time and live in the UK on a permanent basis.

Training & Development

You will receive a blend of technical and people skills development. This is important as it’s not just what you do, but how you do it that is important to us.

Initially you will be immersed into an intensive, but rewarding, 2–3-week induction bootcamp and will be part of a wider graduate community with frequent socials including charity days and diversity and inclusion events. We work to a 70/20/10 learning model with 70% of your learning on the job, 20% informal learning and 10% from formal educational learning.

Life at Lexis Nexis

What really stands us out from the crowd is our culture. We’re an agile, dynamic and forward-thinking organisation who understands the importance of looking after our staff. We pride ourselves on delivering high-quality products, providing our employees with interesting challenges for their personal and career development whilst also striking the right balance between work and personal life.

Please view the information video here: https://www.youtube.com/watch?v=ojhjmhH64O8&feature=emb_imp_woyt

Women in technology

LexisNexis® Risk Solutions Group (RSG) is very supportive of women in Technology and has been a founding signature for the Tech Talent Charter. Currently 27% of our Technology workforce are women which is much higher than the UK average of 17%. We have the following initiatives in place to support women in technology:
• Mentoring Scheme for Women in Technology
• Women’s Network Forum
• Women in Technology Employee Resource Group (ERG)
• RSG proudly support the Tech Talent Charter.

Diversity & Inclusion

At LexisNexis® Risk Solutions Group having diverse employees with different perspectives is key to creating innovative new products for our global customers. We have 35 diversity employee networks globally and prioritise ensuring inclusive leadership is part of our culture. Our aim is for every employee to be the best version of themselves. We actively welcome applications from candidates of diverse backgrounds and underrepresented groups.",London,GB,2023-12-19 15:44:00,https://risk.lexisnexis.com,Consulting
88,FULLTIME,Data Scientist,https://uk.linkedin.com/jobs/view/data-scientist-at-zepz-3765244392,"About Zepz

Zepz is the group powering two leading global remittance brands: WorldRemit and Sendwave. Since 2010, we have been disrupting an industry previously dominated by offline legacy players with our relentless focus on reducing the cost of remittances and increasing safety and convenience for our users. Every day, our people work to unlock the prosperity of cross-border communities through finance and technology - driven by our vision of a world that celebrates migrants’ impact on prosperity, at home and abroad.

Our brands helped cross-border communities send over $15bn from 50 countries to recipients in 130 countries in 2022. We operate over 5,000 money transfer corridors worldwide and employ over 1,000 people globally. Zepz is a remote-first employer, with team members located across six continents.

Our vision is to create a world that celebrates migrants’ impact on prosperity, at home and abroad. Our purpose is to unlock the prosperity of cross-border communities through finance and technology.

Zepz.io

Our Commitments:
• We act like owners - We are relentlessly delivering for our users and spending money thoughtfully.
• We embrace embarrassing honesty - We function best when we're open and honest with one another — especially about our challenges and doubts.
• We have a bias to action - We get to first outcomes quickly, iterate and learn.
• We strive to be better - We may make mistakes, but always learn from them.
• We are inclusive - to better reflect and serve our users.

Your Key Area Of Focus

The main focus of this role initially will be within the marketing & product teams, looking at ways we can improve our customer understanding and optimize our spending and returns, through modeling like MMM, CLV, retention & loyalty. As the role develops there will be other areas of the business that will also need support ie. optimizing performance in the commercial and operations space and looking for anomalies within our data to help spot issues.

You will champion the data science space for these teams, looking for where there are the greatest opportunities to deploy models/algorithms and find the ‘low hanging fruit’.

What You Will Own
• Translate commercial requirements into technical solutions, converting real-world problems into solvable data science projects, resulting in insights that further the strategy and enable visibility into key results
• Designing and implementing new models to improve business performance, whether this is in the marketing, product, or commercial space.
• Improving existing models through greater scrutiny of the methodology and improving the input data
• Own our existing CLV/LTV & MMM models
• Develop a new anomaly detection algorithm, helping us spot strange behaviour in certain countries.
• Develop loyalty models to help retention our customers better
• Develop cost optimization models to help the team understand how to truly optimize their spend
• Evaluate and integrate new data sources for our algorithms, aligning with Data Engineering and Analytical Engineers' best practices for dbt
• Develop strategies and tools to help less technical individuals understand and use the models and results.
• Automate the training and deployment of updated models, ensuring the output is tested, automated, scalable and documented and checks are in place to identify drift.
• Help build experiments to evaluate new models, third-party data sources and tooling.
• Champion the use of Data Science within the business

What you bring to the table:
• 4+ years of professional experience training and deploying models that deliver measurable value (regression, clustering, decision trees, spend optimization etc).
• You have strong SQL skills, confidently able to pull and manipulate data to get into the desired format for modelling (CTEs, joins, case statements, subqueries, an understanding of data types and how to cast them).
• Possess strong Python or R programming skills, able to automate processes and deploy applications. You can develop production standard scripts and perform relevant analysis.
• You are a problem solver who can identify opportunities for data-driven solutions and prioritize against commercial impact
• You are motivated to deeply understand user behaviour and deliver actionable recommendations to teams alongside a strong technical data solution.
• You can confidently discuss complex business and technical topics with a range of stakeholders and present findings
• Work authorization in the country in which you intend to be based.
• Experience in one or more of the following areas:
• Machine Learning (Scikit Learn, Tensorflow, Keras, XGBoost, H2O etc...)
• SQL Analytics (BigQuery, Redshift, Databricks, Athena, etc)
• Visualisation Tools (matlibplot, seaborn, streamlit Looker, Tableau, Periscope, etc)

Bonus points if you
• You have experience with some of the following: CLV/LTV, MMM, churn, loyalty and attribution models, ARIMA.
• Have experience/are comfortable using dbt
• Have a marketing or product experience
• Have experience with experimentation design and evaluation
• You have experience with GA/Adobe or equivalent data and digital marketing/martech stacks
• Demonstrate tenacity and a willingness to go the distance to get something done. You don't mind doing things manually but automate at every opportunity.
• Are inquisitive, intellectually curious and can make sense of complex systems or information.
• Can work in a structured approach towards goals and pay attention to detail.
• Can easily communicate with non-technical folks and translate their feedback into code.
• Are comfortable defaulting to over-communication and overreaching when it comes to coordination
• Adjust quickly to changing priorities and conditions and cope effectively with complexity and change.

Key details
• Team Composition: The Analytics Team is a combination of Analysts, Data Scientists and Analytics Engineers.
• Team Philosophy: The team works on a hub and spoke method - with this role sitting in the hub, meaning that you will help support the entire business, rather than being focused on a particular domain, although there will be a heavy focus on Marketing to begin with.
• Location: Our company is remote first. You can be based anywhere in Africa, Europe, or the Americas
• Length of position: Permanent.

What we offer you: Please note that the benefits below will apply to Full-time roles.

Benefits

We have five core benefits for our talent in the US, UK, Philippines, Poland, and South Africa. If you're not in one of those regions, don’t worry - the Talent team can let you know what is available for you specifically:
• Unlimited Annual Leave: Most Zepz team members are eligible for unlimited annual leave. Colleagues in customer-facing roles, receive a competitive holiday allowance and four recharge days a year. Feel free to make the most of your time off and maintain a healthy work-life balance!
• Private Medical Cover: You can opt-in to a Private Medical Insurance scheme. This provides you with access to thorough medical coverage, so you can feel confident in your health and well-being.
• Retirement: We offer pension schemes to help you plan for and secure your future.
• Life Assurance: Life assurance is available to give you peace of mind and protect your loved ones in case of the unexpected.
• Parental Leave: We offer competitive parental leave schemes to ensure you are spending as much quality time with your new bundle of joy as possible.

We are also remote-first as an organisation, offering flexibility for you to work where you need to be most productive. In many locations, we have workspaces, which you can use as you desire. Most roles in the Philippines are predominately office-based, with this we offer free meals for those 100% on-site.

In addition to the above, you will discover that we have a range of secondary perks (such as the cycle-to-work scheme and employee discounts) depending on your location, to help you thrive at Zepz!

Why choose Zepz?
• Our team of over 1,000 employees is fully distributed across the world. We are working from coffee shops, homes, and co-working spaces — making us one of the larger fully distributed growth-stage startups in the world but we also offer workspace in our talent cluster locations - spaces we can meet, collaborate and connect.
• We are proud parents, community organizers, farmers, band members, yoga teachers, YouTube influencers, former Olympians, and serial entrepreneurs.
• We collectively speak over twenty languages, including Akuapem, Amharic, Bengali, Ewe, Fante, Ga, Igbo, Kalenjin, Luganda, Oromo, Somali, Swahili, Wolof, Bulgarian, Croatian, Czech, Danish, Dutch, English, Estonian, Finnish, French, German, Greek, Hungarian, Irish, Italian, Latvian, Lithuanian, Maltese, Polish, Portuguese, Romanian, Slovak, Slovenian, Spanish and Swedish.
• At Zepz, embodying our commitments binds us together. We are collectively passionate about striving to achieve our vision and purpose - to continue to provide the best service to our users.

Ready to Apply?

Applications will be reviewed on a rolling basis. If interested, please submit your resume along with a cover letter (optional), highlighting why your experience demonstrates you meet the requirements of the role. Please also indicate the countries in which you have work authorization.

Confidence can sometimes hold us back from applying for a job. But we'll let you in on a secret: there's no such thing as a 'perfect' candidate. Zepz is a place where everyone can thrive.

So however you identify and whatever background you bring with you, and if at all you might need any form of support to make the process as comfortable as possible, please let us know and give us a shot by applying. We want you to be excited to wake up to make an impact every day.",London,GB,2023-12-19 14:14:00,http://www.bdo.com,Consulting
89,FULLTIME,NS - Data Engineer,https://uk.linkedin.com/jobs/view/ns-data-engineer-at-bae-systems-digital-intelligence-3768212861,"Location(s): [[mfield3]]

BAE Systems Digital Intelligence is home to 4,500 digital, cyber and intelligence experts. We work collaboratively across 10 countries to collect, connect and understand complex data, so that governments, nation states, armed forces and commercial businesses can unlock digital advantage in the most demanding environments.

We Are Looking For Experienced Data Engineers To Join Our Team Following Continuous Growth And Success. As a Data Engineer You Will Be Involved In
• Design, develop, test and support data collection, data integration and ETL applications to make information and data available to key client stakeholders and technical interfaces
• Model data requirements, data sources and data flows to bring order and structure to programmes of work
• Defining how and where data is created, mastered and destroyed to ensure proper control over the lifecycle of corporate data assets
• Using categories of products that can be used to collect, integrate, store, visualise and govern data and metadata
• Define metadata to provide search ability and governance (including Records Management) for unstructured data.

Not only will your team be directly making a huge impact upon the systems you work on, you’ll be doing it for an organisation who makes a huge impact to the security of the UK.

About You

You will have experience in many of the following:
• Data Engineering, Analysis or Science, with a solid understanding of programming languages along with experience of applying them in your previous role
• Experience in using Data Engineering tools and technology ETL tools including Python and a number of the Big Data Applications. Rather than specifying a list of technologies we look for, demonstrable ability in what you have used previously, along with adaptability and willingness to learn is what we value
• A good understanding of Open Source software for Data Engineering and can evaluate these platforms against products. Given a customer problem you can analyse and evaluate options and recommend solutions.
• An understanding of maintaining and applies up to date, specialist knowledge of database concepts (including unstructured, NoSQL and ”big data” platforms), object and data modelling techniques.
• Previous experience working in the domain of Cyber Security and Intelligence is desirable, but not essential.

Please note that it is essential that you currently hold high level UK security clearance

How We Will Support You
• Work-life balance is important; you can work around core hours with flexible and part-time working, and many of our roles include hybrid working enabling a mix of working from home and in the office
• You’ll get 25 days holiday a year and the option to buy/sell and carry over from the year before
• Our flexible benefits package includes private medical and dental insurance, a competitive pension scheme, cycle to work scheme, taste cards and more
• You’ll have a dedicated Career Manager to help you develop your career and guide you on your journey through BAE
• You’ll be part of our company bonus scheme
• You are welcome to join any/all of our Diversity and Support groups. These groups cover everything from gender diversity to mental health and wellbeing.

About Our Team

Our people are what differentiates us, they are resourceful, innovative and dedicated. We have a mix of generalists and specialists and recognise that this diversity contributes to our success. We recognise the benefits of forming teams from a mix of disciplines, which allows us to come up with cutting edge, high quality solutions. Our breadth of work across the Public Sector provides diverse opportunities for our people to develop their careers in new areas of expertise and with new clients.

You’ll be part of a big company, but we try to create a culture that feels like a small one. The work will stretch you and be challenging, but we encourage a healthy work-life balance. Most of all, we know teams who work well together also perform well. We’ll do everything we can to ensure you have fun at work, and in social activities outside of it whether that’s virtually or in person, as conditions allow.

We have a rich history of working within National Security. In fact, we have over 40 years’ experience of delivering advice and solutions to our customers in this sector, supporting them in carrying out their vital missions.

Life at BAE Systems Digital Intelligence

We are embracing Hybrid Working. This means you and your colleagues may be working in different locations, such as from home, another BAE Systems office or client site, some or all of the time, and work might be going on at different times of the day.

By embracing technology, we can interact, collaborate and create together, even when we’re working remotely from one another. Hybrid Working allows for increased flexibility in when and where we work, helping us to balance our work and personal life more effectively, and enhance well-being.

Diversity and inclusion are integral to the success of BAE Systems Digital Intelligence. We are proud to have an organisational culture where employees with varying perspectives, skills, life experiences and backgrounds – the best and brightest minds – can work together to achieve excellence and realise individual and organisational potential.

Division overview: Capabilities

At BAE Systems Digital Intelligence, we pride ourselves in being a leader in the cyber defence industry, and Capabilities is the engine that keeps the business moving forward. It is the largest area of Digital Intelligence, containing our Engineering, Consulting and Project Management teams that design and implement the defence solutions and digital transformation projects that make us a globally recognised brand in both the public and private sector.

As a member of the Capabilities team, you will be creating and managing the solutions that earn us our place in an ever changing digital world. We all have a role to play in defending our clients, and this is yours.",London,GB,2023-12-19 12:33:00,http://www.detica.com,Computer Services
90,FULLTIME,Net Zero - Senior Data Analyst,https://uk.linkedin.com/jobs/view/net-zero-senior-data-analyst-at-bloomberg-3772160432,"At Bloomberg, we are committed to fighting the battle against climate change. That's why we're taking action, using our expertise in data - and decades of experience leading from the front - to tackle climate change from every angle. Climate change is changing the way market participants allocate capital, and the ability for businesses and investors to understand their climate related impacts, risks, and mitigation pathways is crucial.

Our offerings are fueled by powerful information. We combine data and context to paint the whole picture for our clients, around the clock - from around the world. In Data, we are responsible for delivering this data, news and analytics through innovative technology - quickly and accurately. As a team, we are responsible for the development of Net Zero Transition focused data solutions for Bloomberg, and work across key climate initiatives.

The Role:

As part of the Net Zero Data Management Team, you will have a direct impact on global efforts to fight climate change. As part of the team, you will have an enormous impact on supporting the global financial sector's work to stop climate change and ensuring that financing and capital allocation decisions occur in ways that enable the world to reach net zero by 2050 in line with the objectives of the Paris Agreement.

We'll trust you to:
• Support the team in efforts to develop a framework and operationalization plan for third party data onboarding and data quality.
• Present on data management to senior management, demonstrating key success criteria and ensuring the delivery of goals.
• Work with our research team to embed data quality and control features into their processes for data modelling and mapping.
• Engage with partners to understand business needs and define requirements for forward looking data quality needs, performing data profiling and data analysis to drive decision making.
• Analyze current and -future data quality practices to find opportunities for process improvements and optimizations.
• Construct and maintain data linkage graphs to build better quality, connected datasets.
• Implement business rules for programmatic data validation by codifying jurisdictional requirements and field level relationships.

You'll need to have:
• 5+ years working with sophisticated company disclosure data *
• The ability to work autonomously and take ownership of the development and delivery of key data management projects.
• The ability to communicate complex technical concepts to a wide range of partners including senior management and external firms.
• Experience deploying and maintaining processes for data validation and quality control.
• Experience with Python, SQL, and associated programming tools for data analysis.
• Successful track record of working across product, data, and engineering teams.

We'd love to see:
• Prior exposure to company emissions datasets and associated quality processes.
• Experience balancing and linking across multiple data reporting standards.
• Proven ability to work with external/vendor teams to deliver data tools.
• Experience working with machine readable formats like XBRL.
• Please note we use years of experience as a guide but we certainly will consider applications from all candidates who are able to demonstrate the skills necessary for the role.If this sounds like you:Apply if you think we're a good match! We'll get in touch with you to let you know what the next steps are.Bloomberg is an equal opportunity employer and we value diversity at our company. We do not discriminate on the basis of age, ancestry, color, gender identity or expression, genetic predisposition or carrier status, marital status, national or ethnic origin, race, religion or belief, sex, sexual orientation, sexual and other reproductive health decisions, parental or caring status, physical or mental disability, pregnancy or parental leave, protected veteran status, status as a victim of domestic violence, or any other classification protected by applicable law.

Bloomberg is a disability inclusive employer. Please let us know if you require any reasonable adjustments to be made for the recruitment process. If you would prefer to discuss this confidentially, please email emea_recruit@bloomberg.net. Alternatively, you can get support from our disability partner EmployAbility, please contact +44 7852 764 684 or info@employ-ability.org.uk",London,GB,2023-12-19 15:26:00,http://www.bloomberg.com,Finance
91,FULLTIME,Pension Data Analyst,https://uk.linkedin.com/jobs/view/pension-data-analyst-at-buck-a-gallagher-company-3755080730,"For this role; of which we have two positions, created off the back of a period of significant growth of the firm, we're eager to speak to individuals with data analysts, system development or implementation-type experience within the Pension world. Or, you could be in an administrative role but you're looking to move into something more data-focused and system related!

Ultimately, if you're good at reporting on data, interpreting MI, using SQL and working with/developing Pension systems then you are just the person that we're after!

Within this role, the key responsibilities include:
• Working within a team of implementation data analysts to deliver a high-quality implementation service for new Buck clients and on projects for existing clients.
• Actively participate in the delivery of new clients
• Modify data using SQL to create load files for inhouse pension administration systems.
• Load data and complete control totals for audit purposes.
• Ensure adherence to departmental service standards including the use of UAT systems and sign-off procedures.
• Specify and test enhancements to systems and processes as required.
• Acquire high-level knowledge of legislation and system functionality within the pension and payroll areas. Develop leadership attributes as required for progression.
• Positively contribute to the effectiveness of the Implementation department so that it can provide a quality service to the administration practice.
• Provide process and technical guidance as required for project work or support calls.

Further context to the experience that we're looking for is as follows:
• Good/Advanced SQL experience.
• Previous pension systems implementation experience.
• Understanding of benefit administration systems.
• Experience of complex data manipulation.
• Ability to work productively as a team member and experience of working in a project team.
• MS Office (Word/Excel/Access) to advanced level.
• Good communication skills essential, both verbal and written.

Why join Buck?

• Your Career is our motivation – working as part of a small but highly collaborative department, you get the level of responsibility and client exposure rarely experienced working for some of our larger competitors. At Buck, we pride ourselves on providing excellent support at all levels to drive your ambitions and career developments goals.

• Our commitment to you as a Buck employee – we offer a competitive and comprehensive benefit package and are committed to providing a highly collaborative, stimulating working environment and are committed to flexible working and diversity & inclusion.

• Diversity of clients – we work with leading UK and international corporations, across a variety of sectors and industries, where no two clients are the same!

• We are client focussed – unlike some of our competitors, we offer bespoke and tailored solutions to our clients, not a one size fits all solution.

In return, alongside training, support and career progression, we will also offer you:

• Highly competitive salary;

• Minimum 25 days Annual leave (excluding Bank holidays);

• Holiday trading - (10 days – buy option) or (5 days – sell option);

• Private Medical cover

• Health-checks / Screening;

• Defined Contribution pension provisions;

• Comprehensive Life Assurance coverage;

• Vision Plan;

• Company bonus scheme;

• Interest-free season ticket loan;

• Gym subsidy;

Additional flexible benefits Scheme to support you and your family in and out of work encompassing; Health & Wellbeing, Protection, and Lifestyle covering; additional Life assurance, Travel insurance, Dental insurance, Medical Cash Plan, Critical Illness cover plus many more.

At Buck, we pride ourselves in our Diversity and Inclusion and are an Equal Opportunity Employer.

All qualified applicants will receive consideration for employment without regard to race, colour, religion, sexual orientation, gender identity, national origin, age, disability, or any other legally protected basis, in accordance with applicable UK law.",London,GB,2023-12-20 07:48:00,http://www.buck.com,Consulting
92,FULLTIME,Data Platform Engineer,https://uk.linkedin.com/jobs/view/data-platform-engineer-at-harnham-3789378316,"DATA PLATFORM ENGINEER

LONDON BASED

£70,000-80,000 PER ANNUM

This UK-based sustainability company is searching for a new Data Platform Engineer, to join their expanding Data and Analytics team. You will be responsible for building and maintaining data pipelines using Python, and working on developing their GCP platform.

THE COMPANY

This growing sustainability company is searching for a new Data Platform Engineer. Since forming they have been growing exponentially and are active in over 120 Countries. They have recently received over £25Million in investments and are growing on the back of this.

THE ROLE

Joining this growing department, you will be working closely with the Head Of Data Engineering to solve and deliver professional data integration in the business. You will also be responsible for building and maintaining data pipelines using Python.
• Develop internal tools to further client revenue.
• Develop ETL pipelines working with Python.
• Work with other engineers to handle big data processing using Spark.

SKILLS AND EXPERIENCE
• Extensive knowledge of building pipelines using Python and SQL
• Experience in implementing best coding practices
• Experience implementing Terraform

THE BENEFITS
• Flexible working
• Generous bonus package
• Stock options offered

HOW TO APPLY

Please register your interest by sending your CV to Cameron Webb via the apply link on this page.",London,GB,2023-12-19 17:36:00,http://harnham.com,Consulting
93,FULLTIME,2024 Business Intelligence Engineer Internship,https://uk.linkedin.com/jobs/view/2024-business-intelligence-engineer-internship-at-amazon-3721924956,"Description

We’re on the lookout for the curious, those who think big and want to define the world of tomorrow. At Amazon, you will grow into the high impact, visionary person you know you’re ready to be. Every day will be filled with exciting new challenges, developing new skills, and achieving personal growth.

How often can you say that your work changes the world? At Amazon, you’ll say it often. Join us and define tomorrow

2024 Business Intelligence Engineer Internship - London

Do you enjoy solving complex problems and troubleshooting products? Are you passionate about developing test strategies, finding, and tracking bugs to resolution, and innovating on behalf of customers? Do you want to be a part of a fast-paced, ambiguous environment and contribute to one of the most visited sites on the Internet?

At Amazon, we hire the best minds in technology to innovate on behalf of our customers. The intense focus we have on our customers is why we are one of the world’s most beloved brands – customer obsession is part of our company DNA. Business intelligence engineers use cutting-edge technology to solve complex problems and get to see the impact of their work first-hand.

The challenges business intelligence engineers solve for at Amazon are big and affect millions of customers, sellers, and products around the world. Our path is not always simple, so we are selective about who joins us on this journey. There is a certain kind of person who takes on this role at Amazon – someone who is excited by the idea of creating new products, features, and services from scratch while managing ambiguity and the pace of a company whose ship cycles are measured in weeks, not years.

The Amazon EU Student Programs Team are looking for ambitious students to join us as interns at the heart of our core consumer business! Internships are flexible in length to fit in with your university’s placement scheme.

Key job responsibilities
• Develop analytical solutions to business problems that utilize the highest standards of analytical rigor and data integrity
• Recognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation
• Write high quality code to retrieve and analyze data
• Analyze and solve business problems at their root, stepping back to understand the broader context
• Design pragmatic analyses and automated metrics that add value to your business area
• Understand data resources and how, when, and what to use (and what not to use).
• Develop analyses (whether fully formed or exploratory) for the business’ sake, not for analyses’ sake
• Seek to understand the business objectives relevant to your area, and align your work to those objectives and seek to deliver business value
• Proactively and continually, improve your level of knowledge about Amazon’s business and relevant data resources

A day in the life

Our Business Intelligence Engineer builds data pipelines, reports, dashboards, and analyses to deliver metrics and insights to the business.

Our Business Intelligence Engineers tackle some of the most complex challenges in large scale

computing, work in small teams across the company to contribute to the e-commerce platform that's used by millions of people all over the world. With that in mind, we require applicants to demonstrate their technical skills in a number of areas.

About The Team

If you’re insatiably curious and always want to learn more, then you’ve come to the right place. Depending on your location, country, job status and other requirements, some or all of the following benefits may be available to you as an intern.
• Competitive pay
• Impactful project and internship/role deliverables
• Hybrid working (team dependent)
• Networking opportunities with fellow interns
• Internships events such as speaker series, intern panels, Leadership Principles sessions, Amazon writing skills sessions.
• Mentorship and career development

If you’re successful during your internship, you could be considered for a graduate role after finishing your university studies.

Internship start dates vary throughout the year.

Internship length is ideally 6 months.

We are committed to diversity, equity, and inclusion, and leveraging our unique perspectives to scale our impact and grow. Amazon has 13 affinity groups (https://www.aboutamazon.com/affinity-groups), sometimes known as employee resource groups, which bring employees together across businesses and locations around the world. With executive and company sponsorship, these groups play an important role in building internal networks for creating a community, advising Amazon business units, leading in service projects, and reaching out to communities where Amazonians live and work.

Want to know more about our opportunities? Visit our EMEA Student Programs Team Events page to register for one of our upcoming events: https://amazonstudentevents.splashthat.com/careers

We are open to hiring candidates to work out of one of the following locations:

London, GBR

Basic Qualifications
• Currently enrolled in a Bachelor’s or Master’s degree program in computer engineering, computer science, or a similar technical field
• Availability to complete ideally a 6 months internship working full time week
• Advanced knowledge and/or experience using SQL
• Experience with data querying or modelling with SQL, Excel
• Experience with scripting language (e.g., Python, Java, or R)
• Knowledge of BI analytics/reporting/visualization tools (e.g., Tableau, AWS QuickSight, COGNOS, or other third-party tools)

Preferred Qualifications
• Master’s or advanced technical degree
• Experience with BI analytics/ reporting/visualization tools (e.g., Tableau, AWS QuickSight, COGNOS, or other third-party tools)
• Experience in data mining, data warehouse solutions, and ETL, and using databases in a business environment with large-scale, complex datasets
• Knowledge of algorithm design and complexity analysis
• Ability to deal with ambiguity in a fast-paced environment
• Excellent verbal/written communication skills and data presentation skills

EMEA Student Programs Team

Amazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We make recruiting decisions based on your experience and skills. We value your passion to discover, invent, simplify and build. Protecting your privacy and the security of your data is a longstanding top priority for Amazon. Please consult our Privacy Notice (https://www.amazon.jobs/en/privacy_page) to know more about how we collect, use and transfer the personal data of our candidates.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need an adjustment during the application and hiring process, including support for the interview or onboarding process, please contact the Applicant-Candidate Accommodation Team (ACAT), Monday through Friday from 7:00 am GMT - 4:00 pm GMT. If calling directly from the United Kingdom, please dial +44 800 086 9884 (tel:+448000869884). If calling from Ireland, please dial +353 1800 851 489 (tel:+3531800851489).

Company - Amazon UK Services Ltd. - A10

Job ID: A2451748",London,GB,2023-12-19 13:57:00,http://www.amazon.com,Retail
94,FULLTIME,Data Engineer,https://www.linkedin.com/jobs/view/data-engineer-at-urgently-3790330316,"YOUR MISSION: Your mission is to manage and optimize our cloud data platform. This means you will be responsible for working on a variety of data projects which includes orchestrating our data pipelines using modern big data tools as well as the engineering of existing transactional processing systems while meeting our security requirements.

YOUR LEGACY: Your legacy will be to ensure every Urgently team can access data from any source within minutes, and no data is ever lost. The result? You helped Urgently become the world’s leading mobility assistance company.

1) First 3 months:
• Understand our platform development environment and philosophy.
• Learn our cloud platform and applications’ infrastructure
• Grasp our engineering teams’ work culture.

2) First 6 months:
• Integrate a number of 3rd party data sources
• Employ various cloud tools to integrate our internal and external systems and third party APIs together
• Develop data platform services
• Build monitoring infrastructure / services to give visibility into the pipeline’s status
• Interface with different teams to make data available for reporting and analytics

3) Ongoing...
• Continue to optimize our data platform
• Gather data requirements from other teams and implement solutions for them
• Ensure integrity between our various systems and champion the flow of data across all of our systems ensuring data consistency
• Work with structured and unstructured data at scale from a variety of different data sources (key-value, document, columnar, etc.) as well as traditional RDBMSs
• Constantly monitor and support our complete data ecosystem
• Maintain the data platform security and integrity
• Operate and manage the services in production

WHO YOU ARE:

Technical Skills :
• Bachelor's degree in Computer Science, Information Systems, applied mathematics or in a related degree.
• 4+ years of software development in big data technologies
• Working experience with Redshift, including best practices for performance tuning.
• Experience with stream-processing systems such as Apache Spark Streaming, Kinesis, Apache Kafka.
• Working experience orchestrating data pipelines with Airflow.
• Advanced Python proficiency, encompassing key concepts like OOP, functional programming, decorators, generators, and asynchronous programming.
• Experience in writing and understanding complex SQL queries, including the use of Common Table Expressions (CTEs) and Window Functions.
• Working experience with AWS RDS, Lambda functions, EC2, S3.
• Working knowledge of messaging and data pipeline tools like SNS, SQS.
• Working experience with logging and monitoring using AWS services and tools like CloudWatch, Slack, Google Chat.
• Expert in debugging for AWS Database Migration Service (DMS).
• Working experience in automating the deployment and operation of data pipelines.
• Familiarity with EMR, Glue, Athena, Transfer Family, CloudFormation, OpenSearch, and IAM role-based permission management.

Industry Experience:
• Developed multiple data pipelines involving collecting, streaming, storing, and processing data for different business use cases.
• Skilled in processing various data formats, including CSV, Excel, Text, and Parquet, and adept at managing diverse input/output interactions with database tables, S3, APIs, Webhooks, email, and SFTP operations.
• Have worked with structured, semi-structured, and unstructured large data sets from real-time and batch streaming data feeds.
• Experience with Agile or Scrum methodologies for project management.
• Ability to manage and prioritize multiple tasks and projects simultaneously.
• Experience in optimizing the performance of data pipelines, databases, and related processes.
• Understanding and experience in implementing disaster recovery and backup strategies for data systems.
• Awareness of and adherence to data privacy and regulatory compliance standards, and security protocols.

Problem Solving and Communication:
• Proactively solves problems and constantly upgrades skill sets to enhance data platforms.
• Demonstrate commitment to continuous learning and staying updated with industry trends and technologies.
• Demonstrates effective collaboration with cross-functional teams, stakeholders, and teammates, prioritizing transparent communication and proactive knowledge sharing.
• Proficiency in documenting data processes, workflows, and architecture for knowledge sharing and future reference.
• Work independently to get tasks done while making sizable contribution to improve the overall data systems

NICE TO HAVES:
• Relevant Amazon Web Services certificate(s)
• Worked with data pipeline and governance tools: NiFi, Atlan, Alation, etc.
• Experience working with NoSQL databases like Apache Solr, MongoDB
• Knowledge in data science AWS services like SageMaker
• Have knowledge of HDFS, Flume, Hive, MapReduce
• Have worked with one of the data warehouse tools like Google BigQuery, Snowflake
• Experience with reporting tools like Tableau, Sigma Computing, Power BI

THE NITTY GRITTY:
• Location = Great news! This position is remote and you have the option of working from anywhere in the U.S.!
• Manager = You’ll report to Senior Director of Data Engineering
• Compensation = The base salary range for this position is $100,000 - $130,000. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by job-related skills, experience, and relevant education or training.
• Benefits = At Urgently, we have awesome benefits! We provide short term disability, long term disability, and life insurance to you - all free of charge! We also offer three different medical plans to choose from, two dental plans , a vision plan, and other valuable benefits. You’ll have 12 holidays off and unlimited paid time off. We match 100% on the first 3% you contribute to our 401(k)and then 50% of the next 2% you contribute. So, if you contribute 5% of your paycheck, we’ll match 4% of that. Free money!",London,US,2023-12-19 18:47:00,http://www.geturgently.com,Information
95,FULLTIME,Data Engineer,https://www.linkedin.com/jobs/view/data-engineer-at-autoliv-3790369244,"What You’ll Do
• Product Reliability in Development and Production
• Work with Airbag and Inflator Development Groups providing Reliability Support
• Implement Reliability Measures for issues found in Development and Production
• Create Reliability Documentation for testing of Airbags and Inflators during Development
• Create test methods including fixtures and equipment
• Machine Learning in Development
• Work with teams Globally as a Machine Learning/AI expert.
• Implement Machine Learning algorithms in product development and processes
• Work with the current team to establish standards for Data Analysis
• Effective communication with global colleagues (design reviews, video analysis, etc)
• Work Closely as a team member to promote reliable products

What Is Required
• BS or MS Mechanical Engineering
• Minor in Computer Science
• Machine Learning,
• Data Science
• Programming i.e. Python, Matlab
• Reliability Engineering (plus)
• Module and Inflator Experience (plus)
• Statistics (plus)

What’s In It For You
• Attractive compensation package
• Flexible Options (schedule, etc)
• Recognition awards, company events, family events, university discount options and many more perks.
• Gender Pay Equality

Autoliv is proud to be an equal opportunity employer. Autoliv does not discriminate in any aspect of employment based on race, color, religion, national origin, ancestry, gender, sexual orientation, gender identify and/or expression, age, disability, or any other characteristic protected by federal, state, or local employment discrimination laws where Autoliv does business.",Auburn Hills,US,2023-12-20 09:23:00,http://www.autoliv.com,Manufacturing
96,FULLTIME,Data Engineer,https://www.linkedin.com/jobs/view/data-engineer-at-sophinea-corporation-3790308997,"Sophinea, a leading computer software company, is seeking a highly skilled and motivated Data Engineer to join our dynamic team. As a Data Engineer, you will play a crucial role in designing, developing, and maintaining our data infrastructure. You will ensure the accuracy, availability, and security of our data, providing critical insights to drive the company's success.

In this role, you will collaborate with cross-functional teams to identify and implement data solutions that align with our business objectives. You will be responsible for optimizing data pipelines, ensuring efficient data extraction, transformation, and loading processes. Additionally, you will contribute to the development and implementation of data governance policies, ensuring compliance and data integrity.

If you have a passion for data engineering, possess strong analytical and problem-solving skills, and excel in a collaborative environment, we would love to hear from you. Join our innovative team and be part of shaping the future of our data-driven company.

Responsibilities
• Design, develop, and maintain data pipelines for ETL (Extract, Transform, Load) processes
• Collaborate with cross-functional teams to identify data requirements and implement effective data solutions
• Optimize data models and improve the performance of data stores
• Monitor data quality and implement data validation techniques to ensure accuracy and consistency
• Implement effective data security measures and maintain data privacy standards
• Develop and maintain data governance policies and procedures
• Troubleshoot and resolve data-related issues in a timely manner

Requirements
• Bachelor's degree in Computer Science, Information Systems, or a related field
• Proven experience as a Data Engineer or in a similar role
• Strong knowledge of SQL and data modeling techniques
• Proficiency in at least one programming language, such as Python or Java
• Experience with ETL and data integration tools, such as Apache Kafka or Informatica
• Familiarity with cloud-based data platforms, such as AWS or GCP
• Excellent problem-solving and analytical skills
• Strong communication and collaboration abilities
• Ability to work in a fast-paced and dynamic environment
• Attention to detail and commitment to data accuracy and integrity

Benefits
• Health Care Plan (Medical, Dental & Vision)
• Retirement Plan (401k, IRA)
• Life Insurance (Basic, Voluntary & AD&D)
• Paid Time Off (Vacation, Sick & Public Holidays)
• Short Term & Long Term Disability
• Training & Development
• Work From Home",London,US,2023-12-19 17:51:00,http://www.bdo.com,Consulting
97,FULLTIME,Senior Data Engineer,https://www.linkedin.com/jobs/view/senior-data-engineer-at-urgently-3790328754,"YOUR MISSION: To lead the development and optimization of Urgently's data platform, ensuring efficient data access and analysis for all teams.

YOUR LEGACY: Championing a secure, reliable, and scalable data landscape that empowers data-driven decision-making across the organization. The result? You helped Urgently become the world’s leading mobility assistance company.

WHAT YOU’LL BE RESPONSIBLE FOR:

1) First 3 months:
• Lead the onboarding process for new data engineers, including platform architecture and development practices.
• Own and deliver a key component of a high-priority data pipeline project.
• Develop strong relationships with stakeholders and cross-functional teams.

2) First 6 months:
• Architect and implement complex data pipelines for diverse data sources and business needs.
• Implement data governance and security measures to ensure data integrity and compliance.
• Develop data platform services
• Lead the optimization and performance tuning of existing data pipelines.
• Foster a collaborative and results-oriented data engineering team culture.

3) Ongoing...
• Continuously innovate and improve the data platform to meet evolving business requirements.
• Proactively identify and address data quality issues.
• Champion data democratization by enabling easy and secure access to data for all Urgently teams.
• Lead the adoption of new technologies and best practices in the data engineering landscape.

WHO YOU ARE:

Technical Skills :
• Bachelor's degree in Computer Science, Information Systems, applied mathematics or in a related degree.
• 7+ years of software development in big data technologies
• 7+ years of hands-on experience in building and maintaining scalable data platforms.
• Deep expertise in modern cloud data technologies and tools (AWS preferred)
• Expert in Redshift with advanced proficiency in distribution styles, sort keys, WLM configurations, compression strategies, Concurrency Scaling, Materialized Views, and optimizing query performance, implementing routines, and analyzing execution plans for efficient data warehousing.
• Data Pipelines: Showcase Airflow mastery, including expertise in advanced concepts like dynamic DAGs, XComs, custom operators, sensors, pools, queues, SubDAGs, TaskGroups, custom executors, DAG serialization, ExternalTaskSensor, and dynamic workflow generation. Hands-on experience with streaming technologies such as Kinesis and Kafka.
• Databases: Demonstrate advanced SQL proficiency, encompassing expertise in window functions, common table expressions (CTEs), recursive queries, advanced joins, materialized views, indexing strategies, stored procedures, transactions, temporal tables, analytical functions, JSON and XML processing, query optimization, and database security. Your experience extends to RDS (MySQL, Postgres), DynamoDB, and various NoSQL options such as Solr and MongoDB.
• Data Governance: Experience with data quality tools and adherence to privacy and regulatory compliance standards.
• Cloud Infrastructure: AWS expertise (EC2, S3, Lambda, IAM roles, etc.).
• Monitoring and Logging: CloudWatch, Slack, Google Chat integration for proactive performance monitoring.
• Automation: Experience in automating data pipeline deployment and operations.
• Analytics and Reporting: Familiarity with tools like Tableau, Power BI, and Sigma Computing.

Industry Experience:
• Proven track record of leading and delivering complex data pipeline projects:
• Experience with data ingestion, transformation, storage, and analysis pipelines.
• Expertise in handling diverse data formats (CSV, Excel, Parquet, etc.) and sources (real-time, batch).
• Strong understanding of data architecture and design principles.
• Experience with Agile/Scrum methodologies for project management.
• Demonstrated ability to optimize data pipelines, databases, and processes for performance and efficiency.
• Experience with disaster recovery and backup strategies for data systems.
• Awareness of and adherence to data privacy and regulatory compliance standards, and security protocols.

Problem Solving and Communication:
• Exceptional problem-solving skills and a proactive approach to identifying and resolving data platform issues.
• Commitment to continuous learning and staying updated with the latest data engineering trends and technologies.
• Effective communication and collaboration skills, with a focus on transparency and proactive knowledge sharing with stakeholders and teams.
• Strong documentation skills to ensure clear and concise knowledge transfer of data processes, workflows, and architecture.
• Able to work independently and be a self-learner in new technologies

NICE TO HAVES:
• Relevant AWS certificates
• Experience with data pipeline governance tools (NiFi, Atlan, etc.).
• Experience with data science and AI/ML platforms (SageMaker).
• Experience with HDFS, Flume, Hive, MapReduce.
• Experience with alternative data warehouse tools like Google BigQuery, Snowflake.

THE NITTY GRITTY:
• Location = Great news! This position is remote and you have the option of working from anywhere in the U.S.!
• Manager = You’ll report to Senior Director of Data Engineering
• Compensation = The base salary range for this position is $130,000 - $160,000. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by job-related skills, experience, and relevant education or training.
• Benefits = At Urgently, we have awesome benefits! We provide short term disability, long term disability, and life insurance to you - all free of charge! We also offer three different medical plans to choose from, two dental plans , a vision plan, and other valuable benefits. You’ll have 12 holidays off and unlimited paid time off. We match 100% on the first 3% you contribute to our 401(k)and then 50% of the next 2% you contribute. So, if you contribute 5% of your paycheck, we’ll match 4% of that. Free money!",London,US,2023-12-19 18:50:00,http://www.geturgently.com,Information
98,FULLTIME,Data Engineer Alteryx (Must have),https://www.linkedin.com/jobs/view/data-engineer-alteryx-must-have-at-dice-3790042238,"Dice is the leading career destination for tech experts at every stage of their careers. Our client, Resource Logistics, is seeking the following. Apply via Dice today!

Data Engineer – with expertise in Alteryx

Location – REMOTE

Duration – 6 – 12 months

Top Skills Details
• Experience developing data automation workflows in Alteryx.
• Ability to build data pipelines on databricks using pyspark/python.
• Experience developing integrations between different applications.

Looking for a Senior Data Engineer to support the organization as we continue to modernize our current data infrastructure. This role will be responsible for delivering solutions to help the organization migrate data from different applications into a central enterprise architecture for ready consumption by business and operations teams.

Required Skills/Experience:
• Experience implementing platform development using big data technologies
• Building data pipelines/integrations from SAAS applications
• Building and troubleshooting Alteryx workflows
• Experience in cloud-based solutions; mainly Azure. Knowledge of Azure ADLS, Azure Devops

Data Engineer Alteryx (Must have)",London,US,2023-12-19 16:19:00,http://www.bdo.com,Information
99,FULLTIME,Data and Analytics Engineer,https://www.linkedin.com/jobs/view/data-and-analytics-engineer-at-jetty-3788131758,"Welcome to Jetty, the financial services platform on a mission to make renting a home more affordable and flexible. We've built multiple financial products that benefit both renters and property managers - and we're just getting started.

We are growing our data organization and looking to hire a Data and Analytics Engineer. As a Data and Analytics Engineer, your goal is to cultivate a data-informed culture and create insights that will be leveraged across the entire organization. You have experience executing at a high level, solving complex problems, and delivering solutions with real business impact - and you're excited by the opportunity to apply those principles to a new, best in class function.

Role & Responsibilities
• Build / Support our modern data stack (Snowflake / Fivetran / DBT / Tableau)
• Be an enthusiastic evangelist of our modern data stack (Fivetran / DBT / Snowflake / Tableau)
• Develop analytics data models using SQL
• Document our data models in a user friendly way for our business stakeholders
• Write ELT code using modern software engineering practices (Git, automated testing and deployments)
• Build and maintain data pipelines to support various business processes and reporting (Fivetran / AWS Lambdas)
• Partner with the Product Engineering team to ensure we are capturing the data we need from our applications for analytics and to iterate on our development practices for the data analytics team.

Experience & Qualifications
• 3-5 years of experience working in a data / analytics engineering role
• High proficiency in Snowflake / Fivetran / dbt / Tableau
• High proficiency in SQL and Python
• Ability to collect, interpret, and synthesize inputs from various parts of the business into data model requirements
• Ability to simplify without being simplistic - ability to communicate complex topics and actionable insights in a compelling way that can be understood by a variety of audiences
• Inherent curiosity and analytical follow-through — you can't help but ask ""why?"" and love using data and logic to explore potential solutions
• Ability to balance ""Rigor"" and ""Scrappiness"" — you know the difference between 80/20 and giving something 110%; as well as when each is appropriate.
• Deep understanding of the first and second order effects of reporting — you know the power of presenting the right data to the right people at the right time
• Experience in a data/analytics function at a high-growth startup managing multiple stakeholders and delivering actionable insights
• Strong preference for insurance/actuarial background

Compensation & Benefits

Philosophy:

Beyond our mission, our products, and our people, the best way for Jetty to attract, develop, and retain talent is to provide both career growth and financial opportunity. In order to provide financial opportunity, our goal is to create compensation packages that are:
• Competitive
• Salary bands are based on market data
• Data pulled from similar sized companies to ensure we remain competitive
• Responsible
• Salaries for current and future employees are in our budget, which is reviewed quarterly
• Comp bands are based on 50th percentile market data (aka, right in the middle)
• Fair
• Defined compensation bands for each level of a job family, updated twice a year
• Consistent performance management practices and company wide compensation audits
• Everyone is paid against Tier 1 compensation data, since it's the most robust dataset, regardless of where you work
• Motivating
• Equity grants for all new hires, based on market data and internal comparables
• Additional grants given based on performance
• Supportive
• Comprehensive health insurance options that Jetty contributes to financially
• Health and wellness benefits
• Remote work benefits
• Flexible work schedules
• Generous leave policies

Compensation for this role:
• The annual base salary range for this role is $130-160k and may be inclusive of multiple career levels
• The offer package for this role will also include stock option equity
• Individual offer decisions within this range will be based on multiple factors, including your level of experience, relevant skills, and balancing internal equity to ensure fair and equitable compensation across similar roles

Benefits and perks include:
• Health (with HSA and FSA options), dental, and vision insurance through Aetna & MetLife
• 401(k) retirement savings program
• Optional life and disability coverage
• 20 days of PTO + 12 holidays, ""Jetty Winter Break,"" and flexible sick days
• Generous parental leave policy
• Flexible remote work in any US location (keeping east coast hours)
• Stipends to cover WFH set-up, childcare, phone/internet bill, and optional co-working space

About Jetty

At Jetty, we know renting a home can be a financial challenge. That's why we're on a mission to make renting accessible to everyone. Jetty offers four financial products designed to help our members every step of the renting process: Jetty Deposit, a low-cost security deposit product that dramatically reduces move-in costs; Jetty Rent, a flexible rent payment program to eliminate pricey late rent fees; Jetty Credit, a credit building service that helps renters build credit just by paying rent; and Jetty Protect, an affordable renters insurance product that provides comprehensive coverage in just a few clicks.

Jetty has raised multiple rounds of venture capital from investors including Khosla Ventures, Ribbit Capital, Citi, Valar, and strategic investors. We've built a highly collaborative team working remotely around the country, and we believe in finding the best talent—regardless of where they live. To learn more about life at Jetty, visit jetty.com/careers.

Jetty is firmly committed to building a team as diverse as our Members. We are proud to provide equal employment opportunities for all candidates regardless of race, ancestry, citizenship, sex, gender identity or expression, religion, sexual orientation, marital status, age, disability, or veteran status.",New York,US,2023-12-19 16:03:00,http://www.bdo.com,Consulting
100,FULLTIME,Data Engineer,https://www.linkedin.com/jobs/view/data-engineer-at-vestis-corporation-3790449499,"The Data Engineer will work within Vestis Uniform Services IT department and is responsible for supporting the data integration needs of Enterprise Data Warehouse, Data Lakes, and other integration solutions. The role of the Data Engineer is responsible for building and maintaining optimized and highly available data and analytics layer that facilitates deeper analysis and reporting to business consumers. Data Engineer will design robust and scalable data integration solutions based on industry best practices. The candidate must have a strong hands-on experience working in big data, and data warehouse environment.

Responsibilities/Essential Functions:

--Design, implement, and continuously improve data analytics platform

--Implement optimized and simplify data query and analysis capabilities of the data platform

--Develop and improve the current architecture, emphasizing data security, data quality and timeliness, scalability, and extensibility

--Deploy and apply big data solution and run pilots to design highly performing and low latency data architectures to scale

--Collaborate with cross functional team and develop, implement, and validate KPIs, statistical analyses, data profiling, prediction, forecasting, clustering, and machine learning algorithms

--Leverage best practices, disciplined approaches, and standards to solving technical problems.

--Perform ongoing monitoring, optimization, and refinement of reports and BI solutions

--The role entails 100% hands-on development using MS SQL / Python on MS Azure Synapse Platform

--Build data solutions with efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.

--Develop big data analytics solutions sourcing data from distributed systems and applications

--Ensuring accurate and efficient governance policy development and adherence

--Report on statuses when requested

--Submit all time and expense reporting procedures accurately and timely

--Maintain good standing and completion on all compliance related matters (i.e., assigned mandatory trainings, actions required from audits, corporate policies, etc.)

--Perform all additional duties and responsibilities based on the direction and guidance of supervisor

Knowledge/Skills/Abilities:

--Expertise in ELT optimization, designing, coding, and tuning big data processes using Microsoft Azure Synapse or similar technologies.

--Experience with building data pipelines and analytics solution to stream and process datasets at low latencies.

--Knowledge of Data Engineering and Data Operational Excellence using standard methodologies.

--Hands on level skills coding and optimizing complex SQL and Python

--Strong Knowledge of data warehousing frameworks and methodologies.

--Proven ability to foresee opportunities to innovate and leads the way

--Excellent verbal and written communication

--Proven interpersonal skills and ability to convey key insights from complex analyses in summarized business terms

--Ability to effectively communicate with technical and non-technical teams

--Ability to work with shifting deadlines in a fast-paced environment Skilled and proficient in MS Office O365 suite (i.e. Word, PowerPoint, Excel, SharePoint, Teams, Communications Tools, etc.)

--Ability to operate with a customer-centric service approach

Working Environment/Safety Requirements:

--Ensure necessary working environment and capabilities to effectively carry out responsibilities if working from a non-Vestis location (remote work)

--Ability and willingness to handle work related issues during all hours of the day, every day of the week, understanding the responsibility of our organization’s requirement for 24/7 production support

--Ability, willingness, and flexibility to travel as needed for approved work purposes in accordance with project and management schedules

Experience/Qualifications:

--Bachelor’s degree in Computer Science, Mathematics, Statistics or related field or 6+ years relevant experience

--Experience in data mining, profiling, and analysis

--Experience in Azure Data Factory

--Experience with complex data modelling, ELT design, and using large databases in a business environment

--5+ years experience with languages like SQL, Python, Java, or similar language

--Must have at least three years of work experience in Big Data projects such as Microsoft Azure Synapse or similar Big Data platform a must

License Requirements/Certifications:

--Valid U.S. driver license (for rental cars when applicable)

--Be legally able to work in the United States: U.S. Citizen or Legal Resident

Benefits: Aramark offers a wide array of comprehensive benefit programs and services including medical, dental, vision, short and long-term disability, basic life insurance, and paid parental leave. Employees are able to enroll in the company’s 401k plan. Employees are eligible for 120 hours of vacation, 16 hours of floating holidays, and paid sick time every year. Employees will also receive 9 paid holidays throughout the calendar year.

Compensation: The salary rate for this position ranges from $95K-115K, depending on circumstances including an applicant’s skills and qualifications, certain degrees and certifications, prior job experience, market data, and other relevant factors.",London,US,2023-12-20 01:19:00,http://www.vestis.com,Consulting
101,FULLTIME,Data Engineer (Python/SQL/ETL),https://www.linkedin.com/jobs/view/data-engineer-python-sql-etl-at-robert-half-3788462090,"Description

Job Overview:

We are seeking an experienced and highly skilled Data Pipeline Engineer to join our dynamic team. As a Senior Data Pipeline Engineer, you will play a pivotal role in designing, implementing, and optimizing data pipelines to ensure efficient data processing and seamless data flow within our organization. The ideal candidate should have a strong background in data engineering, a deep understanding of data architecture, and hands-on experience with modern data pipeline technologies.

Responsibilities
• Design and Architecture:
• Lead the design and architecture of robust and scalable data pipelines.
• Collaborate with cross-functional teams to understand data requirements and translate them into efficient pipeline solutions.
• Implementation:
• Develop, implement, and maintain high-performance data pipelines.
• Write efficient, scalable, and well-documented code to process and transform data.
• Optimization:
• Identify and implement optimizations to enhance the performance and reliability of existing data pipelines.
• Troubleshoot and resolve issues related to data processing and pipeline performance.
• Integration:
• Integrate data from various sources, ensuring data quality and integrity throughout the pipeline.
• Collaborate with data scientists and analysts to enable seamless access to processed data for analysis and reporting.
• Automation:
• Implement automation tools and frameworks for continuous integration and deployment of data pipelines.
• Monitor and manage pipeline health, ensuring timely detection and resolution of issues.
• Documentation:
• Create and maintain comprehensive documentation for data pipelines, including design specifications, data mappings, and workflow diagrams.
• Collaboration:
• Work closely with cross-functional teams, including data scientists, analysts, and software engineers, to understand data needs and deliver effective solutions.

Qualifications
• Proven experience as a Data Engineer or similar role, with a focus on designing and implementing data pipelines.
• Strong programming skills in languages such as Python, Java, or Scala.
• Experience with big data technologies (e.g., Apache Spark, Hadoop) and cloud-based data services (e.g., AWS Glue, Google Dataflow).
• Proficient in data modeling and ETL processes.
• Excellent problem-solving and troubleshooting skills.
• Strong communication and collaboration skills.

Preferred Qualifications
• Experience with containerization technologies (e.g., Docker, Kubernetes).
• Knowledge of data governance and security best practices.
• Familiarity with streaming data processing frameworks (e.g., Apache Kafka).

If you are a passionate and experienced Data Pipeline Engineer looking to take on a leadership role in a cutting-edge environment, we encourage you to apply and contribute to the success of our data-driven initiatives.

Requirements

Python, SQL, ETL - Extract Transform Load, Data Pipelines, Amazon Web Services (AWS), Snowflake, DevOps, Docker

Technology Doesn't Change the World, People Do.®

Robert Half is the world’s first and largest specialized talent solutions firm that connects highly qualified job seekers to opportunities at great companies. We offer contract, temporary and permanent placement solutions for finance and accounting, technology, marketing and creative, legal, and administrative and customer support roles.

Robert Half works to put you in the best position to succeed. We provide access to top jobs, competitive compensation and benefits, and free online training. Stay on top of every opportunity - whenever you choose - even on the go.

All applicants applying for U.S. job openings must be legally authorized to work in the United States. Benefits are available to contract/temporary professionals, including medical, vision, dental, and life and disability insurance. Hired contract/temporary professionals are also eligible to enroll in our company 401(k) plan. Visit

© 2024 Robert Half. An Equal Opportunity Employer. M/F/Disability/Veterans. By clicking “Apply Now,” you’re agreeing to",Ogden,US,2023-12-20 02:16:00,http://www.rhi.com,Staffing
102,CONTRACTOR,Data Engineer,https://www.linkedin.com/jobs/view/data-engineer-at-hsk-technologies-inc-3788192814,"Position:Data Engineer (Python)

Location : Houston TX

Mandatory Skills: Python

Experience required : 7+years

Role Description

This is a contract Data Engineer role that requires on-site presence in Houston, TX. The Data Engineer will be responsible for designing, developing, and maintaining data architectures, data modeling, extract-transform-load (ETL) processes, and assist in building data analytics solutions.

Qualifications
• Data Engineering, Data Modeling, and Data Warehousing skills
• Expertise in ETL and data integration technologies
• Data Analytics skills to support business intelligence reporting and analysis
• Expertise in SQL, Python, and/or Java programming languages
• Experience with data processing frameworks like Apache Spark and Hadoop
• Experience with cloud-based platforms such as AWS, Azure, or GCP
• Knowledge of data quality and data governance principles
• Bachelor's degree in Computer Science, Information Technology, or related field
• Experience in the technology, financial services, or healthcare industry is a plus

Please share your updated resume to jenny@hsktechnologies.net",Houston,US,2023-12-19 20:43:00,http://www.bdo.com,Consulting
103,CONTRACTOR,Data Engineer,https://www.linkedin.com/jobs/view/data-engineer-at-oscar-3788196172,"We have partnered with a consulting firm, who is looking to hire multiple Data Engineers for their mortgage financial client.

This role is a fully remote, 12-month contract opportunity.

Ideal candidates will have experience with:
• Python, PySpark
• AWS native services
• Databases (PostgreSQL, Aurora)
• Data engineering (EMR, Redshift, Glue)
• Serverless experience (Lambda, step functions)
• Strong SQL, PL/SQL
• Star/Snowflake Schema Design

Rate: Up to $55/hr on W2 with benefits, or $60/hr on C2C",London,US,2023-12-19 20:31:00,http://www.bdo.com,Consulting
104,FULLTIME,Data Engineer,https://www.linkedin.com/jobs/view/data-engineer-at-vysystems-3788400868,"8 Years + Experience in Software Engineering or related

Proficient in Informatica Power Center, IDMC

Oracle (v9i/10/11/19c), SQL, /SQL Stored Procedures support/ development

UNIX file management & administration and good shell scripting experience

Knowledge of GIT, BitBucket, Jenkins, Maven, AIM and Continuous Delivery tools.

Working towards enhancing the existing systems for better performance and stability

Build durable, stable and efficient software solutions geared towards solving the key business requirements of the organization.

Understand business requirements and collaborate with the architecture team to translate them into technical design.

Demonstrate the ability to work in a modern SDLC environment and constantly strive towards improving the practices within the organization.

Strong knowledge and experience across multiple platforms, including cloud infrastructure.

Knowledge of cloud (private cloud, public cloud etc.) working experience of cloud environments like AWS is a plus

Excellent Communication skills, both written and oral appropriately scaled for technical or business audiences

Strong analysis, research, investigation, and evaluation skills, with a structured approach to problem solving.

Must have experience automating the build and deployment process

Ability to work and effectively prioritize in a highly dynamic work environment that includes goal focus.",Dallas,US,2023-12-19 21:18:00,http://www.bdo.com,Consulting
105,CONTRACTOR,Data Engineer (Contractor),https://www.linkedin.com/jobs/view/data-engineer-contractor-at-grandstage-3790447627,"About Grandstage

Grandstage, an Antler- and Techstars-backed startup, delivers AI-driven insights for B2B marketers to create thought leadership content that builds credibility and drives growth.

Our intelligence engine synthesizes user’s existing content, as well as timely knowledge shared by thousands of industry leaders, pundits, and publications across the web and social media, to suggest topics, editorial guidance, and sample content that increases the quality and resonance of your thought leadership.

Our team

Grandstage is a pre-seed stage startup, and released the public beta of our new product in December. We are a team of six engineers, designers, data scientists, and product folks who have worked for Google, IBM, and many of the largest brands in the world.

Our mission is to empower people and companies to create thought leadership content so good they can never be ignored. We envision a world where any person or company can create the opportunities they desire through content.

Data Engineer Role

We are looking for a contract Data Engineer to join our growing virtual team. You will spearhead development of our proprietary data platform which will serve personalized insights and recommendations to inform our customers’ thought leadership content development.

Responsibilities

At this time, we expect the Data Engineer to be responsible for the following:
• Run and support a production enterprise data platform.
• Design and develop scalable data models for structured and unstructured data.
• Build batch and streaming data pipelines with tools such as Spark, Airflow, and cloud-based data services like Google’s BigQuery, Dataproc, and Pub/Sub.
• Build web crawlers and scrapers capable of curating content and data from various web sources.
• Work on end-to-end implementation of ML and generative AI solutions into our data processing workflow to perform tasks like cleansing, transforming, categorizing, rating, and synthesizing of qualitative and quantitative data.
• Evaluate technical tradeoffs of strategic decisions and serve as SME on data sourcing, data architecture, and scalability.
• Evaluate current methodologies quickly to identify opportunities for enhancement.
• Oversee the development of internal tools to enable data exploration, analysis and reporting.
• Develop processes for automating, testing, and deploying your work.
• Other tasks as needed.

These responsibilities may change, and Grandstage retains the right to change responsibilities at any time.

Characteristics Desired

Culture is immensely important to the success of any business, and Grandstage seeks to be very intentional about this from day one. Below are the values we will look for within each member of the organization and strive to instill in the company:
• Acceptance
• Inclusion
• Transparency
• Professional and personal nurturing
• Respect
• Servant leadership

In order to foster this culture within the organization, we are seeking individuals with the following characteristics:
• High level of emotional intelligence, including humility and diplomacy
• Highly entrepreneurial mindset, a go getter
• Clear and effective communicator
• Strong written, verbal, and presentation skills
• Strong organizational skills
• Flexible, easily adaptable to change, and comfortable with ambiguity
• Data-driven decision making

Qualifications
• BS/BA in a technical field such as Computer Science or equivalent experience.
• Minimum 3-5 years of data analysis and engineering experience.
• Extensive experience using Python, Postgres, and Google Cloud data products such as BigQuery, BigTable, and Pub/Sub tools, and others.
• Experience using proprietary and open source large language models and available LLM API’s.
• Experience building systems capable of storing qualitative and quantitative data in a harmonious environment.
• Experience with operating large-scale data sets and backend services required.
• Comfort working within a modern engineering environment (Python, Javascript, PostgreSQL, multithreaded programming).
• Passionate about problem-solving with strong technical communication skills and desire to collaborate with others.
• Familiar with agile, iterative, and growth-driven product development.
• Track record of delivery in rapidly changing, highly collaborative, multi-site, multi-stakeholder environments.
• Experience with data science and machine learning is a plus.
• Relevant experience with Internet-scale infrastructure.

General Expectations

We expect that the contractor will commit to 30-40 hours a week.

We expect that, upon signing of an agreement, one to two one-hour onboarding sessions will be held to educate you on our:
• Business strategy
• Competitive landscape
• Product strategy and roadmap
• Technical architecture

Typically, we expect to meet three to four times a week on a recurring scheduled cadence. These meetings will consistent of:
• 3 weekly standups (30 minutes)
• Biweekly sprint planning meeting (2 hour minutes)
• Biweekly 1-on-1 meeting (20-30 minutes)

We expect the contractor to communicate, and respond to communication, in a timely manner.

We expect any changes in availability, or expected completion timeline for projects, to be communicated in a timely manner in writing.

It is expected that the contractor will be available for phone/video conferences for emergency meetings, as appropriate.

Terms

As a contractor, you are not an employee of Grandstage nor qualify for any benefits, tax withholdings, etc. Each new contractor is subject to a 90-day trial period. A performance evaluation will be conducted every 6 months.",London,US,2023-12-20 00:22:00,http://www.bdo.com,Consulting
106,FULLTIME,Associate Data Engineer,https://www.linkedin.com/jobs/view/associate-data-engineer-at-confidential-3790345721,"Job Description:

Position: Associate Data Engineer

Remote

Preferred time zones: CST or PST

Salary Range: $60-85k

Our client is a company focused on marketing attribution & spend/outcome decisioning in the cookie-less era, driving benefits for global category leaders with DTC, retail, wholesale, and subscription footprints.

They enable brands to optimize spend outcomes resulting in significant P&L benefit. As audience identification decays and media costs increase, the company measures the diminishing returns of marketing spend, identifies ineffective dollars within channels/tactics/campaigns as they scale, and enables marketers to drive smarter business decisions with their next dollar-in.

The best thing about the company is that brands typically need only 15-30 hours LOE (or less if fully on e-comm platforms) to achieve data readiness (no site-tags). From data-readiness, standup should be less than 3 weeks so that performance marketers recognize value quickly. Our brands often see full annual program payoff within the first few months, making ramp-to-benefit a premium feature.

As an Associate Data Engineer you will:
• Work with large data sets, high performance databases, and data integration tools
• Gain experience in building a multi-tenant SaaS data pipeline product in public clouds such as AWS, GCP and Azure
• Work with geographically spread teams both domestically and internationally

You should have:
• A can-do startup attitude
• Excellent analytical and problem-solving and client-facing communication skills
• Experience in relational databases, preferably Postgre.
• Hands-on experience with SQL and familiarity with Linux commands
• Working knowledge in AWS Tools like AWS CLI
• Expertise or working knowledge in data analysis, ETL programming with Python
• Aptitude to learn multiple functions and processes quickly
• Exposure and ability to learn other AWS tools such as Athena, Lambda, S3, Glue, or IAM
• Exposure to dev tools such as PyCharm, IntelliJ, or Visual Studio Code
• 1+ years experience with: AWS - CLI, Lambda, S3, EC2, EMR, Python, Shell Scripting, Athena, Postgres",London,US,2023-12-19 20:27:00,http://www.bdo.com,Consulting
107,FULLTIME,AWS Data Engineer,https://www.linkedin.com/jobs/view/aws-data-engineer-at-compunnel-inc-3784409459,"Role: AWS Data Engineer

Job Description:

We are seeking a highly experienced AWS Data Engineer to work on AWS and Redshift, with a focus on data management and analytics. E-commerce and retail experience is highly desirable for this role. The candidate should have the ability to lead teams effectively and drive consensus among stakeholders. A master's degree in a related field is preferred, but equivalent education and work experience will be considered.

Key Responsibilities:
• Lead project/program delivery in the warehouse management and logistics domain, preferably on the AWS platform.
• Demonstrate deep expertise in Large Scale Data Platforms, Data Warehouses, Data Lakes, and Data Lakehouses.
• Familiarity with the Data Science Product and Platform ecosystem is a plus.
• Previous experience in roles such as Engineering, Product Management, Product Development, or Competitive Analysis.
• Organize work and teams to optimize efficiency and productivity.
• Attract, select, and retain critical talent for the team.
• Coach team members in coding, development, and implementation skills.
• Set clear, specific goals for the team and provide regular performance feedback through one-on-one meetings and performance reviews.
• Contribute to defining and executing the team's strategy as a part of the engineering leadership.
• Foster Communities of Practice in critical technologies.",Jersey City,US,2023-12-19 13:38:00,http://www.compunnel.com,Consulting
108,FULLTIME,Data Engineer,https://www.linkedin.com/jobs/view/data-engineer-at-kalshi-3788168405,"Data @ Kalshi

What we're up to
• Kalshi has launched the first regulated financial exchange that allows people to trade on the anticipated outcome of events. We’re now looking for the right people to help us continue to grow and scale.
• Our vision is to allow people to capitalize on their opinions and hedge risks that relate to their everyday lives, from ""Will CPI rise more than 0.5% this month?” to ""Will 2023 be the hottest year on record?"".
• We're on a long journey in uncharted territories and are looking for passionate and outlier members excited to embark on this voyage towards building the future of the financial system.

Role Roadmap
• As our go to data person at Kalshi, you build and operate the full data stack at Kalshi. This role is one part data engineering, one part data analysis.

Some of the projects you may work on:
• Partner closely across the business to find improvements/opportunities and influence decisions using data science methodologies and tools
• Drive the collection of new data and the refinement of existing data sources and pipelines
• Build actionable KPIs, create production-quality dashboards and notebooks to convey insights
• Analyze large, complex datasets to extract insights and decide on the appropriate techniques and data representation
• Define and advance best practices within an experiment-driven culture
• Inform product engineering roadmap through analysis of marketplace, user behavior, and product trends

Technology
• Our tech stack includes Python, SQL, DBT for data analytics and pipelining, pipelining and machine learning, Spark for big data processing, and visualization through Superset. We leverage cloud platforms such as AWS for scalable data storage and computational needs.

About you
• We are looking for intellectually curious, highly motivated individuals to be foundational members of our Data team! You will partner with our Engineering and Product teams to identify critical goals for the business, develop a deep understanding of them, and design scalable solutions.
• You should have strong critical thinking and analytical skills, excellent communication abilities, and a knack for working across teams in a fast-paced environment. The ideal candidate will be adept in navigating the data stack and able to support initiatives in all facets from analytics/data engineering and product analytics.

Skills
• Expertise in Python and SQL with a strong familiarity with Pandas, Numpy, DBT,
• Knowledge of Big Data tools like Spark is preferred
• Experience with cloud platforms (bonus points for AWS)
• Expertise in data visualization tools and BI tools
• Intermediate understanding of Machine Learning algorithms and principles
• Extremely strong statistical analysis skills
• Ability to lead initiatives across multiple product areas and communicate findings with leadership and product teams

Attributes
• 3+ years of Data Engineering experience
• Love what Kalshi is building
• Ownership mentality
• Excellent verbal communications, including the ability to clearly and concisely articulate complex concepts to both technical and non-technical collaborators
• Can manage ambiguity and working on multiple projects at once

Bonus Points
• Prior experience working with financial data
• Interest in surveillance systems
• Previous experience working on government interfacing data projects

NYC Pay Transparency Disclosure:
• Salary Range: $100,000 to $180,000 annually plus equity and benefits. This salary range is based on the current available market data, and represents the expected salary range for this role. Kalshi has minimal hierarchy and few titles, but has broad ranges of experience represented within roles. Should you have compensation expectations that exceed these bands, we'd love to hear from you and would welcome you to reach out to further discuss.

Our Culture
• We are a group of people who work hard and get things done, and we're looking for more people like that! Meritocracy is at our core, and we value people who take ownership and figure (usually hard) things out. We think of Kalshi as a family bound together by our mission: we believe that this is the best (and most fun!) way to work. Kalshians are, by far, Kalshi's largest asset and we're obsessed with growing and investing in our people.

Who We Are
• Kalshi is committed to creating a culture of inclusion and belonging, and we are proud to be an equal opportunity employer. We believe it is our collective responsibility to uphold these values and encourage candidates from all backgrounds to join us in our mission. All qualified applicants will be treated with respect and receive equal consideration for employment without regard to race, color, creed, religion, sex, gender identity, sexual orientation, national origin, disability, uniform service, veteran status, age, or any other protected characteristic per federal, state, or local law. If you are passionate about what you do and want to use your talents to support our mission and values, we’d love to hear from you.",New York,US,2023-12-19 19:00:00,http://www.kalshi.com,Consulting
109,FULLTIME,Data Engineer II,https://www.linkedin.com/jobs/view/data-engineer-ii-at-cincinnati-children-s-3790337725,"Expected Starting Salary Range: 41.10 - 52.27

SUBFUNCTION DEFINITION: Focuses on how to design, integrate, and manage complex data and analytic systems over their life cycles. Uses a combination of core software engineering principles and domain specific data and analytic knowledge to ensure the enterprise as seamless access to actionable, meaningful and well-governed data across all domains.

Representative Responsibilities
• Data Pipelines

Design, Build, test and manage simple to moderately complex data pipelines from data sources or endpoints of acquisition to integration to consumption for production for key data and analytics consumers like business/data analysts, data scientists etc. Guarantee compliance with data governance and data security requirements while creating, improving and operationalizing data pipelines, partnering effectively with platform engineers and database administrators. Follow best practice development practices to ensure agile updates to data pipelines from development to production and back. Make simple to moderately complex changes to ETL processes and support upgrade and testing initiatives as necessary. Pursue additional options for data extraction and analysis from the Epic source system to deliver data to meet customer needs for research, regulatory, and collaborative initiatives. Understand bench-marking and process improvement data requirements and develop solutions to address these requests. Develop moderately complex solutions to ensure data analytic solutions don't interfere with transactional systems.
• Metadata Management & Data Modeling

Develop and implement simple to moderately complex data models to support CCHMC strategies. Work with key customer and report/analytic development groups to help ensure solutions are being developed with scalability and efficiencies in mind. Develop documentation of data models and extract processes, so information can be referenced by team members and customers to understand design objectives. Use innovative and modern tools, techniques and architectures to partially or completely automate the most-common, repeatable and tedious data preparation and integration tasks in order to minimize manual and error-prone processes and improve productivity. Continually refine existing solutions, so that best practices are deployed in individual reports, database structure, and extraction techniques. Work with vendors when necessary to ensure CCHMC investments and requests are being adequately supported and enhanced. Address reporting requests that require more complex solutions or require a deeper knowledge of the source system data models.
• Technical & Business Skill

Proficiency in one or more Data Management practices and architectures, such as Data Modelling, Data Warehousing, Data Lake, Data Hub, etc. and foundational understanding of the others. Proficiency with SQL, object-oriented/object function scripting and DevOps principles. Demonstrate understanding of core CCHMC clinical, business and research processes to help build appropriate data solutions. Obtain Epic certifications as appropriate/needed. Build additional skills through continuing education.
• Technical Support & Customer Services

Ensure outstanding end-user support is provided, including ongoing monitoring of Service Level Agreements for incident management and collaboration with other areas to ensure customer-centered incident management and support. Adhere to and promote continual adoption of change management policies and procedures. Model outstanding customer service behavior, including timely and effective follow-up with customers. Escalate support issues with urgency. Collaborate with various stakeholders within the organization. In particular, work in close relationship with data science teams and with business (data) analysts in refining their data requirements for various data and analytics initiatives and their data consumption requirements. Provide second-level incident and problem resolution and support departmental efforts to improve customer satisfaction. Maintain and refine support documentation. Escalate support issues with urgency. Take 24 hour call on a staff rotation.
• Project Execution & Management

Execute own project tasks with urgency and to a high level of quality. Communicate status clearly and effectively using departmental project management tools. Follow time-tracking and other project management requirements. Participate actively in project meetings, stand-ups, etc. Serve as technical lead for moderately complex projects, collaborating with project managers to ensure project scope/risk/budget/etc. are adequately managed. Lead project meetings and workgroups.

Education/Experience

Required:
• Bachelor's degree in a computer science, statistics, applied mathematics, data management, information systems, information science or a related quantitative field.
• 2 years of work experience in a related job discipline.

Preferred
• Experience working in cross-functional teams and collaborating with business stakeholders in support of a departmental and/or multi-departmental data mgmt and analytics initiative.

Unique Skills

Cincinnati Children's is proud to be an Equal Opportunity Employer that values and treasures Diversity, Equity, and Inclusion. We are committed to creating an environment of dignity and respect for all our employees, patients, and families (EEO/AA).

Job

Information Technology

Primary Location

United States-Ohio-Cincinnati-Vernon Place

Schedule

Full-time

Shift

Day Job

Job Type

Standard

Department

IS Digital Strategy

Employee Status

Regular

FTE

1.0

Weekly Hours

40

Salary Range

41.10",Cincinnati,US,2023-12-19 20:09:00,http://www.bdo.com,Consulting
110,FULLTIME,Data Analyst/ Engineer,https://www.linkedin.com/jobs/view/data-analyst-engineer-at-peraton-3770443611,"Peraton Overview

Peraton drives missions of consequence spanning the globe and extending to the farthest reaches of the galaxy. As the world's leading mission capability integrator and transformative enterprise IT provider, we deliver trusted and highly differentiated national security solutions and technologies that keep people safe and secure. Peraton serves as a valued partner to essential government agencies across the intelligence, space, cyber, defense, civilian, health, and state and local markets. Every day, our employees do the can't be done, solving the most daunting challenges facing our customers.

Responsibilities

Peraton seeks a Data Analyst with Software Engineer background to support Army Cyber Command (ARCYBER) on a specialized project. Location: Fort Eisehnower, GA.

In this role you will:
• Operate as a member of a highly skilled team of engineers and data scientists acquiring and data from multipe locations
• Support the development of a solid data foundation to process modeling data and perform robust analytics.
• Leverage online experimentation and other data science methodologies
• Achieve achieve sustainable growth by leveraging Machine Learning (ML), natural language processing, and dynamic network analysis
• Characterize social media narratives and messaging in context of the mission

Qualifications

Required:
• Minimum of 8 years with BS/BA; Minimum of 6 years with MS/MA; Minimum of 3 years with PhD. Will consider HS+12-14 of experience.
• Experienced designer, developer, deployer, tester, and evaluator of software applications.
• Has developed and maintained manuals, drawings, and/or system specifications.
• Skilled in multiple programming languages and knowledgeable in Agile development approaches.
• Must be familiar with basic data analysis and visualization techniques in Python.
• Must have experience using basic Python data analysis packages (pandas, matplotlib, etc.).
• Must have experience using a notebook analytic environment like Jupyter Notebooks.
• Active TS//SCI clearance with a CI Poly and MEAD.

Preferred:
• Python experience
• DoD 8140/8570 IAT Level II

Target Salary Range

$112,000 - $179,000. This represents the typical salary range for this position based on experience and other factors.

SCA / Union / Intern Rate or Range

EEO

An Equal Opportunity Employer including Disability/Veteran.

Our Values

Benefits

At Peraton, our benefits are designed to help keep you at your best beyond the work you do with us daily. We're fully committed to the growth of our employees. From fully comprehensive medical plans to tuition reimbursement, tuition assistance, and fertility treatment, we are there to support you all the way.
• Paid Time-Off and Holidays
• Retirement
• Life & Disability Insurance
• Career Development
• Tuition Assistance and Student Loan Financing
• Paid Parental Leave
• Additional Benefits
• Medical, Dental, & Vision Care",London,US,2023-12-19 13:59:00,http://www.peraton.com,Consulting
111,FULLTIME,Data Engineer,https://www.linkedin.com/jobs/view/data-engineer-at-strategic-employment-partners-sep-3784437196,"Energy company that has been a staple in our Denver community for over 50+ years is looking for a full-time Senior Data Engineer to join their team!

You would be responsible for working with cross-functional teams to identify and address data related issues, creating ETL pipelines, designing and building data models, and to mentoring more junior team members.

This is a mostly remote position, only requiring 1-2 days per month onsite in the heart of downtown.

Qualifications:
• 6+ years of hands-on data engineering experience
• 2+ years of experience with Python
• Familiarity with at least one cloud platform (ideally Azure but open to others)
• Containerization experience (primarily Docker)

Pluses:
• Data visualization experience (Grafana, Matilion, or others)
• Familiarity with Machine Learning

(Sorry, visa sponsorship/transfer and C2C employment are unavailable at this time)",Denver,US,2023-12-19 17:00:00,http://www.bdo.com,Consulting
112,FULLTIME,ETL Data Engineer,https://www.linkedin.com/jobs/view/etl-data-engineer-at-zortech-solutions-3788124368,"Note for full time candidates: (Visa Independent Only for FTE)

Role: ETL Data Engineer

Location: Augusta GA (100% Onsite)

Duration: C2C/Fulltime

Job Description
• Strong hands-on coding experience with 6 to 8 years of experience in ETL
• Hands on exp. on SQL/PL SQL
• Strong hands-on Experience using Azure cloud
• Hands on exp. on Data cloud platforms like Snowflake
• Ability to plan and own the work packets and with minimal supervision or direction is highly desired",London,US,2023-12-19 14:53:00,http://www.bdo.com,Consulting
113,FULLTIME,Data Engineer,https://www.linkedin.com/jobs/view/data-engineer-at-strategic-employment-partners-sep-3784446139,"This leading financial investment firm that's helping to scale cutting-edge SaaS companies throughout the United States, is seeking a passionate Data Engineer to join their growing team! In this role, you will have the opportunity to work with enterprise-level datasets in an effort to optimize business strategies and data-driven decision-making.

If you're passionate about leveraging data for informed business decisions and envision yourself thriving in a role like this, apply now!

Title: Data Engineer

Location: Hybrid in Los Angeles, CA

Compensation: Up to $200k base salary DOE + Benefits

Qualifications For Success:
• 6+ years of Professional Experience as a Data Engineer
• 4+ years of Professional Experience with SQL databases and querying languages
• Strong understanding of data processing concepts, including ETL/ELT, data modeling, and data warehousing
• Bachelor's degree in Computer Science, Data Science, or related field required
• US Citizens and Permanent Residents are welcome to apply, unable to provide sponsorship or 1099/c2c contracts at this time.*",Los Angeles,US,2023-12-19 18:45:00,http://www.bdo.com,Consulting
114,FULLTIME,AWS Data Engineer,https://www.linkedin.com/jobs/view/aws-data-engineer-at-nityo-infotech-3790049057,"Title: Business Intelligence Architect

Location: Charlotte, NC

Responsibilities:
• Provide expert guidance on Business Intelligence BI skills and technologies.
• Admin related activities with BI tools: SAP Business Objects, Tableau & MicroStrategy.
• Lead and guide team regarding metadata extraction for above mentioned tools.
• Maintain accurate and complete technical architecture for Meta data Extraction of BI tools.
• Define BI standards guidelines and best practices for business groups and technical teams.
• Diagnose and resolve BI metadata tool capacity issues & recommend strategies to enhance efficiency to metadata data extractor tool that are going to be built.
• Address customer queries and issues in a timely manner & provide BI administration and technical support during weekends after hours and holidays when needed.
• Provide technical training on BI tools to junior staffs.
• Collaborate with BI Administrators, Developers and Analysts for successful metadata extraction tool development of BI reporting and analysis solutions.
• Work with business groups and technical teams to develop and maintain metadata extraction tool.
• Liaise with business and technology partners to build insightful analytical solutions and translate.
• Troubleshoot data discrepancies resolve and articulate them Identify areas where operational efficiency can be improved through enhanced automation implement those enhancements.

Required Skills:
• Expertise in creating in house tools for extracting metadata for BI tools.
• Ability to perform maintenance and troubleshooting activities for BI metadata tool extractor.
•",Jersey City,US,2023-12-19 15:27:00,http://www.bdo.com,Consulting
115,FULLTIME,Data Engineer with Alteryx exp,https://www.linkedin.com/jobs/view/data-engineer-with-alteryx-exp-at-dice-3790039754,"Dice is the leading career destination for tech experts at every stage of their careers. Our client, ResolveTech Solutions Inc., is seeking the following. Apply via Dice today!

Role: Data Engineer with Alteryx exp

Location: Irving, TX

Onsite job.

Responsibilities:
• Design and develop the data ingestion architecture for all incoming data from various sources into a single warehouse solution.
• Automate data infrastructure and pipelines.
• Design our data warehouse solution for scale with a keen eye on optimizing data infrastructure.
• Build and maintain scalable ETL pipelines to efficiently process and maintain large data volumes.
• Work with our engineering teams to ensure robust implementation across all areas of product.
• Partner with business stakeholders to gather and synthesize data requirements.
• Implement monitoring tools and practices to ensure high data quality and stability.
• Articulate and implement best practices around data ingestion frameworks and pipeline development.

Experience Requirements:
• 4-6 years’ experience in a Data Engineering role, managing large volumes of data.
• Experience with Azure stack a plus

Skill Requirements:
• Background in Data Engineering,4+ years of experience building and maintaining scalable data infrastructure, including distributed processing solutions (e.g. Spark), ETL tools (e.g. Alteryx), cloud-based data lakes and warehouses (e.g. Databricks, Snowflake, BigQuery), workflow management (e.g. Airflow)
• Experience proactively identifying opportunities to improve ETL & dashboard performance
• Familiarity with cloud computing tools such as AWS, Azure, and Google Cloud Platform
• Experience with data transformation tools, automation and scripting
• Knowledge of basic data visualization in Excel and Tableau
• Experience with SQL Server
• Excellent communication, organizational and interpersonal skills and the ability to research and resolve issues ‘
• Strong facilitation skills for requirement elicitation and management communications
• Quantitative rigor, good problem-solving skills and a growth mindset",Irving,US,2023-12-19 16:19:00,http://www.bdo.com,Information
116,FULLTIME,Senior Data Engineer,https://www.linkedin.com/jobs/view/senior-data-engineer-at-m-science-3790040828,"Senior Data Engineer

Location: Portland, OR (remote available)

Job Description:

The Sr Data Engineer is responsible for design, development, and maintenance of various internal and external M Science products and applications, as well as mentoring and leading junior team members. The Data Engineering team focuses on the entire lifecycle of data at M Science, from ingestion through customer data delivery, and you will focus on increased predictability and reliability, with reduced total cost of ownership.

Description/ Responsibilities:
• Collaboration is huge as we regularly partner with other engineers and product managers.
• You should have a passion for learning and exploring new technologies.
• Participate and contribute to the various project development stages from inception to release.
• Design, develop and maintain reference implementations of data pipelines and associated infrastructure.
• Support existing applications.
• Develop clean, readable, structured code solutions that provide desired functionality and adhere to specifications by studying information needs.
• Contribute to technical documentation and make use of clear code and comments.
• Ability to mentor junior members of the team and within the company.

Education/Experience Requirements:
• Bachelor’s degree in Software Engineering or equivalent combination of education and experience
• 4+ years of professional experience with industry leading Data Engineering tools (Airflow, Databricks, Parque, Snowflake, Spark…)
• Knowledge of version control systems; we work with Git but similar experience is acceptable.
• Knowledge of AWS as a platform.
• Experience with unit and integration testing.
• Familiar with CICD technologies and workflow.
• Familiarity with visualization tools such as Tableau will be valued
• Excellent problem-solving skills
• Excellent verbal and written communication skills
• Proactive and willing to learn and adapt new patterns and practices and technologies
• Ability to thrive in a culture of quality and personal accountability
• Team player who is willing to work with internal and cross functional teams",London,US,2023-12-19 15:21:00,http://mscience.com,Consulting
117,FULLTIME,Senior Data Engineer,https://www.linkedin.com/jobs/view/senior-data-engineer-at-nesco-resource-3790018121,"We are seeking a Senior Data Engineer to lead our efforts in designing, developing, and optimizing data solutions that empower our organization's growth objectives.

Join our dynamic team in a hybrid work environment! This role offers the perfect blend of flexibility and collaboration, with the expectation of two days onsite per quarter. Embrace the opportunity to work both remotely and in-person, fostering teamwork while enjoying the benefits of a flexible work schedule.

Candidates that are in the Midwestern US are preferred.

Co-architecting our next-generation cloud data analytics platform

Enhancing operating efficiency and adaptability to evolving requirements.

Monitoring and ensuring the health of our solutions.

Elevating our data-ops practices to new heights.

Collaborating with teams to provide task breakdowns, dependencies, and effort estimates.

Modeling data warehouse entities using Erwin and building data transformation pipelines with Data Build Tools (DBT).

Evaluating cutting-edge technology trends, developing proof-of-concept prototypes, and aligning them with CPI's opportunities.

Cultivating positive relationships with clients, stakeholders, and internal teams.

Translating business goals and processes into technology solutions that drive organizational improvement.

Collaborating in an agile-like environment with engineers, product managers, and analysts to craft innovative solutions.

Conducting design and code reviews, ensuring top-notch quality.

Undertaking other position-related duties as required.

Qualifications:

Bachelor’s degree in computer engineering, computer science, data science, or related field.

Two or more years of experience in designing and implementing data warehouses in Snowflake.

Eight or more years of experience in data modeling, architecture, and engineering.

Expertise in core software development activities from requirements gathering to testing.

Proficiency in data transformation using DBT and familiarity with DQ products like Monte Carlo, BigEye, or Great Expectations.

Hands-on experience with Azure DevOps and formal software development methodologies (SDLC, Agile, or SCRUM).

Proven track record in building high-performance, reliable data pipelines and understanding of data warehouse design patterns.

Knowledge of DataOps, cloud-based compute, storage, integration, security patterns, and RESTful APIs.

Proficiency in SQL and Python, coupled with the ability to work effectively in a collaborative environment.

Strong communication, listening, and facilitation skills.

Ability to manage multiple priorities, driving continuous improvement.

Nice to Haves:

Experience in delivering end-to-end data analytics platforms with modern data stack components.

Exposure to AI/ML, SnowPro Advanced Certification, and DBT Analytical Engineer Certification.

8+ years of experience or a background in senior-level/co-architectural roles in Data Engineering.

Familiarity with Snowflake, Azure DevOps, and Python/SQL.

If you're ready to take on this exciting challenge and contribute to our success, apply now!

Nesco Resource provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws",Milwaukee,US,2023-12-19 14:00:00,http://www.bdo.com,Consulting
118,FULLTIME,Senior Data Engineer (Remote First),https://www.linkedin.com/jobs/view/senior-data-engineer-remote-first-at-european-wax-center-3757566437,"Perks & Benefits
• Remote-First Workplace
• Flexible Fridays
• Diversity, Equity & Inclusion Council
• Monthly Remote Stipend
• Professional Development Stipend (up to $500 annually)
• 1 Wellness/Mental Health Paid Day Off
• 1 Volunteer Paid Day Off
• Health Benefits (Medical, Dental, Vision)
• HDHP with HSA plan (annual employer contribution to HSA)
• Employer-Paid Basic Life Insurance and AD&D
• Employer-Paid Short- and Long-term Disability
• Employer-Paid Wellness Reward Program
• Employer-Paid Mental Health Benefit
• Employer-Paid Employee Assistance Program
• Employer-Paid Out of State Medical Travel Benefit
• 401(k) Safe-Harbor Matching
• Ancillary Benefits (pet insurance, legal coverage, identity theft protection, accident, hospital, and critical illness coverages)
• Paid Time Off (increases with tenure)
• Paid Parental, Adoption, and Foster Leave
• Out of State Medical Travel Benefit

About The Role

EWC is looking for a motivated Senior Data Engineer to join our growing team of data experts. In this role, you will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. The ideal candidate is an experienced data pipeline builder and engineer who enjoys optimizing data systems and building them from the ground up. The Sr. Data Engineer will support our data analysts/scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

A Day In The Life
• Collecting, organizing, managing, and converting raw data into a format that can be easily analyzed by Business Intelligence analysts and data scientists.
• Building and maintaining data pipelines that collect and transport data from various sources to EWC’s data storage systems.
• Using algorithms and programming languages such as SQL and Python to prepare data for analysis.
• Working closely with the management and end-users to understand and address business requirements related to data storage, management, and analysis.
• Creating data analysis tools and developing new data validation methods to ensure data accuracy and completeness.
• Identifying ways to make data more reliable, efficient, and accessible to relevant stakeholders.
• Creating and maintaining the organization’s software and hardware architecture to support efficient and secure data storage and management.
• Conducting research and troubleshooting to address potential problems that may arise in the data storage and management systems.
• Play a key role in designing and crafting a modern Data and Information Delivery and Analytics platform in the cloud to support retail service and product distribution for the US market.
• Create and maintain optimal data pipeline architecture.
• Assemble large, complex data sets that meet functional/non-functional business requirements.
• Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
• Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
• Work with stakeholders including the Executive, Operations, FP&A, and Supply Chain teams to assist with data-related technical issues and support their data infrastructure needs.
• Keep our data separated and secure during transmission and at rest.
• Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
• Work with data and analytics experts to strive for greater functionality in our data systems.

What Sets You Apart
• Adopts EWC values in personal work behaviors, decision making, contributions and interpersonal interactions.
• Helps shape a positive work environment by demonstrating and influencing others to reward performance and value ""can do"" people, accountability, diversity and inclusion, flexibility, continuous improvement, collaboration, creativity, and fun.
• Experience with commercial data engineering/science solution initiatives.
• Ability to manage a broad range of deliverables with ambiguous task symptomatology while consistently achieving collaborative success with others to accomplish goals.
• Works well in a team environment and takes pride in participating in projects that employ the skills of all team members.
• Ability to learn quickly in a dynamic environment and to troubleshoot issues.
• Business savvy communications skills and concise written communication skills.
• Ability to be self-sufficient and self-driven in a small team.
• Understanding of the current threat and vulnerability landscape.
• Excellent organization and presentation skills.

Education And Experience
• BS in Computer Science, Data Science, or equivalent.
• 7+ years of professional software development or data engineering experience.
• 5+ years of experience using and strategizing the use of DBT and Airflow.
• Strong working knowledge of SQL, of datastores and their tradeoffs (including relational, columnar, and document stores), data modeling, data structures, data manipulation.
• Strong knowledge of Extract, Transform, Load (ETL) pipeline design, tooling, and support.
• Experience designing, building and optimizing ‘big data’ data pipelines, architectures and data sets.
• Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
• Strong analytic skills related to working with unstructured datasets.
• Build processes supporting data transformation, data structures, metadata, dependency and workload management.
• Proven ability to architect, implement, and optimize high throughput data pipelines.
• Experience deploying production systems in the cloud (i.e., AWS, Azure).
• Strong communication skills in writing and conversation.
• Experience with tools we use every day:
• Storage: Snowflake, AWS Storage Services (e.g., S3, RDS, Glacier)
• ETL/BI: Astronomer, DBT, Domo, Tableau, PowerBI
• Proven passion and talent for teaching fellow engineers and non-engineers.
• Experience with encryption at rest, including multiple approaches and tradeoffs.
• Experience in Retail operations.

European Wax Center is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability status, protected veteran status, or any other characteristic protected by law.

This job description is a general description of essential job functions. It is not intended to describe all duties someone in this position may perform. All employees of EWC and operating subsidiaries are expected to perform tasks as assigned by supervisory/management personnel, regardless of job.",London,US,2023-12-19 12:36:00,http://waxcenter.com,Restaurant
119,FULLTIME,"Data Engineer, Data Platform",https://www.linkedin.com/jobs/view/data-engineer-data-platform-at-grammarly-3689966167,"Grammarly is excited to offer a remote-first hybrid working model. Team members work primarily remotely in the United States, Canada, Ukraine, Germany, or Poland. Certain roles have specific location requirements to facilitate collaboration at a particular Grammarly hub.

All roles have an in-person component: Conditions permitting, teams meet 2–4 weeks every quarter at one of Grammarly’s hubs in San Francisco, Kyiv, New York, Vancouver, and Berlin, or in a workspace in Kraków. This flexible approach gives team members the best of both worlds: plenty of focus time along with in-person collaboration that fosters trust and unlocks creativity.

Grammarly team members in this role must be based in the United States or Canada, and they must be able to collaborate in person 2 weeks per quarter, traveling if necessary to the hub(s) where the team is based.

The opportunity

Grammarly is the world’s leading AI writing assistance company trusted by over 30 million people and 70,000 professional teams every day. From instantly creating a first draft to perfecting every message, Grammarly’s product offerings help people at 96% of the Fortune 500 get their point across—and get results. Grammarly has been profitable for over a decade because we’ve stayed true to our values and built an enterprise-grade product that’s secure, reliable, and helps people do their best work—without selling their data. We’re proud to be one of Inc.’s best workplaces, a Glassdoor Best Place to Work, one of TIME’s 100 Most Influential Companies, and one of Fast Company’s Most Innovative Companies in AI.

To achieve our ambitious goals, we’re looking for a Data Engineer to join our Data Engineering Platform team. This person will build highly automated, low latency core datasets that will help data engineers and end users across Grammarly to work with analytical data at scale.

Grammarly’s engineers and researchers have the freedom to innovate and uncover breakthroughs—and, in turn, influence our product roadmap. The complexity of our technical challenges is growing rapidly as we scale our interfaces, algorithms, and infrastructure. Read more about our stack or hear from our team on our technical blog.

Your impact

As a Data Engineer on our Data Engineering Platform team, you will:
• Drive improvements to make our analytics effortless by creating and adjusting core data models and storage structures, all while understanding the needs of our users.
• Make analytical data and metrics usable within a few minutes of real world events occuring, and build streaming processes for the output derived events and aggregate data.
• Model structure, storage, and access of data at very high volumes for our data lakehouse.
• Improve developer productivity and self-serve solutions by contributing components to our stream data processing framework(s).
• Own data engineering's infrastructure-as-code for provisioning services that allow our engineers to deploy mature software installations within a few hours.
• Build a world-class process that will allow our systems to scale.
• Mentor other back-end engineers on the team and help them grow.
• Build and contribute to AWS high-scale distributed systems on the back-end.

We’re Looking For Someone Who
• Embodies our EAGER values—is ethical, adaptable, gritty, empathetic, and remarkable.
• Is inspired by our MOVE principles, which are the blueprint for how things get done at Grammarly: move fast and learn faster, obsess about creating customer value, value impact over activity, and embrace healthy disagreement rooted in trust.
• Is able to collaborate in person 2 weeks per quarter, traveling if necessary to the hub where the team is based.
• Has experience with Python, Scala, or Java.
• Has experience with designing database objects and writing relational queries
• Has experience designing and standing up APIs and services.
• Has experience with system design and building internal tools.
• Has experience handling applications that work with data from data lakes.
• Has at least some experience building internal Admin sites.
• Has good knowledge of and at least some experience with AWS (or, alternatively, has deep expertise in Azure or GCE and is willing to learn AWS in a short time frame).
• Can knowledgeably choose an open source or third-party service to accomplish what they need or, alternatively, can devise a quick and simple solution on their own.

Support for you, professionally and personally
• Professional growth: We believe that autonomy and trust are key to empowering our team members to do their best, most innovative work in a way that aligns with their interests, talents, and well-being. We support professional development and advancement with training, coaching, and regular feedback.
• A connected team: Grammarly builds a product that helps people connect, and we apply this mindset to our own team. Our remote-first hybrid model enables a highly collaborative culture supported by our EAGER (ethical, adaptable, gritty, empathetic, and remarkable) values. We work to foster belonging among team members in a variety of ways. This includes our employee resource groups, Grammarly Circles, which promote connection among those with shared identities, such as BIPOC and LGBTQIA+ team members, women, and parents. We also celebrate our colleagues and accomplishments with global, local, and team-specific programs.

Compensation And Benefits

Grammarly offers all team members competitive pay along with a benefits package encompassing the following and more:
• Excellent health care (including a wide range of medical, dental, vision, mental health, and fertility benefits)
• Disability and life insurance options
• 401(k) and RRSP matching
• Paid parental leave
• Twenty days of paid time off per year, eleven days of paid holidays per year, and unlimited sick days
• Home office stipends
• Caregiver and pet care stipends
• Wellness stipends
• Admission discounts
• Learning and development opportunities

Grammarly takes a market-based approach to compensation, which means base pay may vary depending on your location. Our US and Canada locations are categorized into compensation zones based on each geographic region’s cost of labor index. For more information about our compensation zones and locations where we currently support employment, please refer to this page. If a location of interest is not listed, please speak with a recruiter for additional information.

Base pay may vary considerably depending on job-related knowledge, skills, and experience. The expected salary ranges for this position are outlined below by compensation zone and may be modified in the future.

United States

Zone 1: $167,000 - $242,000/year (USD)

Zone 2: $150,000 – $218,000/year (USD)

Zone 3: $142,000 – $206,000/year (USD)

Zone 4: $134,000 – $194,000/year (USD)

We encourage you to apply

At Grammarly, we value our differences, and we encourage all—especially those whose identities are traditionally underrepresented in tech organizations—to apply. We do not discriminate on the basis of race, religion, color, gender expression or identity, sexual orientation, ancestry, national origin, citizenship, age, marital status, veteran status, disability status, political belief, or any other characteristic protected by law. Grammarly is an equal opportunity employer and a participant in the US federal E-Verify program (US). We also abide by the Employment Equity Act (Canada).

Please note that EEOC is optional and specific to US-based candidates.

#NA

All team members meeting in person for official Grammarly business or working from a hub location are strongly encouraged to be vaccinated against COVID-19.",Springdale,US,2023-12-19 11:07:00,http://www.grammarly.com,Consulting
120,FULLTIME,Machine Learning Data Engineer,https://ai-jobs.net/job/99483-machine-learning-data-engineer/,"Requisition Id 12249 Overview: The Advanced Computing in Health Sciences (ACH) section at the Oak Ridge National Laboratory is seeking qualified applicants for a Machine Learning Engineer position for health research projects. The research activities include HIPAA compliant research data that has been entrusted to ORNL. As such, you will have the opportunity to work on some of the most challenging and impactful research and development programs in healthcare informatics, bioinformatics, high performance computing and deep learning. You will work in a collaborative research and development environment focusing on designing and implementing robust and high performance applications for biomedical research. We are looking for someone who has innovative thinking to design and implement machine learning, statistical, probabilistic, or algorithmic solutions to real world problems in the healthcare and biomedical research. As a U.S. Department of Energy (DOE) Office of Science national laboratory, ORNL has an extraordinary 80-year history of solving the nation’s biggest problems. We have a dedicated and creative staff of over 6,000 people! Our vision for diversity, equity, inclusion, and accessibility (DEIA) is to cultivate an environment and practices that foster diversity in ideas and in the people across the organization, as well as to ensure ORNL is recognized as a workplace of choice. These elements are critical for enabling the execution of ORNL’s broader mission to accelerate scientific discoveries and their translation into energy, environment, and security solutions for the nation. Major Duties/Responsibilities: As a Machine Learning Data Engineer, you will be responsible for: Independently solving a variety of sophisticated technical problems for scientific and technical projects. Developing high-quality code following best practices in the community for documentation, provenance, version control, etc. Managing, maintaining, and refactoring ML codebases, pipelines, and workflows. Collaborating closely with research staff to design and implement novel ML approaches. Implementing scalable ML methods and workflows for high-performance computing (HPC) resources, in close collaboration with research staff and computing technical staff. Mobilizing and leading data analysis activities on projects with a focus on common deliverables, goals, and timelines. Troubleshooting data analysis issues, including implementation issues, hyper-parameter choices, and modeling decisions. Assisting in preparation of manuscripts and dissemination of research results in publications and conferences. Working on a variety of data analysis assignments in collaboration with scientists and engineers. Working in secure enclaves and open computing environments on a wide variety of applied areas. Conducting tasks independently and communicate optimally to team members and stakeholders. Delivering ORNL’s mission by aligning behaviors, priorities, and interactions with our core values of Impact, Integrity, Teamwork, Safety, and Service. Promote diversity, equity, inclusion, and accessibility by encouraging a respectful workplace – in how we treat one another, work together, and measure success. Basic Qualifications: Bachelors Degree and 5+ years of relevant experience, or a Masters Degree and 4+ years of relevant experience. Degree area should be in Computer Science, Statistics, Information Systems, Engineering, or closely related field. Significant expertise with the Python ecosystem for data science. Significant expertise with PyTorch or Tensorflow. Preferred Qualifications: Foundational understanding of supervised and unsupervised learning, reinforcement learning, and deep learning. Experience with large, multimodal datasets. Experience developing scalable ML algorithms and workflows for HPC resources. Experience working on Linux/Unix platforms. Self-disciplined work ethic and eagerness to tackle ambitious research problems. Experience with heath care informatics and clinical data is highly desired. Excellent written and oral communication skills. Ability to function well in a fast-paced research environment, set priorities to accomplish multiple tasks within deadlines, and adapt to constantly evolving needs. Benefits at ORNL: ORNL offers competitive pay and benefits programs to attract and retain talented people. The laboratory offers many employee benefits, including medical and retirement plans and flexible work hours, to help you and your family live happy and healthy. Employee amenities such as on-site fitness, banking, and cafeteria facilities are also provided for convenience. In addition, we offer a flexible work environment that supports both the organization and the employee. A hybrid/onsite working arrangement may be available with this position. Other benefits include the following: Prescription Drug Plan, Dental Plan, Vision Plan, 401(k) Retirement Plan, Contributory Pension Plan, Life Insurance, Disability Benefits, Generous Vacation and Holidays, Parental Leave, Legal Insurance with Identity Theft Protection, Employee Assistance Plan, Flexible Spending Accounts, Health Savings Accounts, Wellness Programs, Educational Assistance, Relocation Assistance, and Employee Discounts. If you have difficulty using the online application system or need an accommodation to apply due to a disability, please email: ORNLRecruiting@ornl.gov or call 1.866.963.9545. #li-kc1 This position will remain open for a minimum of 5 days after which it will close when a qualified candidate is identified and/or hired. We accept Word (.doc, .docx), Adobe (unsecured .pdf), Rich Text Format (.rtf), and HTML (.htm, .html) up to 5MB in size. Resumes from third party vendors will not be accepted; these resumes will be deleted and the candidates submitted will not be considered for employment. If you have trouble applying for a position, please email ORNLRecruiting@ornl.gov. ORNL is an equal opportunity employer. All qualified applicants, including individuals with disabilities and protected veterans, are encouraged to apply. UT-Battelle is an E-Verify employer.",London,US,2023-12-19 20:33:00,http://www.bdo.com,Consulting
121,FULLTIME,Data Engineer,https://jobs.ajg.com/jobs/14916?lang=en-us,"Intro

Welcome to Gallagher – a global leader in insurance, risk management, and consulting services. With a growing team of more than 45,000 professionals worldwide, we empower businesses, communities, and individuals to thrive. At Gallagher, you can build a career whether it’s with our brokerage division, our benefits and HR consulting division, or our corporate team. Experience The Gallagher Way, a culture fueled by shared values and a collective passion for excellence. Join one of our dynamic teams, where you'll play a pivotal role in shaping Gallagher's future and unlocking unparalleled opportunities for both clients and yourself.

We believe that every candidate brings something special to the table, including you! So, even if you feel that you’re close but not an exact match, we encourage you to apply.

Overview

The Data Engineer will demonstrate broad and deep knowledge of ETL development in dimensional and relational databases in Azure and Snowflake Cloud environments. The Data Engineer will support the data analysts and data scientists on data initiatives and ensure optimal data delivery architecture is consistent throughout ongoing projects. You will engage in supporting the data needs of multiple teams, systems and products.

Responsibilities
• Build the infrastructure required for optimal ETL/ELT pipelines to ingest data from a wide variety of data sources using Microsoft Azure technologies such as Azure Data Factory and Databricks.
• Construct and maintain of enterprise level integrations using the Snowflake platform, Azure Synapse, Azure SQL and SQL Server.
• Design ETL pipelines and reusable components to implement specified business requirements Troubleshoot and optimize ETL code; interpret ETL logs, perform data validation, understand the benefits and drawbacks of parallelism, proper use of expressions, scoping of variables, commonly used transforms, event handlers and logging providers, understand and optimize the surrogate key generation and inconsistent data type handling
• Create data tools for data analytics and data science team members to deliver actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
• Conduct code reviews, performance analysis and participate in technical design
• Orchestrate large, complex data sets that meet functional/non-functional business requirements.
• Seek out, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
• Partner with data and analytics talent to strive for greater functionality in our data systems.

Qualifications
• A relevant technical BS Degree in Information Technology and 5 years of relevant professional experience implementing well-architected data pipelines that are dynamically scalable, highly available, fault-tolerant, and reliable for analytics and platform solutions
• 3+ years of data engineering experience leveraging technologies such as Snowflake, Azure Data Factory, ADLS Gen 2, Logic Apps, Azure Functions, Databricks, Apache Spark, Scala, Synapse, SQL Server
• Understanding the pros and cons, and best practices of implementing Data Lake, using Microsoft Azure Data Lake Storage
• Experience structuring Data Lake for the reliability, security and performance
• 5 years writing SQL, TSQL queries against any RDBMS with query optimization and performance tuning
• Experience implementing ETL for Data Warehouse and Business intelligence solutions
• Working experience with Python, and Power Shell Scripting
• Skills to read and write effective, modular, dynamic, parameterized and robust code, establish and follow already established code standards, and ETL framework
• Strong analytical, problem solving, and troubleshooting abilities, experience performing root cause analysis
• Good understanding of unit testing, software change management, and software release management
• Experience working within an agile team, In-depth knowledge of agile process and principles
• Excellent communication skills

#LI-TG2

Additional Information

Click Here to review our U.S. Eligibility Requirements

We offer competitive salaries and benefits, including: medical/dental/vision plans, life and accident insurance, 401(K), employee stock purchase plan, educational expense reimbursement, employee assistance program, flexible work hours (availability varies by office and job function), training programs, matching gift program, and more.",Rolling Meadows,US,2023-12-19 17:52:00,http://www.ajg.com,Finance
122,FULLTIME,Entry Level Data Analyst/Management Consultant - Nationwide (US Based Candidates Only),https://www.linkedin.com/jobs/view/entry-level-data-analyst-management-consultant-nationwide-us-based-candidates-only-at-arcadis-3701468616,"Arcadis is the world's leading company delivering sustainable design, engineering, and consultancy solutions for natural and built assets.

We are more than 36,000 people, in over 70 countries, dedicated to improving quality of life. Everyone has an important role to play. With the power of many curious minds, together we can solve the world’s most complex challenges and deliver more impact together.

Role description:

Note: See below regarding the nature of this position being a prospecting position.

Arcadis is currently seeking Analysts and Junior Management Consultants to join our world-class Business Advisory practice nationwide.

We are looking for candidates who want to apply technical know-how, combined with business principles, to the water, wastewater, and stormwater industry. We want dedicated, creative, and energetic candidates interested in tackling challenges and developing sustainable solutions to address water issues like renewal and replacement of aging infrastructure, funding of capital improvements, water supply, workforce retention and development, and emergency preparedness. Collaborating with our experienced consulting professionals, you will support and contribute to project outcomes; interact, and work with clients, and develop your technical capabilities.

We are a People First company, industry thought leaders, and drivers and allies of utility innovation.

Our passion: to Improve Quality of Life.

Our approach: to delight our clients by developing successful long-term partnerships and supporting them to address existing and emerging challenges.

Arcadis provides multiple onboarding and development programs created for young professionals that support professional growth and help drive creativeness, innovation, and greater integration within our local, National and global teams.

Role accountabilities:

What will you do?
• Assess, develop, and support a variety of management consultant projects including performing data analytics, financial analysis, operational and organizational assessments, condition assessments, vulnerability, and mitigation assessments, as well as planning and development for utilities, municipalities, and cities’ (primarily water/wastewater/stormwater utilities).
• Utilize strong analytical skills and ability to apply logic to solve problems.
• Support teams in tasks ranging from general fieldwork to technical office-based analysis.
• Assist in technical writing which may include preparation of technical reports, business development support, presentations, and other audiovisual materials.
• Work independently and as part of a team, with the flexibility to accommodate collaboration with team members across the U.S. and internationally.
• Manage multiple concurrent projects with multiple deadlines, ensuring completion per project budgets and timelines.

What skills will you need?
• Reliable, client-focused, and capable of working independently under the supervision of project managers.
• Exceptional analytical and problem-solving skills, strong attention to detail, organization skills, and work ethic.
• Self-motivated and team-oriented, with the ability to work successfully both independently and within a team.
• Ability to balance and address new challenges as they arise and an eagerness to take ownership of tasks.
• Knowledge of engineering concepts, theories, and practices related to water/wastewater/stormwater.
• Drive to succeed and grow a career in the utility industry

Qualifications & Experience:

Required Qualifications:
• Masters of Science degree in Civil or Environmental Engineering, or closely related STEM discipline; or business analytics/MBA, MS in data science or related business discipline.
• For those with engineering degrees, ability to obtain the EIT within six months of start date

Preferred Qualifications:
• Previous relevant consulting or utility experience, either internship or full-time.
• Experience applying programming languages and analytics to problem-solving is a plus
• SharePoint, Building Information Modeling (BIM), Power BI, Excel, PowerPoint, Visio, Change Management skills, and/or Augmented Reality experience

This is a general job posting and not tied to a specific current open position. Please make sure you create a search agent to be alerted of specific opportunities of interest. Candidates who submit their resume to this posting may be considered for all future openings as they arise.

Why Arcadis?

We can only achieve our goals when everyone is empowered to be their best. We believe everyone's contribution matters. It’s why we are pioneering a skills-based approach, where you can harness your unique experience and expertise to carve your career path and maximize the impact we can make together.

You’ll do meaningful work, and no matter what role, you’ll be helping to deliver sustainable solutions for a more prosperous planet. Make your mark, on your career, your colleagues, your clients, your life and the world around you.

Together, we can create a lasting legacy.

Join Arcadis. Create a Legacy.

Our Commitment to Equality, Diversity, Inclusion & Belonging

We want you to be able to bring your best self to work every day which is why we take equality and inclusion seriously and hold ourselves to account for our actions. Our ambition is to be an employer of choice and provide a great place to work for all our people. We are an equal opportunity and affirmative action employer. Women, minorities, people with disabilities and veterans are strongly encouraged to apply. We are dedicated to a policy of non-discrimination in employment on any basis including race, creed, color, religion, national origin, sex, age, disability, marital status, sexual orientation, gender identity, citizenship status, disability, veteran status, or any other basis prohibited by law.

Arcadis offers benefits for full time and part time positions. These benefits include medical, dental, and vision, EAP, 401K, STD, LTD, AD&D, life insurance, paid parental leave, reward & recognition program and optional benefits including wellbeing benefits, adoption assistance and tuition reimbursement. We offer seven paid holidays and potentially up to two floating holidays per calendar year depending on start date, and 15 days PTO that accrue per year. The salary range for this position is $52000 - 89700 / year.

#ANACollege",Cleveland,US,2023-12-19 13:00:00,http://www.arcadis.com,Construction
123,FULLTIME,Data Scientist / Data Analyst,https://www.linkedin.com/jobs/view/data-scientist-data-analyst-at-tandym-group-3756807333,"A financial services institution in New York City is looking to fill an immediate need with the addition of a new Data Scientist / Data Analyst to their team. In this role, the Data Scientist / Data Analyst will be responsible for spearheading data analysis function on the Acquisitions team byexploring, analyzing, processing and researching novel approaches in data sourcing and processing to enhance our acquisitions and underwriting models.

Responsibilities

The Data Scientist / Data Analyst will be responsible for:
• Create acquisition strategies based on data
• Build out the critical inputs that drive successful real estate expansion strategies using statistical analysis
• Create models and scenario analyses for the full lifecycle financial plan of each potential assets, fund partnership, and acquisition strategy
• Complete typical underwriting and asset due diligence which will include: analyzing the historical budgets, financial statements and asset information for individual assets and a pool of assets in a fund to create a full business plan
• Perform site tours to verify and discover property conditions and operating levels
• Manage and direct a team of external real estate contacts to execute company strategies, help with market data, and provide feedback with respect to real estate activities
• Assist with the origination and placement of debt with market participant
• Conduct market and demographic research, as well as lead site selection and property tours with teams and third-party service providers
• Perform other duties, as needed

Qualifications:
• Bachelor's Degree in Computer Science and/or Engineering
• Extensive understanding of data and its implications for Real Estate Investment
• Current knowledge of industry trends in Real Estate and Development
• An understanding of ML algorithms, data science concepts and ideally some experience in applied statistics
• Solid problem solving and time management skills
• Great interpersonal skills
• Excellent communication skills (written and verbal)
• Strong attention to detail
• Highly organized",Rockville,US,2023-12-19 12:02:00,http://tandymgroup.com,Consulting
124,FULLTIME,Senior Data Analyst,https://www.linkedin.com/jobs/view/senior-data-analyst-at-qinetiq-us-3665308024,"We are a world-class team of professionals who deliver next generation technology and products in robotic and autonomous platforms, ground, soldier, and maritime systems in 50+ locations world-wide. Much of our work contributes to innovative research in the fields of sensor science, signal processing, data fusion, artificial intelligence (AI), machine learning (ML), and augmented reality (AR).

QinetiQ US’s dedicated experts in defense, aerospace, security, and related fields all work together to explore new ways of protecting the American Warfighter, Security Forces, and Allies. Being a part of QinetiQ US means being central to the safety and security of the world around us. Partnering with our customers, we help save lives; reduce risks to society; and maintain the global infrastructure on which we all depend.

Why Join QinetiQ US?

If you have the courage to take on a wide variety of complex challenges, then you will experience a unique working environment where innovative teams blend different perspectives, disciplines, and technologies to discover new ways of solving complex problems. In our diverse and inclusive environment, you can be authentic, feel valued, be respected, and realize your full potential. QinetiQ US will support you with workplace flexibility, a commitment to the health and well-being of you and your family and provide opportunities to work with a purpose. We are committed to supporting your success in both your professional and personal lives.

Position Overview

QinetiQ US seeks a highly skilled Senior Data Analyst responsible for analyzing and interpreting complex data sets, providing insights, and driving data-informed decision-making processes. Your expertise in data analysis, management, and reporting will be instrumental in optimizing business operations, identifying trends, and supporting strategic initiatives.

Responsibilities

Data Analysis and Interpretation:
• * Collect, analyze, and interpret large and complex data sets from various sources.
• Utilize statistical techniques, data mining, and predictive modeling to extract meaningful insights and identify trends.
• Identify patterns, correlations, and relationships within the data to inform business strategies and decision-making.

Reporting and Visualization:
• * Develop and generate reports, dashboards, and visualizations to communicate data insights to stakeholders.
• Present findings in a clear and concise manner, tailored to the intended audience.
• Collaborate with cross-functional teams to ensure data-driven reports and visualizations meet business requirements.

Data Management and Quality Assurance:
• * Develop and implement data management processes and procedures to ensure data integrity and accuracy.
• Perform data cleaning, transformation, and validation to maintain high-quality data sets.
• Collaborate with IT teams to optimize data storage, retrieval, and integration processes.

Performance Measurement and KPI Development:
• Design and develop key performance indicators (KPIs) to track and measure business performance.
• Establish benchmarks and targets for KPIs and monitor progress over time.
• Analyze performance metrics to identify areas for improvement and recommend strategies for optimization.

Process Improvement and Optimization:
• Identify opportunities for process improvement and optimization based on data analysis and business insights.
• Collaborate with stakeholders to develop and implement strategies to enhance operational efficiency and effectiveness.
• Conduct cost-benefit analyses and evaluate the impact of proposed process improvements.

Data Governance and Compliance:
• Ensure compliance with data governance policies, procedures, and regulations.
• Collaborate with internal stakeholders to establish data standards and data management best practices.
• Stay updated on data privacy and security regulations and ensure data handling practices adhere to relevant guidelines.

Stakeholder Collaboration and Consultation:
• Collaborate with business stakeholders to understand their analytical needs and provide data-driven insights.
• Consult with stakeholders to define requirements, prioritize projects, and deliver actionable recommendations.
• Serve as a subject matter expert on data analysis and management techniques, providing guidance and support to colleagues.

Required Qualifications
• Bachelor's degree in Data Science, Business Analytics, Statistics, or a related field. A master's degree is preferred.
• Proven experience (5+ years) as a Data Analyst, Business Analyst, or in a similar role.
• Strong expertise in data analysis techniques, statistical modeling, and data visualization tools.
• Proficiency in programming languages such as Python, R, SQL, or similar languages used in data analysis.
• Experience with data visualization tools and platforms, such as Tableau, Power BI, or similar applications.
• Solid understanding of data management principles, data governance, and data quality assurance.
• Strong analytical and problem-solving skills, with the ability to translate complex data into actionable insights.
• Excellent communication and presentation skills, with the ability to effectively convey technical concepts to both technical and non-technical stakeholders.
• Proven ability to work with cross-functional teams and manage multiple projects and priorities simultaneously.
• Strong attention to detail, with a focus on delivering accurate and reliable results.
• Familiarity with relevant industry regulations, such as data privacy and security requirements.
• Ability to maintain discretion and confidentiality of sensitive information.
• Ability to maintain a security clearance from the U.S. government.

Preferred Qualifications
• Experience setting and managing client relationships and expectations.
• Experience effectively communicating with diverse team, client, and organizational stakeholders.
• Ability to set priorities, plan, and organize tasks and deliverables as needs evolve.
• Previous experience working for a federal government client in the national security space.

Company EEO Statement

Accessibility/Accommodation:

If because of a medical condition or disability you need a reasonable accommodation for any part of the employment process, please send an e-mail to staffing@us.QinetiQ.com or call (540) 658-2720 Opt. 4 and let us know the nature of your request and contact information.

QinetiQ US is an Equal Opportunity/Affirmative Action employer. All Qualified Applicants will receive equal consideration for employment without regard to race, age, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, or protected Veteran status.",Washington,US,2023-12-19 16:48:00,http://www.bdo.com,Consulting
125,FULLTIME,Data Engineer - USDS,https://www.linkedin.com/jobs/view/data-engineer-usds-at-tiktok-3647705558,"Responsibilities

TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

About USDS
At TikTok, we're committed to a process of continuous innovation and improvement in our user experience and safety controls. We're proud to be able to serve a global community of more than a billion people who use TikTok to creatively express themselves and be entertained, and we're dedicated to giving them a platform that builds opportunity and fosters connection. We also take our responsibility to safeguard our community seriously, both in how we address potentially harmful content and how we protect against unauthorized access to user data.

U.S. Data Security (“USDS”) is a standalone department of TikTok in the U.S. This new security-first division was created to bring heightened focus and governance to our data protection policies and content assurance protocols to keep U.S. users safe. Our focus is on providing oversight and protection of the TikTok platform and user data in the U.S., so millions of Americans can continue turning to TikTok to learn something new, earn a living, express themselves creatively, or be entertained. The teams within USDS that deliver on this commitment daily span Trust & Safety, Security & Privacy, Engineering, User & Product Ops, Corporate Functions and more.

About the Role:
As an Data Engineer, you will have significant responsibility and influence in shaping the Data Cycling Center's strategic direction. This role is inherently multi-functional, and the ideal candidate will work across disciplines. We are looking for someone with a love for data and the ability to iterate quickly. Successful candidates will have strong engineering skills and communication and a belief that data-driven processes lead to phenomenal products.

What You'll Need:
- The perfect candidate will have strong data infrastructure and data architecture skills, strong operational skills to drive efficiency and speed, strong project management leadership, and a strong vision for how data engineering can proactively improve companies.
- Experience working cross-functionally with business stakeholders, engineering, product, and SRE teams to understand business requirements and convert that into technical requirements, including developing prototypes to demonstrate the feasibility of data and analytics solutions.

What You'll Do:
- Work with business stakeholders, engineering, product and SRE teams to understand business requirements and convert that into technical requirements, including developing prototypes to demonstrate the feasibility of data and analytics solutions.
- Extract data from various sources such as APIs, HIVE tables and other structured and unstructured data sources to process and store large volumes of data ensuring data accuracy, consistency, and security.
- Design, build, and maintain data pipelines utilizing optimal ETL patterns, frameworks, query techniques, sourcing from structured and unstructured data sources to ensure data is easily accessible and can be used effectively by other members of the organization.
- Implement and monitor quality control measures to ensure data accuracy, completeness, and consistency.
- Create and maintain technical documentation, such as data dictionaries, data flow diagrams, and system documentation, to ensure efficient and effective data management and analysis.
- Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts
- Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way
- Ability to analyze and visualize data to provide business stakeholders with impactful, actionable insights

Qualifications

- Bachelors degree in Statistics, Economics, Computer Science or another quantitative field
- 5+ years of experience working with data analytics and data engineering, including experience with data cleaning and preprocessing, data analysis and dashboard development.
- 2+ years experience building dashboards in Tableau, Power BI or any similar visualization tool.
- Proficiency in distributed data processing using Big Data technologies like Spark/Scala, Java, Hadoop/HDFS/AWS/S3, Cassandra and Kafka
- Proficiency in data modeling, data design, SQL, and NoSQL databases

Preferred:
- Experience in a consumer web or mobile company
- Strong background in algorithms and data structures
- Experience working with PII and GDPR data
- Ability to communicate effectively, both written and verbal, with technical and non-technical partners
- Ability to deliver consistent high quality results while working in a dynamic & fast environment
- Passionate, curious, and seeking to tackle every day problems with innovation

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at usds.accommodations@tiktok.com

Job Information:

【For Pay Transparency】Compensation Description (annually)

The base salary range for this position in the selected city is $136800 - $259200 annually.

Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.

Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees:

We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.

Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.

We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",Mountain View,US,2023-12-19 17:46:00,http://www.bdo.com,Consulting
126,FULLTIME,Data Engineer,https://www.linkedin.com/jobs/view/data-engineer-at-space-telescope-science-institute-3749133001,"The Space Telescope Science Institute (STScI) is a multi-mission science operations center for NASA’s flagship observatories. Our world-class astronomical research center is based on the Johns Hopkins University Homewood campus in Baltimore, Maryland. Visit our website to learn more about our missions. This position can support hybrid work. Candidates must reside in or be willing to relocate to our local market. (MD, DE, VA, PA, DC & WV).

STScI has an immediate opening for a Data Engineer in the Catalog Science Branch (CSB) in the Data Management Division (DMD). The CSB branch is responsible for multi-terabyte astronomical database development and the archived science catalog data management for all missions, including the James Webb Space Telescope, the Hubble Space Telescope and the Nancy Grace Roman Space Telescope which is scheduled for launch in 2026. The team builds science data products to service the scientific community as well.

Your Role & Responsibilities include:
• Collaborate with scientists for developing science data products
• Provide technical support for scalable database platform
• Provide technical support for data ingestion, data transformation, data store and data retrieval activities
• Involve in day-to-day operations, troubleshooting and debugging, fix database production issues

Qualifications:
• Experience with relational databases (PostgreSQL/Microsoft SQL Server)
• Experience with SQL development
• Experience with python programming and development
• 2-5 years relevant experience

Preferred Qualifications:
• Familiarity with big data technologies on both structured and unstructured data
• Familiarity with large scale database cluster
• Familiarity with database development process
• Familiarity with Agile development methodology
• Familiarity with DevOps and data pipeline process and tools
• Eager to learn and grow, demonstrate great versatility and teamwork, creative problem-solver with strong analytical, verbal and written communication skills
• This position requires US Citizenship or Permanent Residence in order to meet ITAR requirements

Education/ Experience:

Bachelor’s degree in Computer Science, Engineering, Physics, Mathematics or a related technical or scientific field.

STScI will consider additional relevant education or experience for the stated qualifications. The starting position and salary are commensurate with education and experience. We offer an excellent and generous benefits package (Click here to explore our benefits). STScI offers a flexible and welcoming workspace for all (Click here to learn more about our culture).

TO APPLY: Share your experience by uploading a resume and completing an online application. Applications received by 12/15/2023 will receive full consideration. Applications received after this date will be considered until the position is filled.

Direct link:

Explore all career opportunities through our website at www.stsci.edu/opportunities

STScI embraces the diversity of our staff as a strategic priority in creating a first-rate community. We reflect this deep dedication in strongly encouraging women, ethnic minorities, veterans, and disabled individuals to apply for these opportunities (Click here to learn more about how we foster Diversity & Inclusion). Veterans, disabled individuals, or wounded warriors needing assistance with the employment process can contact us at careers@stsci.eduEOE/AA/M/F/D/V

AURA, as a leader in the astronomical community, is committed to diversity and inclusion. AURA develops and supports programs that advance our organizational commitment to diversity, broaden participation, and encourage the advancement of diversity throughout the astronomical scientific workforce www.aura-astronomy.org/diversity.asp

As a recipient of U.S. Government funding, AURA is considered a government contractor and is subject to Equal Employment Opportunity and Affirmative Action regulations. As an Equal Opportunity and Affirmative Action Employer, AURA and all of the centers, do not discriminate based on race, sex, age, religion, national origin, sexual orientation, gender identity/gender identity expression, lawful political affiliations, veteran status, disability, and/or any other legally protected status under applicable federal, state, and local equal opportunity laws. The statements below as well as the requests for self-identification are required pursuant to these regulations. We encourage your participation in meeting these federal reporting requirements that are included for protection and to assist us in our record-keeping and reporting. Your responses are kept strictly confidential.",Baltimore,US,2023-12-19 15:51:00,http://www.stsci.edu,Information
127,FULLTIME,Senior Data Analytics Developer,https://www.linkedin.com/jobs/view/senior-data-analytics-developer-at-bevi-3771686952,"Description

Bevi is on a mission to disrupt the beverage supply chain and replace single-use water bottles with smart water machines. Thousands of companies use Bevi to sustainably provide their employees with pure, sparkling, and flavored water at work. As the market leader in IoT-enabled beverage machines, we’ve raised over $160M in venture capital and we have grown tremendously each year since launch. In addition to maintaining hypergrowth with our current product line, Bevi is heavily investing in new product development.

We are seeking a Senior Data Analytics Developer who will partner across teams. Our software and smarts are critical to having the most advanced beverage machine on the market and a first mover advantage. Our sensors deliver a wealth of data on how the machine is performing. You will analyze and use that data to make data-driven improvements to our algorithms that optimize the machine. We envision this role going beyond a traditional data analyst role. This will include development work that requires understanding and tailoring the algorithms underlying the data. We use the latest technology, developing in Kotlin and Java using Android, React, CircleCI and more. We store our data in Snowflake, Postgres, InfluxDB. Our customers love our product and you will play a crucial role in making them even more happy and hydrated. If you love planning and shipping new features, and are excited to bring our team and product to the next level - come join the ride! This role is based onsite in our Boston (Charlestown) headquarters.

Responsibilities:
• Analyze time series and fleet data to enable data-driven changes to our algorithms that further improve the optimal working of the Bevi
• Design, implement, test and ship production code. You’ll be an integral part of the software team doing planning, sprints, development work, code reviews
• Collaborate with product management, business intelligence and software and hardware engineers to maximize the value of the solutions delivered by the team
• Creative problem solver that can suggest alternative solutions and compromises to drive success
• The ability to convey data both visually and verbally in a compelling way to tell a story
• Be scrappy and practical. Functions in an environment where there’s always a lot going on. Capable of combining short term with long term objectives and making good decisions under time pressure
• Take responsibility for and elevate the data capabilities of the team by introducing new tools and techniques to our data platform and championing data-driven decision makingos

Requirements
• 2+ years experience in a data analytics or adjacent role
• At a minimum, intermediate programming skills. (Kotlin, Python)
• Strong knowledge of statistics
• Excellent knowledge of SQL and databases like Snowflake
• Familiar with Jupyter notebooks, dataframes, plotting tools
• Experience with BI tools like Looker
• Previous experience writing production-level code is strongly preferred
• Strong technical understanding, ability to capture and communicate details
• An agile mindset to thrive in a fast-paced environment with a bias to get stuff done

Benefits
• Comprehensive medical, dental and vision insurance plans with BlueCross BlueShield, 95% paid by employer
• 401(k) with company match, and environmentally responsible investment options
• Flexible PTO plus 9 company holidays, and additional paid days for sick leave, etc (including sustainability or social justice volunteer events)
• Generous fully paid parental leave for both birth parents and non-birth parents
• Fully employer paid disability and life insurances
• Wellness and fitness reimbursements
• Monthly stipends for cell phone use and commuting costs
• Onsite snacks and (of course) unlimited Bevi ... plus composting and terracycling, too
• Happy hours, pancake breakfasts, Hero awards - and more!
• Join a team that shares our Bevi Core Values:
• Put Customers First
• Be Great to Work with
• Raise the Bar Together
• Act Like You Own the Business
• Be Curious and Ask Why
• Champion Sustainability",Boston,US,2023-12-19 14:41:00,http://www.bdo.com,Consulting
128,FULLTIME,Data Engineer (56664BR),https://www.linkedin.com/jobs/view/data-engineer-56664br-at-harvard-medical-school-3675208445,"Position Description

The Center for Computational Biomedicine (CCB) is a new center within the Blavatnik Institute at Harvard Medical School. Our mission is to provide cutting-edge computational capabilities, data analysis, and data integration technologies to support medical and biological research within the Medical School. Based at the Harvard Medical School Longwood Campus, we are part of a vibrant community of scientists, physicians, and engineers whose goal is to advance the boundaries of knowledge and improve patient care. The working environment combines the best features of a startup (fast pace, flexibility, flat hierarchies) with those of one of the leading medical schools (excellent benefits, outstanding opportunities for learning, great resources, name recognition).

CCB is looking for an individual to join the Data and Analytic Platforms Group, a group of engineers and scientists developing data warehousing and analytic solutions in support of epidemiology, healthcare economics, machine learning, and basic science research.

The Group works to reduce the burden on faculty by developing centrally managed and shareable data solutions to be used across research silos. We curate very large public and private healthcare utilization (insurance claims, electronic health record), multi-omics, environmental exposure, and social determinants data sets, provision access to those curated data sets, and develop analytic frameworks to accelerate reproducible academic research on top of them. Collectively these data sets contain information relating to hundreds of millions of patients.

This position reports to the Director of the CCB Data and Analytic Platforms Group. Primary responsibilities will include designing and implementing relational database architecture (schema, indexing, stored procedures, ETL processes, etc.) to warehouse multi-terabyte data sets in Microsoft SQL Server. This will include periodically evaluating various query performance metrics to ensure real-time availability to the research community and recommending modifications to the underlying database platform to resolve any identified issues. The bulk of this design work will be left up with the candidate, while a small portion will involve refactoring (or strategically deciding to abandon) existing ETL / indexing strategies. The data sets will be staged into a combination of proprietary schemas as well as the open-source i2b2 data model.

Additional opportunities will be available for the candidate to interact with individual scientific research teams to help improve their workflows.

Basic Qualifications
• Minimum of seven years’ post-secondary education or relevant work experience

Additional Qualifications And Skills
• Bachelor’s Degree in Computer Science or related degree preferred. At least 5 years experience as a software systems architect, including experience developing solutions with both relational database systems and at least one of the following languages: Java, Python, R.
• Master’s Degree in a related field (Computer Science / Electrical Engineering, Bioinformatics, Statistics, Data Science, etc.) preferred.
• Excellent communication skills, both written and oral
• Experience with Microsoft SQL Server or cloud-based data warehousing technologies
• Experience designing and maintaining multi-terabyte analytic relational databases, including index and query optimization
• Experience orchestrating and optimizing Extract-Transform-Load (ETL) processes for multi- terabyte data warehouses
• Comfort doing basic system administration in a Linux environment Comfort doing basic system administration in a Windows environment Experience with relational database index optimization
• Experience with containerized (Docker or Singularity) workflows/paradigms
• Experience with non-relational database systems (graph, key/value, document, array data stores) Experience with the R statistical computing platform
• Experience with Java Experience with Python
• Experience with high-performance computing
• Comfort independently exploring distributed computing and database technologies and generating executive reports
• Experience with public cloud platforms (AWS, Azure, Google Cloud)

Additional Information

This is a 12-month term appointment with the possibility of renewal contingent on funding.

The health of our workforce is a priority for Harvard University. With that in mind, we strongly encourage all employees to be up-to-date on CDC-recommended vaccines.

Please note that we are currently conducting a majority of interviews and onboarding remotely and virtually. We appreciate your understanding.

Harvard University offers an outstanding benefits package including:
• Time Off: 3 - 4 weeks paid vacation, paid holiday break, 12 paid sick days, 12.5 paid holidays, and 3 paid personal days per year.
• Medical/Dental/Vision: We offer a variety of excellent medical plans, dental & vision plans, all coverage begins as of your start date.
• Retirement: University-funded retirement plan with full vesting after 3 years of service.
• Tuition Assistance Program: Competitive tuition assistance program, incredibly affordable classes directly at the Harvard Extension School, and discounted options through participating Harvard grad schools.
• Transportation: Harvard offers a 50% discounted MBTA pass as well as additional options to assist employees in their daily commute.
• Wellness options: Harvard offers programs and classes at little or no cost, including stress management, massages, nutrition, meditation, and complementary health services.
• Harvard access to athletic facilities, libraries, campus events, and many discounts throughout metro Boston.

The Harvard Medical School is not able to provide visa sponsorship for this position.

Not ready to apply? Join our Talent community to keep in touch and learn about future opportunities!

( https://www.gem.com/form?formID=16341e35-cbc6-4904-88a3-09b35763307e )

Job Function

Information Technology, Research

Department Office Location

USA - MA - Boston

Job Code

I1359P IT Data Architect Prof V

Work Format

Remote

Sub-Unit

Salary Grade

059

Department

Center for Computational Biomedicine

Union

00 - Non Union, Exempt or Temporary

Time Status

Full-time

Pre-Employment Screening

Criminal, Identity

Schedule

35 hrs. per week | Monday - Friday | 9:00 am - 5:00 pm

Commitment to Equity, Diversity, Inclusion, and Belonging

We are committed to cultivating an inclusive workplace culture of faculty, staff, and students with diverse backgrounds, styles, abilities, and motivations. We appreciate and leverage the capabilities, insights, and ideas of all individuals. Harvard Medical School Mission and Community Values

EEO Statement

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, gender identity, sexual orientation, pregnancy and pregnancy-related conditions, or any other characteristic protected by law.",Boston,US,2023-12-19 16:16:00,https://hms.harvard.edu,Education
129,FULLTIME,"Staff Data Engineer, Fleet Analytics",https://www.linkedin.com/jobs/view/staff-data-engineer-fleet-analytics-at-tesla-3737835058,"What To Expect
Data is deeply embedded in the product and engineering culture at Tesla. We rely on data – lots of it – to improve autopilot, to optimize hardware designs, to proactively detect faults, and to optimize load on the electrical grid. We collect data from each of our cars, Superchargers, and energy storage devices to make these products better and our customers safer.

We're the Fleet Analytics team, a central team that helps many teams leverage the data we collect. We help engineers through direct support by doing data analysis for them and through applications and tools so they can self-serve those analyses in the future. To do so, we leverage our internal data platform built on top of AWS, S3, Spark, Trino using open source data science tools such as Jupyter notebooks, Pandas, Bokeh, Superset, and Airflow. Our work has a direct impact on Tesla's product, and enables the work of hundreds of engineers across disciplines throughout the company.

We're looking for a talented staff engineer to develop applications which leverage our wealth of device data. These applications will span the full breadth of data engineering, data analysis, and data science activities, taking a first-principles approach to problem solving to inform future hardware and firmware designs, as well as ensuring that our existing vehicles, chargers, and energy devices continue to perform to Tesla's exacting standards. Applications will include full-stack web applications, software frameworks to enable efficient training and modeling, and complex systems which drive action. You will be responsible for bringing these applications from concept to production in collaboration with other members of Fleet Analytics, as well as providing ongoing maintenance and community support. In addition, you will occasionally partner with a team focusing on another discipline (e.g., mechanical engineering, electrical engineering, or firmware engineering), joining a critical project to help them define product requirements, optimize control algorithms, or otherwise improve the product quality.

What You'll Do
• Work with stakeholders to develop and maintain complex software systems which elevate the use of device data at Tesla
• Provide guidance to Tesla's data engineering / data science community regarding best practices
• Work with engineers to drive usage of applications and tools
• Write reproducible data analysis over petabytes of data using cutting-edge open source technologies
• Summarize and clearly communicate data analysis assumptions and results
• Build data pipelines to optimize the efficiency and accuracy of analysis work across the company
• Design and implement metrics, applications and tools that will enable engineers by allowing them to self-serve their data insights
• Write clean and tested code that can be maintained and extended by other software engineers

What You'll Bring
• 7+ Years of Software Development experience in a related field
• Strong proficiency in Python, SQL
• Experience with data processing engines like Apache Spark
• Experience with data science tools such as Pandas, Numpy, R, Matlab, Octave
• Experience building data pipelines, web applications, and machine learning models in a professional environment
• Strong foundation in statistics
• Experience building data visualizations
• Strong verbal and written communication skills
• Strong problem-solving skills to help refine problem statements and figure out how to solve them with the available data and from first principles

Nice To Have
• Strong proficiency in Scala
• Understanding of distributed computing, i.e. how HDFS, Spark and Presto work
• Experience with devops tools - e.g., Linux, Ansible, Docker, Kubernetes
• Experience with complex hardware systems
• Experience with continuous integration and continuous development

Benefits
Compensation and Benefits
Along with competitive pay, as a full-time Tesla employee, you are eligible for the following benefits at day 1 of hire:
• Aetna PPO and HSA plans > 2 medical plan options with $0 payroll deduction
• Family-building, fertility, adoption and surrogacy benefits
• Dental (including orthodontic coverage) and vision plans, both have options with a $0 paycheck contribution
• Company Paid (Health Savings Account) HSA Contribution when enrolled in the High Deductible Aetna medical plan with HSA
• Healthcare and Dependent Care Flexible Spending Accounts (FSA)
• LGBTQ+ care concierge services
• 401(k) with employer match, Employee Stock Purchase Plans, and other financial benefits
• Company paid Basic Life, AD&D, short-term and long-term disability insurance
• Employee Assistance Program
• Sick and Vacation time (Flex time for salary positions), and Paid Holidays
• Back-up childcare and parenting support resources
• Voluntary benefits to include: critical illness, hospital indemnity, accident insurance, theft & legal services, and pet insurance
• Weight Loss and Tobacco Cessation Programs
• Tesla Babies program
• Commuter benefits
• Employee discounts and perks program

Expected Compensation

$104,000 - $348,000/annual salary + cash and stock awards + benefits

Pay offered may vary depending on multiple individualized factors, including market location, job-related knowledge, skills, and experience. The total compensation package for this position may also include other elements dependent on the position offered. Details of participation in these benefit plans will be provided if an employee receives an offer of employment.

Tesla",Palo Alto,US,2023-12-19 11:14:00,http://www.tesla.com,Manufacturing
130,FULLTIME,Data Engineer,https://www.linkedin.com/jobs/view/data-engineer-at-lennar-3751616897,"Overview

Lennar is seeking a Data Engineer to support our marketing and digital analytics initiatives. Lennar is poised to revolutionize home buying by bringing it online, improving customer experience, and driving business growth. The ideal candidate is an experienced, strategic data engineer with deep experience in data ingestion, data modeling, and monitoring/alerting. They’re excited about the opportunity to build a world-class data infrastructure and enabling analysts.

Responsibilities

Princ ipal Duties and Responsibilities:
• Ingest, analyze, and organize raw data into easy-to-use data sets for analysts, data scientists, and machine learners
• Build data systems and pipelines leveraging dbt, Snowflake, and Prefect
• Conduct complex data analysis and report on results
• Prepare data for prescriptive and predictive modeling
• Build algorithms and prototypes
• Combine raw information from different sources
• Explore ways to enhance data quality and reliability
• Identify opportunities for data acquisition
• Collaborate with data scientists and architects on several projects

Qualifications

E ducation and Experience Requirements:
• Bachelor’s degree or higher in Statistics, Economics, Math, Computer Science, or a related analytical field with equivalent experience.
• 5+ years in Data Engineering
• Excellent problem-solving and analytical skills
• Proactive, not reactive, with the ability to work independently in a fast-paced environment
• Ability to take in loose requirements and produce scalable and reliable data infrastructure
• Confident in learning new tools, technologies, and methodologies
• Expertise with DBT, Snowflake, Funnel, and Prefect
• Designs, builds, and monitors key data pipelines from end to end

Physical Requirements:

This is primarily a sedentary office position which requires the incumbent to have the ability to operate computer equipment, speak, hear, bend, stoop, reach, lift, and move and carry up to 25 lbs. Finger dexterity is necessary.

This description outlines the basic responsibilities and requirements for the position noted. This is not a comprehensive listing of all job duties of the Associates. Duties, responsibilities and activities may change at any time with or without notice.

Type

Regular Full-Time",Miami,US,2023-12-19 13:21:00,http://www.lennar.com,Construction
131,INTERN,Data Engineer Intern,https://www.linkedin.com/jobs/view/data-engineer-intern-at-shure-incorporated-3771576309,"SUMMER 2024

Shure offers a challenging, fun and rewarding summer internship program. The twelve-week program is offered to undergraduate and graduate students. We offer internships with a variety of work arrangements from onsite interns to fully remote in US. Each intern will receive a competitive salary. Additionally, Interns who relocate to Illinois for onsite internships will receive a housing stipend to cover living expenses. Applications will be collected, reviewed, and selected candidates will be contacted in late fall/early winter.

The data science team seeks a motivated engineer to work closely with us in designing, developing, and maintaining scalable data infrastructure. This position offers an excellent opportunity to gain hands-on experience in data engineering while working in a collaborative environment on innovative technologies supporting data analytics and data science.

This Internship can be Onsite or Hybrid or Remote

Responsibilities
• The intern will help research, prototype, and demonstrate forward-leaning use cases in next generation cloud data infrastructures and technologies.
• Working closely with our data science and data analytics team to help generate new footing for data platforms and pipelines within our current architecture.

Qualifications
• Bachelor's or master's degree in computer science, statistics, mathematics, or related field with coursework or experience in data engineering.
• Experience with full stack development languages such as Java, Scala, Python, and C#.
• Experience with database architectures like PostgreSQL, MySQL, Redshift, Snowflake, DynamoDB, MongoDB, and Cassandra.
• Experience and understanding of cloud-based services like AWS and related tools (S3, RDS, DynamoDB, Athena, Lambda, Glue, ECS/EC2, Kinesis, CloudWatch)
• Experience with containerization (Docker).
• Experience with big data technologies like Spark and data streaming is a plus.
• Creativity and curiosity for future technologies while having a strong core of fundamentals.

Who We Are

Shure’s mission is to be the most trusted audio brand worldwide – and for nearly a century, our Core Values have aligned us to be just that. Founded in 1925, we are a leading global manufacturer of audio equipment known for quality, reliability, and durability. We engineer microphones, headphones, wireless audio systems, conferencing systems, and more. And quality doesn’t stop at our products. Our talented teams strive for perfection and innovate every chance they get. We offer an Associate-first culture, flexible work arrangements, and opportunity for all.

Shure Incorporated is headquartered in Niles, Illinois, with remote and hybrid opportunities throughout the United States. We have more than 35 regional sales offices, engineering hubs, and manufacturing facilities throughout the Americas, EMEA, and Asia.

THE MIX MATTERS

Don’t check off every box in the job requirements? No problem! We recognize that every professional journey is unique and are committed to providing an equitable candidate experience for all prospective Shure Associates. If you’re excited about this role, believe you’ve got the skills to be successful, and share our passion for creating an inclusive, diverse, equitable, and accessible work environment, then apply!",Niles,US,2023-12-19 12:00:00,http://www.shure.com,Manufacturing
132,FULLTIME,"Staff Data Engineer, Data Products (Contract)",https://www.linkedin.com/jobs/view/staff-data-engineer-data-products-contract-at-sofi-3759867882,"Employee Applicant Privacy Notice

Who we are:

Shape a brighter financial future with us.

Together with our members, we’re changing the way people think about and interact with personal finance.

We’re a next-generation fintech company using innovative, mobile-first technology to help our millions of members reach their goals. The industry is going through an unprecedented transformation, and we’re at the forefront. We’re proud to come to work every day knowing that what we do has a direct impact on people’s lives, with our core values guiding us every step of the way. Join us to invest in yourself, your career, and the financial world.

Team:

SoFi is seeking an experienced and motivated Staff Data Engineer to drive high standard technical solutions for the Data Products team within the Data Enablement division. The mission of the Data Enablement division is to activate data throughout SoFi, enabling the creation of personalized and delightful experiences for our members. The Data Enablement division is responsible for Data Platform, Data Products, and Data Governance for all of SoFi. As the technical leader for the Data Products group, you will lead the vision and strategy to build foundational and critical data products, such as members' 360, members' time series etc., which are highly leveraged across SoFi for analytical, reporting, and machine learning use-cases. Our goal is to empower all teams at SoFi to make data driven decisions and effectively measure their results by providing high quality, high availability data, and democratized data access through self-service tools.

Role:

A talented, enthusiastic, detail-oriented, and experienced Data Engineer who knows how to take on big data challenges in an agile way. This includes big data design and analysis, data modeling, and development, deployment, and operations of big data pipelines. Leads development of some of the most critical data pipelines and data sets, and expands self-service data knowledge and capabilities. This role requires you to live at the cross section of data and engineering. You should have a deep understanding of data, analytical techniques, and how to connect insights to the business, and you have practical experience in insisting on the highest standards on operations in ETL and big data pipelines.

What you’ll do:
• Design and develop robust data architectures and data pipelines to support data ingestion, processing, storage, and retrieval. Evaluate and select appropriate technologies, frameworks, and tools to build scalable and reliable data infrastructure.
• Optimize data engineering systems and processes to handle large-scale data sets efficiently. Design solutions that can scale horizontally and vertically.
• Collaborate with cross-functional teams, such as data scientists, software engineers, and business stakeholders, to understand data requirements and deliver solutions that meet business needs. Effectively communicate complex technical concepts to non-technical stakeholders.
• Optimize data engineering systems and processes to handle large-scale data sets efficiently. Design solutions that can scale horizontally and vertically,
• Enforce data governance policies and practices to maintain data integrity, security, and compliance with relevant regulations. Collaborate with data governance and security teams to implement robust data protection mechanisms and access controls.

What you’ll need:
• A bachelor's degree in Computer Science, Data Science, Engineering, or a related field;
• Over 8 years of experience in data engineering and analytics technical strategy.
• Proficiency in data engineering tech stack; Snowflake / PostgreSQL / Python / SQL / GitLab / AWS / Airflow/ DBT and others..
• Proficiency in relational database platforms and cloud database platforms such as Snowflake, Redshift, or GCP
• Strong in Python and/or another data centric language.
• Thorough knowledge of data modeling, database design, data architecture principles, and data operations.
• Strong analytical and problem-solving abilities, with the capability to simplify complex issues into actionable plans.
• Experience in the Fintech industry is advantageous.

Due to the temporary nature of the engagement, this position is not eligible for visa sponsorship.

Compensation And Benefits

The base pay range for this role is listed below. Final base pay offer will be determined based on individual factors such as the candidate’s experience, skills, and location.

To view all of our comprehensive and competitive benefits, visit our Benefits at SoFi page!

SoFi provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion (including religious dress and grooming practices), sex (including pregnancy, childbirth and related medical conditions, breastfeeding, and conditions related to breastfeeding), gender, gender identity, gender expression, national origin, ancestry, age (40 or over), physical or medical disability, medical condition, marital status, registered domestic partner status, sexual orientation, genetic information, military and/or veteran status, or any other basis prohibited by applicable state or federal law.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

New York applicants: Notice of Employee Rights

SoFi is committed to embracing diversity. As part of this commitment, SoFi offers reasonable accommodations to candidates with physical or mental disabilities. If you need accommodations to participate in the job application or interview process, please let your recruiter know or email accommodations@sofi.com.

Due to insurance coverage issues, we are unable to accommodate remote work from Hawaii or Alaska at this time.

Internal Employees

If you are a current employee, do not apply here - please navigate to our Internal Job Board in Greenhouse to apply to our open roles.",Claymont,US,2023-12-19 10:33:00,http://www.sofi.com,Finance
133,FULLTIME,Sr. Data Engineer,https://www.linkedin.com/jobs/view/sr-data-engineer-at-tata-consultancy-services-3768582691,"Key Qualifications
• Fluency in Advanced SQL (complex joins, stored procedures, subqueries, window functions, performance optimization, etc.), Snowflake, Python.
• Provide analytical reporting and analytics to the operations team and external partners.
• Ability to operate in a fast paced, rapidly changing environment.
• Ability to rapidly learn and adapt to business changes.
• Excellent communication, project management, and presentation skills
• Create and maintain reports, create and manage data models, leverage data across complex hierarchies using multiple data sources.
• Leverage process improvement techniques to drive improvements in data quality.

Perform testing to support system implementations and upgrades",Austin,US,2023-12-19 13:20:00,http://www.tcs.com,Computer Services
134,FULLTIME,Pyspark Developer,https://www.linkedin.com/jobs/view/pyspark-developer-at-tiger-analytics-3551633349,"Job Description

Tiger Analytics is a global analytics consulting firm. With data and technology at the core of our solutions, we are solving some of the toughest problems out there. Our culture is modeled around expertise and mutual respect with a team first mindset. Working at Tiger, you’ll be at the heart of this AI revolution. You’ll work with teams that push the boundaries of what-is- possible and build solutions that energize and inspire. We are headquartered in the Silicon Valley and have our delivery centers across the globe. The below role is for our Chennai.

About the role:

You will work on teams building a variety of big data analytics solutions including big data

lakes. More specifically, you will work on:

Scalable data ingestion pipelines to handle real time streams, CDC events, and batch data

High-performance data processing for structured and unstructured data, and data harmonization

Scheduling, orchestrating, and validating pipelines

Exception handling and log monitoring for debugging

Collaborate with business consultants, data scientists, engineers, and application developers to develop analytics

solutions

Job Requirement

Required Experience, Skills & Competencies:

Hadoop ecosystem - HDFS, Hive, Sqoop, Kafka, ELK Stack etc

Spark, Scala, Python and core/advance Java

NOSQL databases e.g. Hbase, Cassandra, MongoDB

Relevant AWS or Azure components required to build big data solutions

Good to know: Databricks, Snowflake

Ability to develop and manage scalable Hadoop cluster environments

Good understanding of data warehousing concepts, distributed systems, data pipelines, ETL

3+ years of professional experience with at least 2 years in big data engineering

Designation will be commensurate with expertise/experience. Compensation packages are among the best in the

industry.",London,US,2023-12-19 18:07:00,http://www.tigeranalytics.com,Consulting
135,FULLTIME,DATA ENGINEER III,"https://www.ziprecruiter.com/c/United-States-Cold-Storage-Inc/Job/DATA-ENGINEER-III/-in-Camden,NJ?jid=df04b9619c2ea15f","Job Title: Data Engineer III USCS’s is the third largest 3PL in the US and leading provider of third-party logistics solutions. The Center of Digital Excellence or CoDE is the IT department for USCS that supports our mission critical warehouse operations and our various corporate systems (HR, Accounting, Finance, etc.) with custom technology solutions alongside many vendor solutions. Job Overview:We are looking for a self-motivated Data Engineer to join our data engineering and data science practice. This group is responsible for sourcing data from our internal systems, partners, industry datasets, etc. and delivering it into a consumable and maintainable data warehouse to facilitate decision making by our internal stakeholders using various analytics tools. The Job Details: · Create and maintain an optimal data pipeline architecture.· Assemble large, complex data sets that meet functional / non-functional business requirements.· Design and implement various data flow automations using various tools and technologies.· Build optimal ETL jobs and pipelines from a variety of data sources using SQL, REST APIs, Azure Data technologies, Microsoft Power Platform technologies and Python · Build analytical dashboards and reports using BI and reporting tools to provide actionable insights· Work with various stakeholders to gather requirements and provide operational support for our data warehouse, reports and dashboards· Keep our data separated and secure across national boundaries through multiple data centers and Azure and OCI cloud regions.
• Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
• Work with data and analytics experts to strive for greater functionality in our data systems.
The Job Specifics: · Location, Department and Work Hours: Camden NJ, work hours may vary. · Reports To: Sr Software Development Manager· Travel Amount: 10% · Job Type, EEO, and Job Code: Full-Time, What We Are Looking For: Education · Bachelors degree in computer science or related field or equivalent experienceExperience · 5-7 years of experience as a Data Engineer· Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.· Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.· Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.· Strong analytic skills related to working with unstructured datasets.· Build processes supporting data transformation, data structures, metadata, dependency and workload management.· A successful history of manipulating, processing and extracting value from large disconnected datasets.· Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.· Strong project management and organizational skills.· Experience supporting and working with cross-functional teams in a dynamic environment.· We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:· Experience with big data tools: Hadoop, Spark, Kafka, etc.· Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.· Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.· Experience with AWS cloud services: EC2, EMR, RDS, Redshift· Experience with stream-processing systems: Storm, Spark-Streaming, etc.· Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc. Other Abilities You Will Need to Have: The physical demands described below are representative of those required of an individual performing the essential duties of this position. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties. · Good arithmetic, reading, and typing skills · Sit and/or stand for extended periods of time · Be able to see, speak and hear · Ability to work overtime as needed · May require physical effort associated with using the computer to access information, or occasional standing, walking, lifting needed to carry out everyday activities. · Understand and follow verbal instruction, written instruction and company policies. · A starter that can work independently and coordinate with others · Follow safety procedures at all times. · Ability to manage stress and productivity guidelines The Standard Details: · Always maintain a professional manner in appearance and communications. · Participate in staff and/or customer meetings if required. · Initiate action to prevent the occurrence of any non-conformities relating to product, process, and quality systems.  · Identify and record any issues relating to product, processes and/or quality. · Initiate, recommend, or provide solutions through appropriate channels. · Verify the implementation of solutions. · Follow posted security procedures at all times while in the building. · Participate in Safety and Educational Training. What’s In It For You: A great company with great people. Full-time employees not under contract are offered: 401K and Educational Assistance after 1 year; If elected, Blue Cross Blue Shield after 30 days of service; Company Life Insurance; and a bunch of other great perks. Things We Need To Mention: · The above job description may not include all tasks necessary to complete the job. · Job functions may vary based on area of operation. The job description is a listing of the most common tasks the associate will be required to perform in that job area. · Reasonable accommodations may be made to enable individuals with disabilities to perform the essential duties.",Camden,US,2023-12-19 20:15:00,http://www.uscold.com,Logistics
136,FULLTIME,"Data Engineer, Data Platform - US Tech Services Team",https://www.linkedin.com/jobs/view/data-engineer-data-platform-us-tech-services-team-at-tiktok-3646525311,"Responsibilities

About Tiktok
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

About USDS
At TikTok, we're committed to a process of continuous innovation and improvement in our user experience and safety controls. We're proud to be able to serve a global community of more than a billion people who use TikTok to creatively express themselves and be entertained, and we're dedicated to giving them a platform that builds opportunity and fosters connection. We also take our responsibility to safeguard our community seriously, both in how we address potentially harmful content and how we protect against unauthorized access to user data.

U.S. Data Security (“USDS”) is a standalone department of TikTok in the U.S. This new security-first division was created to bring heightened focus and governance to our data protection policies and content assurance protocols to keep U.S. users safe. Our focus is on providing oversight and protection of the TikTok platform and user data in the U.S., so millions of Americans can continue turning to TikTok to learn something new, earn a living, express themselves creatively, or be entertained. The teams within USDS that deliver on this commitment daily span Trust & Safety, Security & Privacy, Engineering, User & Product Ops, Corporate Functions and more.

As a data engineer in the data platform team area, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world that directly supports the TikTok app. You'll have the opportunity to gain hands-on experience on all kinds of systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users.

• Design, build and maintain data transformations efficiently and reliably for different purposes (e.g. reporting, growth analysis, multi-dimensional analysis)
• Design, implement and maintain reliable, scalable, robust and extensible big data systems that support core products and business
• Establish solid design and best engineering practice for engineers as well as non-technical people

Qualifications

• Bachelor's degree in Computer Science, a related technical field involving software or systems engineering, or equivalent practical experience
• Experience in performing data analysis, data ingestion and ETL(Extraction, Transformation & Loading)
• Experience with the Big Data technologies is a plus (Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc)

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at usds.accommodations@tiktok.com

Job Information:

【For Pay Transparency】Compensation Description (annually)

The base salary range for this position in the selected city is $177688 - $341734 annually.

Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.

Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees:

We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.

Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.

We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",Seattle,US,2023-12-19 15:16:00,http://www.bdo.com,Consulting
137,FULLTIME,Junior Market Data Engineer,https://www.linkedin.com/jobs/view/junior-market-data-engineer-at-stonex-group-inc-3740502370,"Overview

Permanent, full-time, hybrid (3 days per week in an office)

Working as part of the Enterprise Market Data team, you will be responsible for the design, development, and testing of several key greenfield projects in the StoneX Global Market Data space. Work streams will include both business initiatives and technology modernization. You will be working on the strategic implementation of a new technology stack based on the Refinitiv TREP infrastructure. You will be expected to make an active contribution to this process and be prepared to offer ideas and solve problems at every stage of each project. The projects you will be working on will mainly be server-side.

Responsibilities

Key Responsibilities:
• Perform detailed review of requirements, designs, and code to ensure thorough due diligence is applied.
• Understand individual business requirements to design, develop, and test effective solutions.
• Understand and implement required development guidelines, design standards, and best practices.
• Understand in detail the business operational process both before and after the impact of any software change.
• Ensure software releases support continuous build and automated deployment practices.
• Provide prompt and knowledgeable assistance to business continuity and platform operations whenever requested.
• Work to identify risks and to enhance control across the business.
• Production support

Qualifications

Essential Skills, Knowledge & Experience:
• C++ development (minimum 4 years of educational experience)
• Experience with threading, low latency, and lockless techniques
• Experience with Linux
• Understanding of Agile, Scrum processes

Desirable Skills, Knowledge & Experience:
• Experience with performance optimization
• Understanding of NUMA, L1 cache, TCP Offload, PTP time synch and other hardware considerations
• Working with streaming “real time” messaging in a distributed system
• Experience with Market Data and TREP development
• Experience with TREP Refinitiv
• RFA/UPA/Elektron, and MDF/OMM messaging technologies
• Knowledge of C++20
• Experience with Python, Bash, and other scripting language
• Experience with TeamCity and other CI/CD tools
• Experience with Ansible

Education:
• BS/MS degree in Computer Science, Engineering, or a related subject",Chicago,US,2023-12-19 12:13:00,http://www.stonex.com,Finance
138,FULLTIME,Senior Data Engineer,https://www.linkedin.com/jobs/view/senior-data-engineer-at-salesforce-3738099369,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.

Job Category

Software Engineering

Job Details

About Salesforce

We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.

The Data and Analytics Organization (DnA) is Salesforce's cornerstone for fostering growth and margins through unparalleled data insights. From robust governance to strategic execution, we support data pioneers with an unbiased approach. Our Enterprise Data Strategy builds a solid data foundation, fostering a culture of data-driven decisions. We ensure end-to-end quality through a cohesive data supply chain. By deploying and integration platform tools, we enable seamless data access and automated data management driving efficiency and growth with actionable insights. As a steadfast partner, we shape a data ecosystem that fuels innovation. Our commitment to integrity and accessibility propels informed decision-making, propelling Salesforce to new heights of excellence.

Interesting Articles about some of our work and our culture:
• https://www.salesforce.com/blog/what-does-salesforce-do/
• https://www.salesforce.com/company/equality/
• https://www.salesforce.com/resources/data

Team Overview

Data Strategy and Management Engineering team brings Data to life, partnering with data producers and platform engineers to empower data consumers (data scientists, data analysts and visualization engineers) who consume data for business analytics and AI augmented solutions. We do this by delivering trusted data, in an agile way and make it accessible for a variety of use cases. We pride ourselves in being data curious (one who has an intrinsic need to understand a data point). We architect, automate, and scale our data curation frameworks, services, and processes to rapidly integrate disconnected and disparate raw data into a business-relevant asset and work towards one common theme - Customer Success.

Role Description
• Design, build, and maintain scalable and efficient data pipelines and ETL processes to support data-driven decision-making.
• Implement data validation and monitoring processes to ensure data quality and integrity throughout the data lifecycle.
• Have opinionated views on how data will be collected, stored, consumed & managed.
• Ensure compliance with governing standards, data quality & protection principles.
• Optimize data storage and retrieval mechanisms to enhance performance and cost-effectiveness, making data readily accessible for analytics.
• Participate in code reviews and contribute to the development of coding standards and best practices to ensure high-quality data engineering solutions.

If You Are,
• Experienced Data Engineer: Demonstrated experience in data engineering roles with a strong foundation in data pipeline development.
• Experienced Professional:
• Proficient in big data technologies like Hadoop, Spark, Presto, Hive, Snowflake etc...
• Strong coding skills in Python/Java/Scala or equivalent
• Understanding of scalability and reliability concerns for data-intensive applications
• Data Engineering Enthusiast: Passion for data engineering and a desire to grow in this field.
• Collaborative & Communicative: Effective communication skills and the ability to work well within a team.
• Data Advocate: Strong commitment to data quality, security, and compliance.
• Preferred: Familiarity with cloud-based data platforms (e.g., AWS, GCP, Azure).

Minimum Requirements (Senior Data Engineer)
• Bachelor’s or Master's degree in Computer Science, Information Technology, or related field.
• 6+ years of experience in data engineering and related roles.

Accommodations

If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.

Posting Statement

At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com.

Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce.

Salesforce welcomes all.",Atlanta,US,2023-12-19 12:39:00,http://www.salesforce.com,Information
139,FULLTIME,Data Engineer,https://www.linkedin.com/jobs/view/data-engineer-at-advantasure-3605746612,"Job Description

Data Engineer

Lead II - Data Analysis

Who We Are

Advantasure is a growing company and a member of the UST HealthProof family, Advantasure champions innovative solutions with an eye on the future—providing health plans with the flexibility to adapt to a changing regulatory environment and evolving business needs. Leveraging the industry’s leading experts in government-sponsored health plans, Advantasure offers solutions for administrative cost management, quality patient outcomes and experiences, enrollment growth, risk adjustment and quality and provider engagement initiatives.

We achieve this mission together through teamwork, communication, collaboration, and focus. Our employees are our greatest assets, and we invite you to apply to be a part of our journey toward making a difference in healthcare in the United States.

You Are

UST is searching for a Data Engineer who will independently provide expertise on data analysis techniques using software tools, streamlining business processes, and managing teams.

The Opportunity
• Work with Technical Leads and Architects to analyze solutions.
• Translate complex business requirements into tangible data requirements through collaborative work with both business and technical subject matter experts.
• Develop/modify data models with an eye toward high performance, scalability, flexibility, and usability.
• Ensure data models are in alignment with the overall architecture standards.
• Create source-to-target mapping documentation.
• Subject matter knowledge guidance in source system analysis and ETL build.
• Responsible for overseeing data integrity in the Smart Conductor system
• Serves as data flow and enrichment “owner” with deep expertise in data dynamics, capable of recognizing and elevating improvement opportunities early in the process
• Work with product owners to understand business reporting requirements and deliver appropriate insights on a regular basis
• Responsible for system configuration to deliver reports, data visualizations, and other solution components

This position description identifies the responsibilities and tasks typically associated with the performance of the position. Other relevant essential functions may be required.

What You Need
• More than 5 years of software development experience
• Proficient in Power BI/Tableau, Google Data Studio, R, SQL, Python
• Strong knowledge of cloud computing and experience in Microsoft Azure – Azure ML Studio, Azure Machine Learning
• Strong knowledge of SSIS
• Proficient in Azure services - Azure Data Factory, Synapse, Data Lake
• Experience querying, analyzing, or managing data required
• Experience within the healthcare insurance industry with payer data is strongly preferred
• Experience in data cleansing, data engineering, data enrichment, data warehousing/ Business Intelligence preferred
• Strong analytical, problem solving and planning skills.
• Strong organizational and presentation skills.
• Excellent interpersonal and communication skills.
• Ability to multi-task in a fast-paced environment.
• Flexibility to adapt readily to changing business needs in a fast-paced environment
• Team player who is delivery-oriented and takes responsibility for the team’s success.
• Enthusiastic, can-do attitude with the drive to continually learn and improve.
• Knowledge of Agile, SCRUM, and/or Agile methodologies.

Compensation can differ depending on factors including but not limited to the specific office location, role, skill set, education, and level of experience.  As required by local law, UST HealthProof provides a reasonable range of compensation for roles that may be hired in California, Colorado, New York City, or Washington as set forth below.  

Role Location: Range of Starting Pay for Role

Remote: $97,000-$145,000

Our associates are eligible for employee stock options, 401K matching, and covered from day 1 for paid vacation and sick time, and healthcare, dental, vision, life, and disability insurance benefits.

What We Believe

We’re proud to embrace the same values that have shaped UST and its subsidiaries since the beginning. Since day one, we’ve been building enduring relationships and a culture of integrity. And today, it's those same values that are inspiring us to encourage innovation from everyone to champion diversity and inclusion and place people at the center of everything we do.

Humility: We will listen, learn, be empathetic, and help selflessly in our interactions with everyone.

Humanity: Through business, we will better the lives of those less fortunate than ourselves.

Integrity: We honor our commitments and act with responsibility in all our relationships.

Equal Employment Opportunity Statement

UST HealthProof is an Equal Opportunity Employer.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

#Advantasure",London,US,2023-12-19 10:35:00,http://www.advantasure.com,Consulting
140,FULLTIME,Sr. Data Engineer Jobs,https://www.clearancejobs.com/jobs/7462400/sr-data-engineer,"ECS is seeking a Sr. Data Engineer to work in our Washington, DC office.

Job Description:

ECS is seeking a TS-cleared Sr. Data Engineer to support one of our mission critical programs for the Department of Justice. We offer the chance to support the world's finest law enforcement organization and help the people that keep us safe. In this job you will support agents, analysts, and professionals and technology they use to fight terrorism, espionage, cyber-attacks, and major criminal threats.

We are seeking candidates committed to high quality to provide courteous and accurate technical information. As a Sr. Data Engineer, you will collaborate with customers, often engaging directly with non-technical personnel, to understand their data science related needs, suggest solutions, and complete work in a timely manner. This position performs activities associated with implementation, integration, and support of computer systems in mission-critical response operations environment.

General Responsibilities are listed below:
• Develop, implement, and utilizes data systems and other strategies that optimize statistical efficiency and data quality.
• Analyzes, identifies, and assesses data attributes using statistical software packages; develops recommendations and processes to improve operational performance ensuring adherence to Bureau policies and procedures.
• Performs statistical analysis and research in support of investigative projects. Prepares reports, materials and documentation associated with information gathering.
• Interprets and analyzes data collected from a variety of sources using exploratory and statistical techniques.
• Constructs tailored data visualizations to assist the novice in understanding the analytic results.
• Uses advanced/complex mathematical methodologies/algorithms to develop new innovations in the use of data analysis techniques, as well as to analyze and interpret trends or patterns in complex data sets.

Required Skills:
• Bachelors Degree
• Must have a current Top-Secret Clearance with the capability of obtaining SCI / CI-Poly if needed to meet contract requirements
• Minimum 10 years of experience
• Experience with AI, statistical analysis, data modeling and visualization.
• Ability to take bulk data, organize it and run queries.
• Technical expertise regarding data analysis and manipulation, data cleansing, and segmentation techniques.
• Professional competence in scientific methods of analysis to perform inquiry into exceptionally difficult or unprecedented problems.
• Professional skill in the development of research designs and methodologies, including statistical sampling and analytic methods, to provide sound plans for coordinating or conducting studies and to effectively complete analytic projects.
• Professional skill in modeling of real-world problems and in applying probability theory and statistical analysis to models and research data.
• Comprehensive knowledge of general mathematics, to develop research models and to design and carry out statistical analyses.
• Knowledge of and skill in the configuration and use of computer equipment for scientific research, including technical skill in the use of data analysis software, data base software, spreadsheet software, statistical software, graphics, and other software.
• Skill in computer programming to efficiently develop models, collect data, and analyze data using computers.
• Skill in data acquisition, processing, and measurement to collect research data effectively and according to accepted scientific methods.
• Skill in oral communications to provide effective presentations and instruction concerning the research.
• Exceptional writing skills to produce reports/documents reflective of the findings/results of the analysis.

Desired Skills:
• AWS Certification
• Willingness to learn new skills and technologies on the fly
• Ability to communicate with customers to refine requirements.
• Ability to deconstruct customer requirements into delineated tasks.
• Being a team player, willing to transparently collaborate with technical SMEs.
• Experience with building and utilizing databases within an IT Infrastructure
• Experience with implementing scalability within an AWS Cloud infrastructure.
• Work in data warehouse environment, which includes data design, database architecture, metadata and repository creation.
• Perform Extract, Transform, Load tasks.
• Translate business needs into long-term architecture solutions.
• Develop data warehousing blueprints, evaluating hardware and software platforms, and integrating systems.
• Review object and data models and the metadata repository to structure the data for better management and quicker access.

ECS is an equal opportunity employer and does not discriminate or allow discrimination on the basis of race, color, religion, gender, age, national origin, citizenship, disability, veteran status or any other classification protected by federal, state, or local law. ECS promotes affirmative action for minorities, women, disabled persons, and veterans.

ECS is a leading mid-sized provider of technology services to the United States Federal Government. We are focused on people, values and purpose. Every day, our 3800+ employees focus on providing their technical talent to support the Federal Agencies and Departments of the US Government to serve, protect and defend the American People.",Washington,US,2023-12-20 00:01:00,http://www.bdo.com,Consulting
141,FULLTIME,Data Science Engineer Intern - Summer 2024,https://www.linkedin.com/jobs/view/data-science-engineer-intern-summer-2024-at-ericsson-3765657914,"Data Science Engineering Intern

Location: Plano, TX

About This Opportunity

We are now looking for a Data Analyst to define, create, automate, and maintain key operational and statistical data (standard and customized). In this role you will develop new processes to increase task effectiveness and to consolidate in scope customers

What You Will Do
• Deliver standard & new measure/analysis
• Drive Continuous Service and Process Improvement (CSI)
• Translate business requirements into analytics
• Identify new measures /improvement by spotting patterns, trends, and correlations
• Maintain/upgrade existing measures/analysis
• Present large amounts of information in ways that are universally understandable or easy to interpret
• Create management Dashboards

You will bring
• Enrollment in Bachelors or Master's degree program in Computer Science, Engineering, Mathematics or Statistics
• Relevant industry experience in analytics and development activity
• Acumen for business flow understanding and expertise in data preparation and pre-processing
• Automation oriented mindset
• Excel/Access knowledge, including knowledge of macros. VBA programming (to manage / develop custom reports)
• Programming languages (e.g. C#, .NET, Java etc.) would be a plus
• SQL, PL/SQL, SQL Server, SSIS knowledge and experience
• Experience with Tableau, PowerBI or any other visualization tool
• PHP would be an advantage (to manage / develop portal)
• New wave programming for machine learning - like Python would be considered a plus

This role reports to the Head of Global Delivery Management

Why join Ericsson?

At Ericsson, you´ll have an outstanding opportunity. The chance to use your skills and imagination to push the boundaries of what´s possible. To build never seen before solutions to some of the world’s toughest problems. You´ll be challenged, but you won’t be alone. You´ll be joining a team of diverse innovators, all driven to go beyond the status quo to craft what comes next.

What happens once you apply?

Click Here to find all you need to know about what our typical hiring process looks like.

Encouraging a diverse and inclusive organization is core to our values at Ericsson, that's why we nurture it in everything we do. We truly believe that by collaborating with people with different experiences we drive innovation, which is essential for our future growth. We encourage people from all backgrounds to apply and realize their full potential as part of our Ericsson team.

Ericsson is proud to be an Equal Opportunity and Affirmative Action employer, learn more.

If you need assistance or to request an accommodation due to a disability, please contact Ericsson at hr.direct.mana@ericsson.com.

DISCLAIMER: The above statements are intended to describe the general nature and level of work being performed by employees in this position. They are not an exhaustive list of all responsibilities, duties and skills required for this position, and you may be required to perform additional job tasks as assigned.

]]>",Plano,US,2023-12-19 12:00:00,http://www.ericsson.com,Information
142,FULLTIME,Senior Data Engineer,https://www.linkedin.com/jobs/view/senior-data-engineer-at-strongdm-3759010720,"StrongDM lives by a very simple principle: Put People First.

That means we do the right things by our colleagues, employees and customers. It also means developing products and solutions that improve the lives of our customers. Our commitment to People First is one of the reasons our year-over-year customer retention rate is an industry-leading 98%. Once a customer, forever a fan. That's our goal.

When you work at StrongDM, you work with people who care, technology that works, and customers who are obsessed with both the product and the support they receive.

If you ask any employee of StrongDM, you’ll find that our values truly are our guiding principles in everything we do–from how we make decisions to how we treat each other. That’s because these values represent the foundation for our culture and who we are as a company. It sounds cliche, we know. But trust us—we’re onto something good. G2 can confirm. ✔️
• We embrace the mission
• We pursue mastery
• We are people first
• We are smarter together

These are the values we seek to cultivate as an organization. They inform not just how we behave as individuals and teams, but also the unspoken traits of the candidates we hire and perspectives we take when helping and supporting customers. Speaking of candidates, we’re so glad you’re here! If this sounds like an environment you’d thrive in, read on.

WHAT YOU’LL DO:
• Building the infrastructure for processing data from many different sources
• Designing and maintaining data infrastructure, pipelines, and databases in support of StrongDM’s overall product strategy
• Implement scalable, performant, and reliable data pipelines and data platforms for various use cases spanning business intelligence, machine learning, and more
• Ability to design large-scale data architectures that balance performance, cost, and platform flexibility

REQUIREMENTS:
• 5 or more years of hands-on experience with building and maintaining data infrastructure in the cloud and at many PB scale. Must have experience with customer-facing data products e.g. embedded BI dashboards
• Experience with traditional databases (SQL and NoSQL), cloud data warehouses, and lake houses
• Experience with the following: Postgres, Redshift/Snowflake/BigQuery, Databricks, Dremio/Presto, Iceberg/Tabular and S3
• Able to manage data infrastructure programmatically using IaC (Terraform)
• Familiarity with popular BI tools like Looker, Tableau, Preset, and others.
• Good command of ETL tools like dbt, Airflow, Meltano
• You work very well cross-functionally and are able to think rigorously and make hard decisions and tradeoffs.

Compensation
• $160,000-$190,000 + equity salary packages
• Company sponsored benefits, including:
• Medical, dental, and vision insurance (free to employees and dependents)
• 401K, HSA, FSA, short/long-term disability coverage, life insurance
• 6 weeks of combined accrued vacation + sick time
• Volunteer days + standard holidays
• 24 weeks paid parental leave for everyone + 1 month transition time back + childcare stipend for first year
• Generous monthly and annual stipend for internet + home office

$160,000 - $190,000 a year",London,US,2023-12-19 13:46:00,https://www.strongdm.com,Consulting
143,FULLTIME,Lead Data Engineer - Hybrid,https://www.linkedin.com/jobs/view/lead-data-engineer-hybrid-at-incendia-partners-3724314055,"Description:

We are searching for a Lead Data Engineer to implement data engineering and analytics solutions .

Primary responsibilities include full implementation and maintenance of data ingestion, data maintenance, data validation and data delivery of investment data.

We are looking for someone who thrives in an agile, collaborative, team-based environment, working closely with technology peers across the organization, investment professionals and key vendor partners.

This position offers the opportunity to shape the future of investment data here.

Duties:
• Design, develop, and implement data pipelines to maintain unified data platform for the Investment Data Management group
• Lead and participate in all development activities, develop and implement solutions to meet business requirements that align with program strategic objectives
• Responsible for new and on-going development of data pipelines sourcing from internal and external sources
• Drive continuous improvement of data quality, resiliency, control, efficiency, and monitoring
• Troubleshooting complex system interactions to find the root cause to problems
• Partner with platform lead to design, develop, implement and deploy new software components to investment data platform
• Partner with data architect to evaluate and finalize the unified data model
• Partner with integration architect to upgrade and integrate data ingestion and data delivery tools with the unified data platform
• Upgrade and integrate transformation tool, data validation tool and orchestration tools with the unified data platform to implement data engineering, analytical engineering and data maintenance capabilities.
• Provide support during unexpected outages

Qualifications:
• Bachelor’s degree in Computer Science or related disciplines.
• Minimum of 5 years of experience in design, development and building data oriented complex applications.
• Deep understanding of Agile SDLC, DevOps and Cloud technologies required, in addition to exposure to multiple, diverse technologies, platforms, and processing environments.
• Experience in data integration, data warehouse, data modeling and data analytics architecture and design principles. Knowledge of and experience with Snowflake and other cloud native databases is highly preferred.
• Knowledge about various architectures, patterns such as unified data management architecture (UDM), data mesh architecture, event-driven architecture, real-time data flows, non-relational repositories, data virtualization, tc.
• Experience with building solutions in the financial services domain with an understanding of financial instruments, transactions, and positions, is desired.
• Good interpersonal and communication skills with the ability to lead cross-team collaboration and partnerships across a variety of internal and external constituencies.

#ZR",Boston,US,2023-12-19 22:26:00,http://www.incendia.com,Consulting
144,FULLTIME,Lead Data Engineer,https://www.linkedin.com/jobs/view/lead-data-engineer-at-plymouth-rock-assurance-3755173097,"The Plymouth Rock Home Group is an innovative Insurtech start-up within a successful, well-established insurance organization. We quadrupled topline revenue over the past 4 years by revolutionizing the way homeowners insurance is priced, marketed, bought, and sold. Our customers obtain a home insurance quote in seconds using our @Home quoting engine. But the fast quote is not the real innovation. We collect large, detailed data about homes, homeowners and where they are located. The @Home product uses cutting edge techniques from skilled data scientists across machine learning and artificial intelligence to create models that predict loss costs, likelihood to buy, the best service and coverages we can offer, and the best way to provide them. The result is a simplified sales process and a feature-rich coverage package that our distributors want to sell and consumers want to buy.

Here Is What You Will Do
• Work with key leaders across Data Science, IT and Business to spearhead data engineering and infrastructure projects for our rapidly growing @Home business.
• Assist with the transition to a Cloud based data lake and help drive new ways of working that capture the benefits of new technology and techniques.
• Search for and obtain relevant data that helps us understand and serve all homeowners, even potential customers who do not choose to buy from us.
• Make data and the insights generated from it accessible to the entire organization.
• Create and manage data infrastructure to design, develop, and enhance the data and analytics solutions and pipelines, enabling data-driven decision-making processes.
• Work closely with the IT development team in building Innovative, API first, cloud native solutions using AWS platform, Snowflake, Python, etc.
• Enhance full delivery pipeline through automation, expanded yet increasingly efficient test coverage, ultimately optimizing time-to-market and overall quality
• Optimize and fine-tune existing data pipelines for performance, scalability, and reliability.
• Implement data quality checks and monitoring processes to ensure data accuracy and consistency.
• Stay current with industry trends and best practices in data engineering and recommend improvements to existing processes
• Mentor analysts across the organization; collaborate in technical documentation; participate in code reviews and adhering to engineering excellence/best practices.
• Play a pivotal role in shaping the future of data analysis while thriving in a fast-paced environment that encourages personal growth and development.

Here Is What You Will Bring To The Table
• A vision of how to do things differently – better, faster, cheaper, adding more value – than our competitors.
• A bachelor’s degree in a technical or business discipline, or equivalent experience.
• 3+ years of related data engineering experience with focus on designing and building data pipelines.
• Expert in Python, proficient in SQL, additional SAS knowledge a bonus for legacy code.
• Experience with data modeling and data warehousing.
• Experience with cloud data platforms, Snowflake (preferable), AWS.
• Proficiency with AWS Services including but not limited to AWS S3, AWS Glue, AWS Lambda, AWS EC2, Sagemaker.
• Proficient with ETL/ELT data pipelines, patterns for loading Data Warehouses, Lakes.
• Experience with build/deploy automation & DevOps frameworks (CI/CD, Bamboo, GitHub Actions, pipeline-as-code).
• A design thinking and test-driven development mindset.
• Experience with business intelligence tools and reporting solutions (Tableau etc.).

About The Company

The Plymouth Rock Company and its affiliated group of companies write and manage over $1.8 billion in personal and commercial auto and homeowner’s insurance throughout the Northeast and mid-Atlantic, where we have built an unparalleled reputation for service. We continuously invest in technology, our employees thrive in our empowering environment, and our customers are among the most loyal in the industry. The Plymouth Rock group of companies employs more than 2,000 people and is headquartered in Boston, Massachusetts. Plymouth Rock Assurance Corporation holds an A.M. Best rating of “A-/Excellent”.",Boston,US,2023-12-19 12:39:00,http://www.plymouthrock.com,Finance
145,FULLTIME,Senior Data Engineer,https://www.linkedin.com/jobs/view/senior-data-engineer-at-mgic-3735279019,"Why work at MGIC?

Are you someone who wants to play a critical role in our company’s success? Do you enjoy solving puzzles and finding a better way to get things done? Are you someone who likes to Take The Lead and make an impact? If so, then imagine yourself at MGIC. At MGIC we are a team of dedicated professionals on a fearless mission. A team that fosters a culture of career development and continuous learning opportunities to help you rise to new heights. We are passionate about providing outstanding customer service and making a difference in our community. #WeAreMGIC

Preferred location: Milwaukee based – hybrid (3 days office, 2 days remote)

Other locations: Madison, Minnesota, Illinois, and Michigan (occasional travel into the office to support team engagements).

How will you make an impact?

We are currently looking for a Senior Data Engineer to deliver high quality, maintainable and scalable data solutions. The Senior Data Engineer will partner with solution architects and other data engineers to develop our enterprise analytics data platform through new and updated data pipelines leveraging shared components and aligning to standards and best practices. This role is focused on collecting data from internal and external sources and transforming it into usable information for the business including data scientists and data analysts.
• Deliver high quality data assets to be used by the business to transform business processes and to enable leaders to make data-driven decisions
• Continuously improve data solutions to increase quality, speed of delivery and trust of data engineering team’s deliverables to enable business outcomes
• Reduce total cost of ownership of solutions by developing shared components and implementing best practices and coding standards

Do you have what it takes?
• Ability to translate data engineering designs into working code
• Data analysis and data engineering pipeline experience including design, development, and support
• Experience with AWS services or cloud data offerings including S3, Lambda, EMR, Dynamo DB, Glue, Snowflake and/or other data technologies.
• Experience with coding in Python, PySpark, and Terraform
• Experience with DevOps practices including Continuous Integration, Continuous Delivery, and Infrastructure as Code to deliver end-to-end automation of data delivery.
• Ability to train and mentor junior data engineers.
• Experience with Agile engineering practices including the scrum framework.

Enjoy these benefits from day one:
• Competitive Salary & pay-for-performance bonus
• Financial Benefits (401k with company match, profit sharing, HSA, wellness rewards program)
• On-site Fitness Center and classes (corporate office)
• Paid-time off and paid company holidays
• Business casual dress

For additional information about MGIC and to apply, please visit our website at www.mgic.com/careers.",London,US,2023-12-19 16:07:00,http://mgic.com,Consulting
146,FULLTIME,Senior Cloud Data Engineer,https://www.linkedin.com/jobs/view/senior-cloud-data-engineer-at-bdo-usa-3765467842,"Job Description

Job Summary:

This position will work with cutting edge technology, deliver high quality solutions across various industries, and oversee team(s) on engagements that range in size and scope. This position will receive continuous career development opportunities, given the size and potential of client engagements. This role will perform hands-on delivery of data analytics projects, contributing to the development and unit testing of solutions.

Job Duties
• Designs and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS
• Listens to client needs to align solution with business requirements and delivery schedule
• Creates written functional and technical designs
• Participates in project status and stand meetings, and assists with providing aggregated project status for project and program managers
• Assists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions
• Writes code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles
• Delivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency)
• Assists with implementation of data governance programs and best practices
• Performs the cleaning and transforming of data from source systems into analytics models
• Implements models to support data visualizations and integrations
• Assists with implementing DevOps, DataOps and MLOps methodologies on projects
• Writes custom integration logic in applicable programming languages
• Assists project managers with work breakdown structure creation, project estimation, resource staffing, workload planning and adjustments throughout the project lifecycle
• Assists clients with licensing, security, and cost estimation of solutions
• Performs code reviews to ensure adherence to standards
• Works directly with clients and team members to establish secure data analytics platforms and infrastructure
• Contributes to successful deployments of developed solutions and integration of DevOps tools
• Maintains a broad and current understanding of data analytics and business intelligence strategies, cloud platforms, methodologies, and tools
• Builds client relationships during project execution, effectively becoming a trusted advisor of the client
• Participates in support activities for existing software solutions
• Other duties as assigned

Supervisory Responsibilities
• Supervises the day-to-day workload of Associates on assigned engagements to ensure that timelines and deliverables are met, and reviews work product

Education

Qualifications, Knowledge, Skills and Abilities:
• High School Diploma or GED equivalent, required
• Bachelor’s degree, preferred; focus in Information Systems, Data Science or Computer Science, preferred

Experience
• Five (5) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required
• One (1) or more years of experience technically leading development projects, preferred
• One (1) or more years of consulting experience or implementation of cloud-based data analytics solutions, preferred

Software
• Strong SQL skills including Data Definition Language (DDL), Data Manipulation Language (DML), views, functions, stored procedures, or performance tuning, required
• Experience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema Construction, required
• Hands on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, preferred
• Experience with one (1) or more of the following computer languages, preferred:
• C#
• Python
• Java
• Scala
• Experience with tabular modeling within Microsoft Fabric, Power BI, or Azure Analysis Services, preferred
• Experience with Git and DevOps deployment technologies, preferred
• Experience with Linux, preferred
• Experience with one (1) or more of the following, preferred:
• Data Lake Medallion Architecture
• Batch and/or streaming data ingestion into a data lake
• AI Algorithms/Machine Learning
• Automation tools such as UiPath, Alteryx, etc.
• Computer Vision based AI technologies

Other Knowledge, Skills & Abilities
• Ability to work with a high degree of professionalism and autonomy
• Excellent verbal and written communication skills
• Solid organizational skills, especially the ability to meet project deadlines with a focus on details
• Ability to successfully multi-task while working independently or within a group environment
• Ability to work in a deadline-driven environment, and handle multiple projects simultaneously
• Ability to interact effectively with people at all organizational levels of the Firm
• Ability to effectively interact with a team of professionals and delegating work assignments, as needed
• Ability to build and maintain strong relationships with internal and client personnel
• Ability to encourage a team environment on engagements, and contribute to the professional development of assigned personnel

Keywords: Data Analytics, Business Intelligence, BI, Synapse, IoT, Machine Learning, Data Lake, Stream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine Learning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Python, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling, SQL, SSIS, SSAS, SSRS, PySpark, Microsoft Fabric, dbt, Linux, Terraform, Bicep, Data Ops, Purview, Git, Delta, Pandas, Spark SQL

Individual salaries that are offered to a candidate are determined after consideration of numerous factors including but not limited to the candidate’s qualifications, experience, skills, and geography.

California Range: $111,000 - $152,000

Colorado Range: $111,000 - $152,000

New York City/ Valhalla Range: $111,000 - $152,000

Washington Range: $111,000 - $152,000

About Us

BDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients’ needs. We currently serve more than 400 publicly traded domestic and international clients.
• Unparalleled partner-involvement
• Deep industry knowledge and participation
• Geographic coverage across the U.S.
• Cohesive global network
• Focused capabilities across disciplines

BDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world’s fifth largest accounting network.

BDO offers a competitive Total Rewards package that encompass so much more than – “traditional benefits”. Our wide range of rewards and our employees’ ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best & Brightest Companies to Work For and more.

Some Examples Of Our Total Rewards Offerings Include
• Competitive pay and eligibility for an annual performance bonus.
• A 401k plan plus an employer match
• Comprehensive, medical, dental, vision, FSA, and prescription insurance from day one
• Competitive Paid Time Off with daily accrual from day one of employment, plus paid holidays
• Paid Parental Leave
• Adoption Assistance
• Firm paid life insurance
• Wellness programs
• Additional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance

Above offerings may be subject to eligibility requirements.

Click here to find out more!

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status.

""BDO USA, P.A. is an EO employer M/F/Veteran/Disability""",New York,US,2023-12-19 11:02:00,http://www.bdo.com,Consulting
147,FULLTIME,Data Engineering Intern,https://www.linkedin.com/jobs/view/data-engineering-intern-at-david-yurman-3755350191,"About Us

David Yurman is a celebrated American jewelry company founded in New York by David Yurman, a sculptor, and his wife, Sybil, a painter and ceramicist. When the artists began collaborating, their goal was simply to make beautiful objects to wear. Led today by their son Evan, David Yurman creates timeless, yet contemporary collections for women and men defined by inspiration, innovation, consummate craftsmanship and cable – the brand’s artistic signature. David Yurman collections are available at 50 retail stores throughout the United States, Canada, Hong Kong and France and at over 300 locations worldwide, through their exclusive authorized fine jewelry and timepiece network of retailers.

Job Description

David Yurman Internship Program

The David Yurman Summer Internship Program is a paid, 10-week learning experience in which interns collaborate closely on company projects and initiatives in their respective professional areas of interest. Interns also work in teams throughout the summer to develop their capstone project, which is presented to our senior leadership team at the end of the summer.

At David Yurman, we are proud to foster a learning environment, and provide interns with a robust learning and development program. Through professional and social events with internal and external guest speakers, interns have the opportunity to learn more about jewelry, luxury retail as well as develop their communication, presentation and leadership development skills.

Students of diverse backgrounds are encouraged to apply, including, but not limited to race, ethnicity, gender expression, LGBTQ+, military status, and people with disabilities.

Dates: June 3rd, 2024- August 9th 2024

Diversity, Equity & Inclusion at David Yurman

As a company founded by artists, David Yurman champions self-expression in everything we do. We are committed to fostering a culture of openness and creative collaboration within our entire community, and we cherish the diversity of our employees’ backgrounds and perspectives. We will always advocate for equity and inclusion for all.

Title- Data Engineering & Analytics Intern

Reports to- Technology Lead Data Engineering

Overview

David Yurman is looking for a Data Engineering & Analytics Intern to help support the Data Management & Engineering Team. The selected candidate should have outstanding interpersonal skills, strong organizational skills, and a collaborative approach.

The Data Management & Engineering (DME) team at David Yurman (DY) is responsible to design & implement state of the art data management solutions. We are looking for a Data Engineering Intern to work side by side with the Data Engineers and participate in developing data integration solutions to support DY’s business needs.

What You’ll Do
• Leverage your knowledge of databases to query data and provide analysis / insights as per the business needs.
• Identify patterns and develop reactionary and predictive models to address data needs.
• Designing and building efficient data pipelines for data ingress from various sources to Snowflake Data Warehouse.
• Leverage the technology stack ro manage and enhance data pipelines currently in production.
• Drive identification and resolution of issues leveraging technical expertise and product knowledge.

Qualifications
• Experience with programming languages – SQL, Python , Scala.
• Experience working within AWS and AWS toolset e.g. irflow, Glue, Lambda.
• Familiarity with data ops including code/test/deploy cycle.
• Experience with at least one ETL tool & end-to-end ETL/ELT process a plus such as DBT
• Ability to interpret business needs into multiple analytics solutions

Education

Must be currently enrolled in undergraduate studies in a related field with a 3.0 overall GPA minimum
• M.S. in Computer Science or Data Science

Work location

New York, NY (Hybrid)

The company offers its interns competitive compensation and perks:
• The estimated pay range for this role is $21/hour
• Weekly learning & social events
• Summer Fridays

David Yurman is an Equal Employment Opportunity employer and provides equal opportunities to all employees and applicants without regard to an individual’s age, race, creed, color, religion, national origin, sex (including pregnancy, sexual orientation, gender expression, military status, marital status, genetic predisposition, carrier status, disability, or membership in any other protected class under applicable law.

David Yurman is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.",New York,US,2023-12-19 14:41:00,http://www.davidyurman.com,Retail
148,FULLTIME,"Sr. Data Analyst, Residential Energy Operations",https://www.linkedin.com/jobs/view/sr-data-analyst-residential-energy-operations-at-tesla-3737833368,"What To Expect
Data is deeply embedded in the product, engineering, quality, and customer experience culture at Tesla. As a Senior Data Analyst, you will help to identify, distill, and resolve issues that affect customer experience, product/process throughput, and quality within the residential energy business. By using data and reporting metrics to identify potential problems, you will drive change across the organization by assisting teams with data-driven insights. An ideal candidate is skilled at data analytics, reporting, and data processing concepts and is naturally motivated to seek out and fix problems in a methodical way.

What You'll Do
• Define and own “source of truth” metrics for executive reporting for use in assessing operational performance and quality
• Interface with business leaders to receive and distill requirements – allowing them to make confident and effective decisions via thorough analytical support and reporting
• Create and maintain ETLs – identify data sources, write custom SQL queries, validate data against source applications, and make modifications according to new requirements
• Coordinate with data engineering teams to establish data pipelines and verify data integrity
• Create and maintain business-critical reporting suites using data visualization tools
• Automate repetitive tasks with Python and SQL
• Write clean, tested code that can be maintained and extended upon by other analysts
• Work with quality and process improvement teams to provide key analytical support in identifying process and software improvements
• Maintain documentation and support aligned business units and their core applications
• Keep up to date with relevant technologies and frameworks for identifying trends and crafting new ways of looking at data
• Ensure safe and secure data handling practices by partnering with key data protection, privacy, and information security leaders

What You'll Bring
• Bachelor’s Degree in Engineering, Mathematics, Computer Science, or equivalent
• 4+ years of experience in business analytics or data management experience
• Expert SQL user – can write complex custom SQL queries using advanced aggregation functions and optimization techniques
• Proficient Python user – can write efficient ETLs to establish critical data pipelines
• Proficiency in using data visualization tools (i.e., Tableau, PowerBI, etc.)
• Firm grasp of database management and database performance concepts
• Demonstrated ability to provide insights and conclusions from large, dense datasets
• Excellent interpersonal communication and collaboration skills – and the ability to operate in a highly cross-functional environment
• Self-motivated, fast learner capable of first principle thinking in an ever-changing data landscape
• Detail-oriented with excellent organizational skills
• Master’s Degree in Data or Business Analytics is a plus
• 1 + years of experience with renewable energy generation systems

Benefits
Compensation and Benefits
Along with competitive pay, as a full-time Tesla employee, you are eligible for the following benefits at day 1 of hire:
• Aetna PPO and HSA plans > 2 medical plan options with $0 payroll deduction
• Family-building, fertility, adoption and surrogacy benefits
• Dental (including orthodontic coverage) and vision plans, both have options with a $0 paycheck contribution
• Company Paid (Health Savings Account) HSA Contribution when enrolled in the High Deductible Aetna medical plan with HSA
• Healthcare and Dependent Care Flexible Spending Accounts (FSA)
• LGBTQ+ care concierge services
• 401(k) with employer match, Employee Stock Purchase Plans, and other financial benefits
• Company paid Basic Life, AD&D, short-term and long-term disability insurance
• Employee Assistance Program
• Sick and Vacation time (Flex time for salary positions), and Paid Holidays
• Back-up childcare and parenting support resources
• Voluntary benefits to include: critical illness, hospital indemnity, accident insurance, theft & legal services, and pet insurance
• Weight Loss and Tobacco Cessation Programs
• Tesla Babies program
• Commuter benefits
• Employee discounts and perks program

Tesla",Austin,US,2023-12-19 12:38:00,http://www.tesla.com,Manufacturing
149,FULLTIME,Lead Data Engineer,https://www.linkedin.com/jobs/view/lead-data-engineer-at-burtch-works-3740458573,"Our client, a leader in the hospitality industry, is looking for a Lead Data Engineer to provide technical expertise and leadership in delivering end to end data pipelines. This role will impact the teams advanced analytics capabilities and drive innovation and decision-making across the organization.

Responsibilities:
• Build and maintain real-time data pipelines
• Collaborate with the greater analytics organization to prepare data for modeling
• Lead a team of Data Engineers and delegate tasks
• Architect, implement, and maintain data warehouse and database systems for efficient data storage, retrieval, and analysis using Snowflake.
• Act as a subject matter expert on data-related projects and communicate effectively with non-technical stakeholders.

Qualifications:
• Bachelors degree in a STEM field preferred (Masters is a plus)
• 5+ Years experience in Data Engineering, 2+ years with leadership responsibilities a plus
• Experience working with Snowflake as well as ETL tools like Matillion or DBT
• Proven experience working with Cloud Architectures (Azure is a plus)
• Expertise with Python and SQL

Work Environment: Hybrid Tuesday-Thursday

Compensation: $130,000-$150,000

KeyWords: Matillion, DBT, Snowflake, Data Engineer, Azure, AWS, Cloud, SQL, Python, ETL",Chicago,US,2023-12-19 20:10:00,http://www.bdo.com,Consulting
150,FULLTIME,Data Engineer Technical Specialist,https://www.linkedin.com/jobs/view/data-engineer-technical-specialist-at-peraton-3728940783,"Peraton Overview

Peraton drives missions of consequence spanning the globe and extending to the farthest reaches of the galaxy. As the world's leading mission capability integrator and transformative enterprise IT provider, we deliver trusted and highly differentiated national security solutions and technologies that keep people safe and secure. Peraton serves as a valued partner to essential government agencies across the intelligence, space, cyber, defense, civilian, health, and state and local markets. Every day, our employees do the can't be done, solving the most daunting challenges facing our customers.

Responsibilities

Designs, develops, builds, analyzes, evaluates, and installs database management systems to include database modeling and design, relational database architecture, metadata, and repository creation and configuration management. Uses data mapping, data mining, and data transformational analysis tools to design and develop databases. Determines data storage and optimum storage requirements. Prepares system requirements, source analysis, process analyses, and design throughout the database implementation. Evaluates, sizes, and selects technology components, such as software, hardware, and networking capabilities, for database management systems and application databases. Writes and tunes SQL queries for performance and scalability. Implements comprehensive backup and database replication solutions. Manipulates data and data flows for existing and new systems performing ETL, analytical support, and maintenance of critical data. Provides support in the areas of data extraction, transformation and load (ETL), data mapping, analytical support, operational support, database support, and maintenance support of data and associated systems. Research, design, develop, or modify enterprise-wide systems or application software-researches emerging technologies to determine their impact on application execution. Troubleshoot complex problems and provide support for the ETL process. Prepare reports on analyses, findings, and project progress.

Qualifications
• Master's Degree in Computer Science, Information Systems, Engineering, or another related discipline, and 3+ years of relevant experience, OR
• Bachelor's Degree in Computer Science, Information Systems, Engineering, or another related discipline, and 5+ years of relevant experience
• In-depth experience conducting data analysis and parsing
• Possesses extensive knowledge of relational databases and non-relational data stores, including Relational Database Management Systems (RDBMS) and large-scale distributed systems (e.g., Hadoop)
• Maintains an ability to conduct investigations and tests of considerable complexity
• Possesses extensive experience in developing complex data flows or making significant enhancements to existing pipelines
• Experience building and maintaining data flows in NiFi or Pentaho
• Experience with the following languages: Java/J2EE, C, C++, SQL, XML, XQuery, XPath, Ruby on Rails, HTML/XHTML, CSS, Python, Shell Scripting, JSON
• Possesses in-depth knowledge of server operating systems; Windows, Linux, Distributed Computing, Blade Centers, and cloud infrastructure
• Must have strong problem-solving skills and the ability to comprehend database methodologies
• Possesses excellent interpersonal, organizational, writing, communications; has strong analytical, critical thinking, and problem-solving, including briefing, and team-building skills

Preferred Qualifications:
• IBM Certified Solution Developer or equivalent
• Certified Data Management Professional - Data Management (CDP-DM)
• Oracle Certified Associate or Oracle9i Database Administrator (OCA)
• Strong understanding and familiarity with Cloud technologies, resources, and tools

Clearance: Secret

Target Salary Range

$146,000 - $234,000. This represents the typical salary range for this position based on experience and other factors.

SCA / Union / Intern Rate or Range

EEO

An Equal Opportunity Employer including Disability/Veteran.

Our Values

Benefits

At Peraton, our benefits are designed to help keep you at your best beyond the work you do with us daily. We're fully committed to the growth of our employees. From fully comprehensive medical plans to tuition reimbursement, tuition assistance, and fertility treatment, we are there to support you all the way.
• Paid Time-Off and Holidays
• Retirement
• Life & Disability Insurance
• Career Development
• Tuition Assistance and Student Loan Financing
• Paid Parental Leave
• Additional Benefits
• Medical, Dental, & Vision Care",London,US,2023-12-19 13:16:00,http://www.peraton.com,Consulting
151,FULLTIME,Cloud Data Engineer,https://www.linkedin.com/jobs/view/cloud-data-engineer-at-talener-3748836564,"Our client is a health-tec firm that provides a platform for claims management and an online pharmacy. They are looking to hire a Cloud Data Enigneer/Architect that is strong with Azure. You will play a critical role in designing, implementing, and maintaining data solutions on Microsoft Azure. You will be responsible for developing robust, scalable, and high-performance data pipelines, databases, and analytics.

Title: Cloud Data Engineer

Location: Melville, NY

Required Skills And Responsibilities
• 5+ years of experience as a Cloud Data Engineer or Architect
• Experience in designing, implementing, and managing data solutions using Azure SQL.
• Proficiency in SQL, T-SQL, and database design principles.
• Experience with ETL tools and data integration techniques
• Data Architecture: Collaborate with cross-functional teams to design and implement Azure SQL-based data architectures that meet business and technical requirements.
• Data Ingestion: Develop and maintain data pipelines for ingesting data from various sources into Azure SQL databases.
• Data Transformation: Implement data transformation processes, ensuring data quality, consistency, and accuracy.
• Database Management: Manage, optimize, and maintain Azure SQL databases to ensure high availability, performance, and security.
• Performance Tuning: Identify and resolve performance bottlenecks and optimize database queries for efficient data retrieval.
• Monitoring and Troubleshooting: Monitor data systems, perform diagnostics, and address issues in a timely manner. Set up alerts and proactive monitoring.

Nice To Have Skills
• Azure certifications (e.g., Azure Data Engineer, Azure SQL Database) are a plus.
• Familiarity with data modeling, data governance, and data security.

Compensation
• $120,000-150,000
• Annual bonus

For additional information, please reach out to Jed Pillion at jpillion@talener.com",London,US,2023-12-19 13:06:00,https://talener.com,Consulting
152,FULLTIME,Senior Cloud Data Engineer,https://www.linkedin.com/jobs/view/senior-cloud-data-engineer-at-bdo-usa-3765469446,"Job Description

Job Summary:

This position will work with cutting edge technology, deliver high quality solutions across various industries, and oversee team(s) on engagements that range in size and scope. This position will receive continuous career development opportunities, given the size and potential of client engagements. This role will perform hands-on delivery of data analytics projects, contributing to the development and unit testing of solutions.

Job Duties
• Designs and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS
• Listens to client needs to align solution with business requirements and delivery schedule
• Creates written functional and technical designs
• Participates in project status and stand meetings, and assists with providing aggregated project status for project and program managers
• Assists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions
• Writes code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles
• Delivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency)
• Assists with implementation of data governance programs and best practices
• Performs the cleaning and transforming of data from source systems into analytics models
• Implements models to support data visualizations and integrations
• Assists with implementing DevOps, DataOps and MLOps methodologies on projects
• Writes custom integration logic in applicable programming languages
• Assists project managers with work breakdown structure creation, project estimation, resource staffing, workload planning and adjustments throughout the project lifecycle
• Assists clients with licensing, security, and cost estimation of solutions
• Performs code reviews to ensure adherence to standards
• Works directly with clients and team members to establish secure data analytics platforms and infrastructure
• Contributes to successful deployments of developed solutions and integration of DevOps tools
• Maintains a broad and current understanding of data analytics and business intelligence strategies, cloud platforms, methodologies, and tools
• Builds client relationships during project execution, effectively becoming a trusted advisor of the client
• Participates in support activities for existing software solutions
• Other duties as assigned

Supervisory Responsibilities
• Supervises the day-to-day workload of Associates on assigned engagements to ensure that timelines and deliverables are met, and reviews work product

Education

Qualifications, Knowledge, Skills and Abilities:
• High School Diploma or GED equivalent, required
• Bachelor’s degree, preferred; focus in Information Systems, Data Science or Computer Science, preferred

Experience
• Five (5) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required
• One (1) or more years of experience technically leading development projects, preferred
• One (1) or more years of consulting experience or implementation of cloud-based data analytics solutions, preferred

Software
• Strong SQL skills including Data Definition Language (DDL), Data Manipulation Language (DML), views, functions, stored procedures, or performance tuning, required
• Experience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema Construction, required
• Hands on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, preferred
• Experience with one (1) or more of the following computer languages, preferred:
• C#
• Python
• Java
• Scala
• Experience with tabular modeling within Microsoft Fabric, Power BI, or Azure Analysis Services, preferred
• Experience with Git and DevOps deployment technologies, preferred
• Experience with Linux, preferred
• Experience with one (1) or more of the following, preferred:
• Data Lake Medallion Architecture
• Batch and/or streaming data ingestion into a data lake
• AI Algorithms/Machine Learning
• Automation tools such as UiPath, Alteryx, etc.
• Computer Vision based AI technologies

Other Knowledge, Skills & Abilities
• Ability to work with a high degree of professionalism and autonomy
• Excellent verbal and written communication skills
• Solid organizational skills, especially the ability to meet project deadlines with a focus on details
• Ability to successfully multi-task while working independently or within a group environment
• Ability to work in a deadline-driven environment, and handle multiple projects simultaneously
• Ability to interact effectively with people at all organizational levels of the Firm
• Ability to effectively interact with a team of professionals and delegating work assignments, as needed
• Ability to build and maintain strong relationships with internal and client personnel
• Ability to encourage a team environment on engagements, and contribute to the professional development of assigned personnel

Keywords: Data Analytics, Business Intelligence, BI, Synapse, IoT, Machine Learning, Data Lake, Stream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine Learning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Python, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling, SQL, SSIS, SSAS, SSRS, PySpark, Microsoft Fabric, dbt, Linux, Terraform, Bicep, Data Ops, Purview, Git, Delta, Pandas, Spark SQL

Individual salaries that are offered to a candidate are determined after consideration of numerous factors including but not limited to the candidate’s qualifications, experience, skills, and geography.

California Range: $111,000 - $152,000

Colorado Range: $111,000 - $152,000

New York City/ Valhalla Range: $111,000 - $152,000

Washington Range: $111,000 - $152,000

About Us

BDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients’ needs. We currently serve more than 400 publicly traded domestic and international clients.
• Unparalleled partner-involvement
• Deep industry knowledge and participation
• Geographic coverage across the U.S.
• Cohesive global network
• Focused capabilities across disciplines

BDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world’s fifth largest accounting network.

BDO offers a competitive Total Rewards package that encompass so much more than – “traditional benefits”. Our wide range of rewards and our employees’ ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best & Brightest Companies to Work For and more.

Some Examples Of Our Total Rewards Offerings Include
• Competitive pay and eligibility for an annual performance bonus.
• A 401k plan plus an employer match
• Comprehensive, medical, dental, vision, FSA, and prescription insurance from day one
• Competitive Paid Time Off with daily accrual from day one of employment, plus paid holidays
• Paid Parental Leave
• Adoption Assistance
• Firm paid life insurance
• Wellness programs
• Additional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance

Above offerings may be subject to eligibility requirements.

Click here to find out more!

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status.

""BDO USA, P.A. is an EO employer M/F/Veteran/Disability""",Costa Mesa,US,2023-12-19 11:16:00,http://www.bdo.com,Consulting
153,FULLTIME,Lead GCP Data Engineer,https://www.linkedin.com/jobs/view/lead-gcp-data-engineer-at-new-york-technology-partners-3783664165,"Job Title: GCP Lead Data Engineer

Location: Charlotte, NC - Onsite all 5 days in office

Position Type: Contract

Note: Required Minimum 10+ years’ experience.

Job Description:

Note : Very strong and deep knowledge of GCP with Airflow, Dataflow, Composer, Big Query.

Required Past Experience:

· Looking for a Lead Data Engineer for its Cloud and Big Data projects in the Data Warehousing, Data Analytics domain.

· Develop data-driven solutions with Cloud based technologies to meet evolving business needs. Deliver impactful, scalable, and highly performant Data solution to our customers based in US, UK, Canada and India based customers

· Provide technical design and develop Extract/Transform/Load (ETL) applications that interface with Client’s customer applications.

· Lead and implement data driven solutions and collaborate with larger development teams

· Lead and Develop Test Strategy, Test Plan, Test Cases to test the cloud based solutions

Core Responsibilities

· Drive Analysis to understand and meet all technical specifications and business requirements according to the established designs.

· Work extensively to develop Test Strategy, Test Plan, Test Cases to test the cloud based solutions

· Analyze Issues identified during Testing phase, propose solutions to fix the issues.

· Provide senior-level technical consulting to peer data engineers during design, development and testing for highly complex and critical data projects.

· Work extensively within the Cloud ecosystem and migrate data from Teradata/Netezza/ similar on-Premise Big Data platforms to Cloud based platforms like Big Query, SQL

Requirements

· Bachelor's degree in computer science, or related field

· Approx 8+ years of experience with a proven experience in data platform and big data engineering

· Hands-on Experience in SQL is mandatory. Quickly learning skills to adapt GCP cloud native SQL (Bigquery).

· Hands-on experience in Python is mandatory. Experience in using a Jupyter notebook is a plus.

· Hands on and deep experience working with Google Data Products (e.g. BigQuery, Dataflow, Cloud Composer, GCS etc.).

· Willingness to continuously learn & share learnings with others

· Capability to collaborate with stakeholders and project leaders to understand requirements, deliverables, and set expectations on tasks that you will be responsible for

· Ability to work in a fast-paced, rapidly changing environment

· Ability to work with business stakeholders and IT team to understand the requirements and quickly translate them into workable solutions using Python and SQL (Bigquery)

· Experience working in an agile and collaborative team environment

· Excellent written and verbal communication, presentation and professional speaking skills

· Proven problem-solving skills and attention to detail with a commitment to excellence and high standards.

If you believe you are qualified for this position and are currently in the job market or interested in making a change, please email me the resume along with contact details on nishant@nytp.com or give me a call at 201-484-0331.",Charlotte,US,2023-12-19 14:07:00,http://www.bdo.com,Consulting
154,FULLTIME,Vibration Test & Data Analysis Engineer,https://www.linkedin.com/jobs/view/vibration-test-data-analysis-engineer-at-tesla-3737828736,"What To Expect
This position will work as a member of Tesla’s reliability and test team to develop and execute vibration and durability validation tasks for Tesla products.

What You'll Do
• Process public roads, proving ground durability data and develop accelerated random vibration profiles for MAST/ED shakers
• Develop constant amplitude durability test profiles based on raw data collected from proving ground or field data
• Conduct vibration testing on various vehicle sub-systems on electrodynamic shaker tables
• Development, improvement of vibration durability methodologies (simulation and testing)
• Do hands-on test setup (mounting unit on and off the shaker table) and instrumentation (accelerometers etc.)
• Design test fixtures in CATIA for mounting sub-systems on electrodynamic and other shaker tables
• Conduct part inspections, root cause and report failures
• Post process test data and make test reports
• Be involved with general test equipment maintenance and lab expansions
• Work in close collaboration with other technicians, instrumentation and design teams
• Maintain a clean and organized work environment

What You'll Bring
• BS and/or MS degree in mechanical, automotive or mechatronics engineering or equivalent
• Strong mechanical engineering, vibration, and durability (damage theory) fundamentals
• 1+ years of experience with automotive systems or competitive projects like Formula SAE etc.
• Data processing and analysis using nCode Glyphworks, MATLAB, Python etc.
• Well versed with the instrumentation, usage, and data consumption from accelerometers, strain gages, load transducers and other road load data acquisition sensors
• Experience with modal testing
• Experience with 3D CAD software for fixture design (CATIA or 3D Experience preferred)
• Able to work well under pressure while managing competing demands and tight deadlines
• Excellent written & verbal communication skills
• Strong organization skills with meticulous attention to detail

Benefits
Compensation and Benefits
Along with competitive pay, as a full-time Tesla employee, you are eligible for the following benefits at day 1 of hire:
• Aetna PPO and HSA plans > 2 medical plan options with $0 payroll deduction
• Family-building, fertility, adoption and surrogacy benefits
• Dental (including orthodontic coverage) and vision plans, both have options with a $0 paycheck contribution
• Company Paid (Health Savings Account) HSA Contribution when enrolled in the High Deductible Aetna medical plan with HSA
• Healthcare and Dependent Care Flexible Spending Accounts (FSA)
• LGBTQ+ care concierge services
• 401(k) with employer match, Employee Stock Purchase Plans, and other financial benefits
• Company paid Basic Life, AD&D, short-term and long-term disability insurance
• Employee Assistance Program
• Sick and Vacation time (Flex time for salary positions), and Paid Holidays
• Back-up childcare and parenting support resources
• Voluntary benefits to include: critical illness, hospital indemnity, accident insurance, theft & legal services, and pet insurance
• Weight Loss and Tobacco Cessation Programs
• Tesla Babies program
• Commuter benefits
• Employee discounts and perks program

Expected Compensation

$80,000 - $300,000/annual salary + cash and stock awards + benefits

Pay offered may vary depending on multiple individualized factors, including market location, job-related knowledge, skills, and experience. The total compensation package for this position may also include other elements dependent on the position offered. Details of participation in these benefit plans will be provided if an employee receives an offer of employment.

Tesla",Fremont,US,2023-12-19 11:18:00,http://www.tesla.com,Manufacturing
155,FULLTIME,Senior Cloud Data Engineer,https://www.linkedin.com/jobs/view/senior-cloud-data-engineer-at-bdo-usa-3765472151,"Job Description

Job Summary:

This position will work with cutting edge technology, deliver high quality solutions across various industries, and oversee team(s) on engagements that range in size and scope. This position will receive continuous career development opportunities, given the size and potential of client engagements. This role will perform hands-on delivery of data analytics projects, contributing to the development and unit testing of solutions.

Job Duties
• Designs and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS
• Listens to client needs to align solution with business requirements and delivery schedule
• Creates written functional and technical designs
• Participates in project status and stand meetings, and assists with providing aggregated project status for project and program managers
• Assists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions
• Writes code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles
• Delivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency)
• Assists with implementation of data governance programs and best practices
• Performs the cleaning and transforming of data from source systems into analytics models
• Implements models to support data visualizations and integrations
• Assists with implementing DevOps, DataOps and MLOps methodologies on projects
• Writes custom integration logic in applicable programming languages
• Assists project managers with work breakdown structure creation, project estimation, resource staffing, workload planning and adjustments throughout the project lifecycle
• Assists clients with licensing, security, and cost estimation of solutions
• Performs code reviews to ensure adherence to standards
• Works directly with clients and team members to establish secure data analytics platforms and infrastructure
• Contributes to successful deployments of developed solutions and integration of DevOps tools
• Maintains a broad and current understanding of data analytics and business intelligence strategies, cloud platforms, methodologies, and tools
• Builds client relationships during project execution, effectively becoming a trusted advisor of the client
• Participates in support activities for existing software solutions
• Other duties as assigned

Supervisory Responsibilities
• Supervises the day-to-day workload of Associates on assigned engagements to ensure that timelines and deliverables are met, and reviews work product

Education

Qualifications, Knowledge, Skills and Abilities:
• High School Diploma or GED equivalent, required
• Bachelor’s degree, preferred; focus in Information Systems, Data Science or Computer Science, preferred

Experience
• Five (5) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required
• One (1) or more years of experience technically leading development projects, preferred
• One (1) or more years of consulting experience or implementation of cloud-based data analytics solutions, preferred

Software
• Strong SQL skills including Data Definition Language (DDL), Data Manipulation Language (DML), views, functions, stored procedures, or performance tuning, required
• Experience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema Construction, required
• Hands on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, preferred
• Experience with one (1) or more of the following computer languages, preferred:
• C#
• Python
• Java
• Scala
• Experience with tabular modeling within Microsoft Fabric, Power BI, or Azure Analysis Services, preferred
• Experience with Git and DevOps deployment technologies, preferred
• Experience with Linux, preferred
• Experience with one (1) or more of the following, preferred:
• Data Lake Medallion Architecture
• Batch and/or streaming data ingestion into a data lake
• AI Algorithms/Machine Learning
• Automation tools such as UiPath, Alteryx, etc.
• Computer Vision based AI technologies

Other Knowledge, Skills & Abilities
• Ability to work with a high degree of professionalism and autonomy
• Excellent verbal and written communication skills
• Solid organizational skills, especially the ability to meet project deadlines with a focus on details
• Ability to successfully multi-task while working independently or within a group environment
• Ability to work in a deadline-driven environment, and handle multiple projects simultaneously
• Ability to interact effectively with people at all organizational levels of the Firm
• Ability to effectively interact with a team of professionals and delegating work assignments, as needed
• Ability to build and maintain strong relationships with internal and client personnel
• Ability to encourage a team environment on engagements, and contribute to the professional development of assigned personnel

Keywords: Data Analytics, Business Intelligence, BI, Synapse, IoT, Machine Learning, Data Lake, Stream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine Learning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Python, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling, SQL, SSIS, SSAS, SSRS, PySpark, Microsoft Fabric, dbt, Linux, Terraform, Bicep, Data Ops, Purview, Git, Delta, Pandas, Spark SQL

Individual salaries that are offered to a candidate are determined after consideration of numerous factors including but not limited to the candidate’s qualifications, experience, skills, and geography.

California Range: $111,000 - $152,000

Colorado Range: $111,000 - $152,000

New York City/ Valhalla Range: $111,000 - $152,000

Washington Range: $111,000 - $152,000

About Us

BDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients’ needs. We currently serve more than 400 publicly traded domestic and international clients.
• Unparalleled partner-involvement
• Deep industry knowledge and participation
• Geographic coverage across the U.S.
• Cohesive global network
• Focused capabilities across disciplines

BDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world’s fifth largest accounting network.

BDO offers a competitive Total Rewards package that encompass so much more than – “traditional benefits”. Our wide range of rewards and our employees’ ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best & Brightest Companies to Work For and more.

Some Examples Of Our Total Rewards Offerings Include
• Competitive pay and eligibility for an annual performance bonus.
• A 401k plan plus an employer match
• Comprehensive, medical, dental, vision, FSA, and prescription insurance from day one
• Competitive Paid Time Off with daily accrual from day one of employment, plus paid holidays
• Paid Parental Leave
• Adoption Assistance
• Firm paid life insurance
• Wellness programs
• Additional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance

Above offerings may be subject to eligibility requirements.

Click here to find out more!

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status.

""BDO USA, P.A. is an EO employer M/F/Veteran/Disability""",San Diego,US,2023-12-19 11:52:00,http://www.bdo.com,Consulting
156,FULLTIME,Senior Cloud Data Engineer,https://www.linkedin.com/jobs/view/senior-cloud-data-engineer-at-bdo-usa-3765470284,"Job Description

Job Summary:

This position will work with cutting edge technology, deliver high quality solutions across various industries, and oversee team(s) on engagements that range in size and scope. This position will receive continuous career development opportunities, given the size and potential of client engagements. This role will perform hands-on delivery of data analytics projects, contributing to the development and unit testing of solutions.

Job Duties
• Designs and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS
• Listens to client needs to align solution with business requirements and delivery schedule
• Creates written functional and technical designs
• Participates in project status and stand meetings, and assists with providing aggregated project status for project and program managers
• Assists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions
• Writes code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles
• Delivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency)
• Assists with implementation of data governance programs and best practices
• Performs the cleaning and transforming of data from source systems into analytics models
• Implements models to support data visualizations and integrations
• Assists with implementing DevOps, DataOps and MLOps methodologies on projects
• Writes custom integration logic in applicable programming languages
• Assists project managers with work breakdown structure creation, project estimation, resource staffing, workload planning and adjustments throughout the project lifecycle
• Assists clients with licensing, security, and cost estimation of solutions
• Performs code reviews to ensure adherence to standards
• Works directly with clients and team members to establish secure data analytics platforms and infrastructure
• Contributes to successful deployments of developed solutions and integration of DevOps tools
• Maintains a broad and current understanding of data analytics and business intelligence strategies, cloud platforms, methodologies, and tools
• Builds client relationships during project execution, effectively becoming a trusted advisor of the client
• Participates in support activities for existing software solutions
• Other duties as assigned

Supervisory Responsibilities
• Supervises the day-to-day workload of Associates on assigned engagements to ensure that timelines and deliverables are met, and reviews work product

Education

Qualifications, Knowledge, Skills and Abilities:
• High School Diploma or GED equivalent, required
• Bachelor’s degree, preferred; focus in Information Systems, Data Science or Computer Science, preferred

Experience
• Five (5) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required
• One (1) or more years of experience technically leading development projects, preferred
• One (1) or more years of consulting experience or implementation of cloud-based data analytics solutions, preferred

Software
• Strong SQL skills including Data Definition Language (DDL), Data Manipulation Language (DML), views, functions, stored procedures, or performance tuning, required
• Experience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema Construction, required
• Hands on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, preferred
• Experience with one (1) or more of the following computer languages, preferred:
• C#
• Python
• Java
• Scala
• Experience with tabular modeling within Microsoft Fabric, Power BI, or Azure Analysis Services, preferred
• Experience with Git and DevOps deployment technologies, preferred
• Experience with Linux, preferred
• Experience with one (1) or more of the following, preferred:
• Data Lake Medallion Architecture
• Batch and/or streaming data ingestion into a data lake
• AI Algorithms/Machine Learning
• Automation tools such as UiPath, Alteryx, etc.
• Computer Vision based AI technologies

Other Knowledge, Skills & Abilities
• Ability to work with a high degree of professionalism and autonomy
• Excellent verbal and written communication skills
• Solid organizational skills, especially the ability to meet project deadlines with a focus on details
• Ability to successfully multi-task while working independently or within a group environment
• Ability to work in a deadline-driven environment, and handle multiple projects simultaneously
• Ability to interact effectively with people at all organizational levels of the Firm
• Ability to effectively interact with a team of professionals and delegating work assignments, as needed
• Ability to build and maintain strong relationships with internal and client personnel
• Ability to encourage a team environment on engagements, and contribute to the professional development of assigned personnel

Keywords: Data Analytics, Business Intelligence, BI, Synapse, IoT, Machine Learning, Data Lake, Stream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine Learning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Python, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling, SQL, SSIS, SSAS, SSRS, PySpark, Microsoft Fabric, dbt, Linux, Terraform, Bicep, Data Ops, Purview, Git, Delta, Pandas, Spark SQL

Individual salaries that are offered to a candidate are determined after consideration of numerous factors including but not limited to the candidate’s qualifications, experience, skills, and geography.

California Range: $111,000 - $152,000

Colorado Range: $111,000 - $152,000

New York City/ Valhalla Range: $111,000 - $152,000

Washington Range: $111,000 - $152,000

About Us

BDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients’ needs. We currently serve more than 400 publicly traded domestic and international clients.
• Unparalleled partner-involvement
• Deep industry knowledge and participation
• Geographic coverage across the U.S.
• Cohesive global network
• Focused capabilities across disciplines

BDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world’s fifth largest accounting network.

BDO offers a competitive Total Rewards package that encompass so much more than – “traditional benefits”. Our wide range of rewards and our employees’ ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best & Brightest Companies to Work For and more.

Some Examples Of Our Total Rewards Offerings Include
• Competitive pay and eligibility for an annual performance bonus.
• A 401k plan plus an employer match
• Comprehensive, medical, dental, vision, FSA, and prescription insurance from day one
• Competitive Paid Time Off with daily accrual from day one of employment, plus paid holidays
• Paid Parental Leave
• Adoption Assistance
• Firm paid life insurance
• Wellness programs
• Additional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance

Above offerings may be subject to eligibility requirements.

Click here to find out more!

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status.

""BDO USA, P.A. is an EO employer M/F/Veteran/Disability""",Los Angeles,US,2023-12-19 12:15:00,http://www.bdo.com,Consulting
157,FULLTIME,Senior Cloud Data Engineer,https://www.linkedin.com/jobs/view/senior-cloud-data-engineer-at-bdo-usa-3765471241,"Job Description

Job Summary:

This position will work with cutting edge technology, deliver high quality solutions across various industries, and oversee team(s) on engagements that range in size and scope. This position will receive continuous career development opportunities, given the size and potential of client engagements. This role will perform hands-on delivery of data analytics projects, contributing to the development and unit testing of solutions.

Job Duties
• Designs and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS
• Listens to client needs to align solution with business requirements and delivery schedule
• Creates written functional and technical designs
• Participates in project status and stand meetings, and assists with providing aggregated project status for project and program managers
• Assists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions
• Writes code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles
• Delivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency)
• Assists with implementation of data governance programs and best practices
• Performs the cleaning and transforming of data from source systems into analytics models
• Implements models to support data visualizations and integrations
• Assists with implementing DevOps, DataOps and MLOps methodologies on projects
• Writes custom integration logic in applicable programming languages
• Assists project managers with work breakdown structure creation, project estimation, resource staffing, workload planning and adjustments throughout the project lifecycle
• Assists clients with licensing, security, and cost estimation of solutions
• Performs code reviews to ensure adherence to standards
• Works directly with clients and team members to establish secure data analytics platforms and infrastructure
• Contributes to successful deployments of developed solutions and integration of DevOps tools
• Maintains a broad and current understanding of data analytics and business intelligence strategies, cloud platforms, methodologies, and tools
• Builds client relationships during project execution, effectively becoming a trusted advisor of the client
• Participates in support activities for existing software solutions
• Other duties as assigned

Supervisory Responsibilities
• Supervises the day-to-day workload of Associates on assigned engagements to ensure that timelines and deliverables are met, and reviews work product

Education

Qualifications, Knowledge, Skills and Abilities:
• High School Diploma or GED equivalent, required
• Bachelor’s degree, preferred; focus in Information Systems, Data Science or Computer Science, preferred

Experience
• Five (5) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required
• One (1) or more years of experience technically leading development projects, preferred
• One (1) or more years of consulting experience or implementation of cloud-based data analytics solutions, preferred

Software
• Strong SQL skills including Data Definition Language (DDL), Data Manipulation Language (DML), views, functions, stored procedures, or performance tuning, required
• Experience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema Construction, required
• Hands on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, preferred
• Experience with one (1) or more of the following computer languages, preferred:
• C#
• Python
• Java
• Scala
• Experience with tabular modeling within Microsoft Fabric, Power BI, or Azure Analysis Services, preferred
• Experience with Git and DevOps deployment technologies, preferred
• Experience with Linux, preferred
• Experience with one (1) or more of the following, preferred:
• Data Lake Medallion Architecture
• Batch and/or streaming data ingestion into a data lake
• AI Algorithms/Machine Learning
• Automation tools such as UiPath, Alteryx, etc.
• Computer Vision based AI technologies

Other Knowledge, Skills & Abilities
• Ability to work with a high degree of professionalism and autonomy
• Excellent verbal and written communication skills
• Solid organizational skills, especially the ability to meet project deadlines with a focus on details
• Ability to successfully multi-task while working independently or within a group environment
• Ability to work in a deadline-driven environment, and handle multiple projects simultaneously
• Ability to interact effectively with people at all organizational levels of the Firm
• Ability to effectively interact with a team of professionals and delegating work assignments, as needed
• Ability to build and maintain strong relationships with internal and client personnel
• Ability to encourage a team environment on engagements, and contribute to the professional development of assigned personnel

Keywords: Data Analytics, Business Intelligence, BI, Synapse, IoT, Machine Learning, Data Lake, Stream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine Learning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Python, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling, SQL, SSIS, SSAS, SSRS, PySpark, Microsoft Fabric, dbt, Linux, Terraform, Bicep, Data Ops, Purview, Git, Delta, Pandas, Spark SQL

Individual salaries that are offered to a candidate are determined after consideration of numerous factors including but not limited to the candidate’s qualifications, experience, skills, and geography.

California Range: $111,000 - $152,000

Colorado Range: $111,000 - $152,000

New York City/ Valhalla Range: $111,000 - $152,000

Washington Range: $111,000 - $152,000

About Us

BDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients’ needs. We currently serve more than 400 publicly traded domestic and international clients.
• Unparalleled partner-involvement
• Deep industry knowledge and participation
• Geographic coverage across the U.S.
• Cohesive global network
• Focused capabilities across disciplines

BDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world’s fifth largest accounting network.

BDO offers a competitive Total Rewards package that encompass so much more than – “traditional benefits”. Our wide range of rewards and our employees’ ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best & Brightest Companies to Work For and more.

Some Examples Of Our Total Rewards Offerings Include
• Competitive pay and eligibility for an annual performance bonus.
• A 401k plan plus an employer match
• Comprehensive, medical, dental, vision, FSA, and prescription insurance from day one
• Competitive Paid Time Off with daily accrual from day one of employment, plus paid holidays
• Paid Parental Leave
• Adoption Assistance
• Firm paid life insurance
• Wellness programs
• Additional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance

Above offerings may be subject to eligibility requirements.

Click here to find out more!

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status.

""BDO USA, P.A. is an EO employer M/F/Veteran/Disability""",West Palm Beach,US,2023-12-19 11:29:00,http://www.bdo.com,Consulting
158,FULLTIME,Senior Cloud Data Engineer,https://www.linkedin.com/jobs/view/senior-cloud-data-engineer-at-bdo-usa-3765472147,"Job Description

Job Summary:

This position will work with cutting edge technology, deliver high quality solutions across various industries, and oversee team(s) on engagements that range in size and scope. This position will receive continuous career development opportunities, given the size and potential of client engagements. This role will perform hands-on delivery of data analytics projects, contributing to the development and unit testing of solutions.

Job Duties
• Designs and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS
• Listens to client needs to align solution with business requirements and delivery schedule
• Creates written functional and technical designs
• Participates in project status and stand meetings, and assists with providing aggregated project status for project and program managers
• Assists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions
• Writes code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles
• Delivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency)
• Assists with implementation of data governance programs and best practices
• Performs the cleaning and transforming of data from source systems into analytics models
• Implements models to support data visualizations and integrations
• Assists with implementing DevOps, DataOps and MLOps methodologies on projects
• Writes custom integration logic in applicable programming languages
• Assists project managers with work breakdown structure creation, project estimation, resource staffing, workload planning and adjustments throughout the project lifecycle
• Assists clients with licensing, security, and cost estimation of solutions
• Performs code reviews to ensure adherence to standards
• Works directly with clients and team members to establish secure data analytics platforms and infrastructure
• Contributes to successful deployments of developed solutions and integration of DevOps tools
• Maintains a broad and current understanding of data analytics and business intelligence strategies, cloud platforms, methodologies, and tools
• Builds client relationships during project execution, effectively becoming a trusted advisor of the client
• Participates in support activities for existing software solutions
• Other duties as assigned

Supervisory Responsibilities
• Supervises the day-to-day workload of Associates on assigned engagements to ensure that timelines and deliverables are met, and reviews work product

Education

Qualifications, Knowledge, Skills and Abilities:
• High School Diploma or GED equivalent, required
• Bachelor’s degree, preferred; focus in Information Systems, Data Science or Computer Science, preferred

Experience
• Five (5) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required
• One (1) or more years of experience technically leading development projects, preferred
• One (1) or more years of consulting experience or implementation of cloud-based data analytics solutions, preferred

Software
• Strong SQL skills including Data Definition Language (DDL), Data Manipulation Language (DML), views, functions, stored procedures, or performance tuning, required
• Experience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema Construction, required
• Hands on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, preferred
• Experience with one (1) or more of the following computer languages, preferred:
• C#
• Python
• Java
• Scala
• Experience with tabular modeling within Microsoft Fabric, Power BI, or Azure Analysis Services, preferred
• Experience with Git and DevOps deployment technologies, preferred
• Experience with Linux, preferred
• Experience with one (1) or more of the following, preferred:
• Data Lake Medallion Architecture
• Batch and/or streaming data ingestion into a data lake
• AI Algorithms/Machine Learning
• Automation tools such as UiPath, Alteryx, etc.
• Computer Vision based AI technologies

Other Knowledge, Skills & Abilities
• Ability to work with a high degree of professionalism and autonomy
• Excellent verbal and written communication skills
• Solid organizational skills, especially the ability to meet project deadlines with a focus on details
• Ability to successfully multi-task while working independently or within a group environment
• Ability to work in a deadline-driven environment, and handle multiple projects simultaneously
• Ability to interact effectively with people at all organizational levels of the Firm
• Ability to effectively interact with a team of professionals and delegating work assignments, as needed
• Ability to build and maintain strong relationships with internal and client personnel
• Ability to encourage a team environment on engagements, and contribute to the professional development of assigned personnel

Keywords: Data Analytics, Business Intelligence, BI, Synapse, IoT, Machine Learning, Data Lake, Stream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine Learning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Python, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling, SQL, SSIS, SSAS, SSRS, PySpark, Microsoft Fabric, dbt, Linux, Terraform, Bicep, Data Ops, Purview, Git, Delta, Pandas, Spark SQL

Individual salaries that are offered to a candidate are determined after consideration of numerous factors including but not limited to the candidate’s qualifications, experience, skills, and geography.

California Range: $111,000 - $152,000

Colorado Range: $111,000 - $152,000

New York City/ Valhalla Range: $111,000 - $152,000

Washington Range: $111,000 - $152,000

About Us

BDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients’ needs. We currently serve more than 400 publicly traded domestic and international clients.
• Unparalleled partner-involvement
• Deep industry knowledge and participation
• Geographic coverage across the U.S.
• Cohesive global network
• Focused capabilities across disciplines

BDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world’s fifth largest accounting network.

BDO offers a competitive Total Rewards package that encompass so much more than – “traditional benefits”. Our wide range of rewards and our employees’ ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best & Brightest Companies to Work For and more.

Some Examples Of Our Total Rewards Offerings Include
• Competitive pay and eligibility for an annual performance bonus.
• A 401k plan plus an employer match
• Comprehensive, medical, dental, vision, FSA, and prescription insurance from day one
• Competitive Paid Time Off with daily accrual from day one of employment, plus paid holidays
• Paid Parental Leave
• Adoption Assistance
• Firm paid life insurance
• Wellness programs
• Additional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance

Above offerings may be subject to eligibility requirements.

Click here to find out more!

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status.

""BDO USA, P.A. is an EO employer M/F/Veteran/Disability""",Philadelphia,US,2023-12-19 11:29:00,http://www.bdo.com,Consulting
159,FULLTIME,Senior Cloud Data Engineer,https://www.linkedin.com/jobs/view/senior-cloud-data-engineer-at-bdo-usa-3765472146,"Job Description

Job Summary:

This position will work with cutting edge technology, deliver high quality solutions across various industries, and oversee team(s) on engagements that range in size and scope. This position will receive continuous career development opportunities, given the size and potential of client engagements. This role will perform hands-on delivery of data analytics projects, contributing to the development and unit testing of solutions.

Job Duties
• Designs and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS
• Listens to client needs to align solution with business requirements and delivery schedule
• Creates written functional and technical designs
• Participates in project status and stand meetings, and assists with providing aggregated project status for project and program managers
• Assists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions
• Writes code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles
• Delivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency)
• Assists with implementation of data governance programs and best practices
• Performs the cleaning and transforming of data from source systems into analytics models
• Implements models to support data visualizations and integrations
• Assists with implementing DevOps, DataOps and MLOps methodologies on projects
• Writes custom integration logic in applicable programming languages
• Assists project managers with work breakdown structure creation, project estimation, resource staffing, workload planning and adjustments throughout the project lifecycle
• Assists clients with licensing, security, and cost estimation of solutions
• Performs code reviews to ensure adherence to standards
• Works directly with clients and team members to establish secure data analytics platforms and infrastructure
• Contributes to successful deployments of developed solutions and integration of DevOps tools
• Maintains a broad and current understanding of data analytics and business intelligence strategies, cloud platforms, methodologies, and tools
• Builds client relationships during project execution, effectively becoming a trusted advisor of the client
• Participates in support activities for existing software solutions
• Other duties as assigned

Supervisory Responsibilities
• Supervises the day-to-day workload of Associates on assigned engagements to ensure that timelines and deliverables are met, and reviews work product

Education

Qualifications, Knowledge, Skills and Abilities:
• High School Diploma or GED equivalent, required
• Bachelor’s degree, preferred; focus in Information Systems, Data Science or Computer Science, preferred

Experience
• Five (5) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required
• One (1) or more years of experience technically leading development projects, preferred
• One (1) or more years of consulting experience or implementation of cloud-based data analytics solutions, preferred

Software
• Strong SQL skills including Data Definition Language (DDL), Data Manipulation Language (DML), views, functions, stored procedures, or performance tuning, required
• Experience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema Construction, required
• Hands on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, preferred
• Experience with one (1) or more of the following computer languages, preferred:
• C#
• Python
• Java
• Scala
• Experience with tabular modeling within Microsoft Fabric, Power BI, or Azure Analysis Services, preferred
• Experience with Git and DevOps deployment technologies, preferred
• Experience with Linux, preferred
• Experience with one (1) or more of the following, preferred:
• Data Lake Medallion Architecture
• Batch and/or streaming data ingestion into a data lake
• AI Algorithms/Machine Learning
• Automation tools such as UiPath, Alteryx, etc.
• Computer Vision based AI technologies

Other Knowledge, Skills & Abilities
• Ability to work with a high degree of professionalism and autonomy
• Excellent verbal and written communication skills
• Solid organizational skills, especially the ability to meet project deadlines with a focus on details
• Ability to successfully multi-task while working independently or within a group environment
• Ability to work in a deadline-driven environment, and handle multiple projects simultaneously
• Ability to interact effectively with people at all organizational levels of the Firm
• Ability to effectively interact with a team of professionals and delegating work assignments, as needed
• Ability to build and maintain strong relationships with internal and client personnel
• Ability to encourage a team environment on engagements, and contribute to the professional development of assigned personnel

Keywords: Data Analytics, Business Intelligence, BI, Synapse, IoT, Machine Learning, Data Lake, Stream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine Learning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Python, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling, SQL, SSIS, SSAS, SSRS, PySpark, Microsoft Fabric, dbt, Linux, Terraform, Bicep, Data Ops, Purview, Git, Delta, Pandas, Spark SQL

Individual salaries that are offered to a candidate are determined after consideration of numerous factors including but not limited to the candidate’s qualifications, experience, skills, and geography.

California Range: $111,000 - $152,000

Colorado Range: $111,000 - $152,000

New York City/ Valhalla Range: $111,000 - $152,000

Washington Range: $111,000 - $152,000

About Us

BDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients’ needs. We currently serve more than 400 publicly traded domestic and international clients.
• Unparalleled partner-involvement
• Deep industry knowledge and participation
• Geographic coverage across the U.S.
• Cohesive global network
• Focused capabilities across disciplines

BDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world’s fifth largest accounting network.

BDO offers a competitive Total Rewards package that encompass so much more than – “traditional benefits”. Our wide range of rewards and our employees’ ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best & Brightest Companies to Work For and more.

Some Examples Of Our Total Rewards Offerings Include
• Competitive pay and eligibility for an annual performance bonus.
• A 401k plan plus an employer match
• Comprehensive, medical, dental, vision, FSA, and prescription insurance from day one
• Competitive Paid Time Off with daily accrual from day one of employment, plus paid holidays
• Paid Parental Leave
• Adoption Assistance
• Firm paid life insurance
• Wellness programs
• Additional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance

Above offerings may be subject to eligibility requirements.

Click here to find out more!

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status.

""BDO USA, P.A. is an EO employer M/F/Veteran/Disability""",Dallas,US,2023-12-19 11:11:00,http://www.bdo.com,Consulting
160,FULLTIME,Senior Cloud Data Engineer,https://www.linkedin.com/jobs/view/senior-cloud-data-engineer-at-bdo-usa-3765470288,"Job Description

Job Summary:

This position will work with cutting edge technology, deliver high quality solutions across various industries, and oversee team(s) on engagements that range in size and scope. This position will receive continuous career development opportunities, given the size and potential of client engagements. This role will perform hands-on delivery of data analytics projects, contributing to the development and unit testing of solutions.

Job Duties
• Designs and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS
• Listens to client needs to align solution with business requirements and delivery schedule
• Creates written functional and technical designs
• Participates in project status and stand meetings, and assists with providing aggregated project status for project and program managers
• Assists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions
• Writes code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles
• Delivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency)
• Assists with implementation of data governance programs and best practices
• Performs the cleaning and transforming of data from source systems into analytics models
• Implements models to support data visualizations and integrations
• Assists with implementing DevOps, DataOps and MLOps methodologies on projects
• Writes custom integration logic in applicable programming languages
• Assists project managers with work breakdown structure creation, project estimation, resource staffing, workload planning and adjustments throughout the project lifecycle
• Assists clients with licensing, security, and cost estimation of solutions
• Performs code reviews to ensure adherence to standards
• Works directly with clients and team members to establish secure data analytics platforms and infrastructure
• Contributes to successful deployments of developed solutions and integration of DevOps tools
• Maintains a broad and current understanding of data analytics and business intelligence strategies, cloud platforms, methodologies, and tools
• Builds client relationships during project execution, effectively becoming a trusted advisor of the client
• Participates in support activities for existing software solutions
• Other duties as assigned

Supervisory Responsibilities
• Supervises the day-to-day workload of Associates on assigned engagements to ensure that timelines and deliverables are met, and reviews work product

Education

Qualifications, Knowledge, Skills and Abilities:
• High School Diploma or GED equivalent, required
• Bachelor’s degree, preferred; focus in Information Systems, Data Science or Computer Science, preferred

Experience
• Five (5) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required
• One (1) or more years of experience technically leading development projects, preferred
• One (1) or more years of consulting experience or implementation of cloud-based data analytics solutions, preferred

Software
• Strong SQL skills including Data Definition Language (DDL), Data Manipulation Language (DML), views, functions, stored procedures, or performance tuning, required
• Experience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema Construction, required
• Hands on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, preferred
• Experience with one (1) or more of the following computer languages, preferred:
• C#
• Python
• Java
• Scala
• Experience with tabular modeling within Microsoft Fabric, Power BI, or Azure Analysis Services, preferred
• Experience with Git and DevOps deployment technologies, preferred
• Experience with Linux, preferred
• Experience with one (1) or more of the following, preferred:
• Data Lake Medallion Architecture
• Batch and/or streaming data ingestion into a data lake
• AI Algorithms/Machine Learning
• Automation tools such as UiPath, Alteryx, etc.
• Computer Vision based AI technologies

Other Knowledge, Skills & Abilities
• Ability to work with a high degree of professionalism and autonomy
• Excellent verbal and written communication skills
• Solid organizational skills, especially the ability to meet project deadlines with a focus on details
• Ability to successfully multi-task while working independently or within a group environment
• Ability to work in a deadline-driven environment, and handle multiple projects simultaneously
• Ability to interact effectively with people at all organizational levels of the Firm
• Ability to effectively interact with a team of professionals and delegating work assignments, as needed
• Ability to build and maintain strong relationships with internal and client personnel
• Ability to encourage a team environment on engagements, and contribute to the professional development of assigned personnel

Keywords: Data Analytics, Business Intelligence, BI, Synapse, IoT, Machine Learning, Data Lake, Stream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine Learning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Python, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling, SQL, SSIS, SSAS, SSRS, PySpark, Microsoft Fabric, dbt, Linux, Terraform, Bicep, Data Ops, Purview, Git, Delta, Pandas, Spark SQL

Individual salaries that are offered to a candidate are determined after consideration of numerous factors including but not limited to the candidate’s qualifications, experience, skills, and geography.

California Range: $111,000 - $152,000

Colorado Range: $111,000 - $152,000

New York City/ Valhalla Range: $111,000 - $152,000

Washington Range: $111,000 - $152,000

About Us

BDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients’ needs. We currently serve more than 400 publicly traded domestic and international clients.
• Unparalleled partner-involvement
• Deep industry knowledge and participation
• Geographic coverage across the U.S.
• Cohesive global network
• Focused capabilities across disciplines

BDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world’s fifth largest accounting network.

BDO offers a competitive Total Rewards package that encompass so much more than – “traditional benefits”. Our wide range of rewards and our employees’ ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best & Brightest Companies to Work For and more.

Some Examples Of Our Total Rewards Offerings Include
• Competitive pay and eligibility for an annual performance bonus.
• A 401k plan plus an employer match
• Comprehensive, medical, dental, vision, FSA, and prescription insurance from day one
• Competitive Paid Time Off with daily accrual from day one of employment, plus paid holidays
• Paid Parental Leave
• Adoption Assistance
• Firm paid life insurance
• Wellness programs
• Additional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance

Above offerings may be subject to eligibility requirements.

Click here to find out more!

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status.

""BDO USA, P.A. is an EO employer M/F/Veteran/Disability""",Columbia,US,2023-12-19 12:23:00,http://www.bdo.com,Consulting
161,FULLTIME,Senior Cloud Data Engineer,https://www.linkedin.com/jobs/view/senior-cloud-data-engineer-at-bdo-usa-3765470283,"Job Description

Job Summary:

This position will work with cutting edge technology, deliver high quality solutions across various industries, and oversee team(s) on engagements that range in size and scope. This position will receive continuous career development opportunities, given the size and potential of client engagements. This role will perform hands-on delivery of data analytics projects, contributing to the development and unit testing of solutions.

Job Duties
• Designs and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS
• Listens to client needs to align solution with business requirements and delivery schedule
• Creates written functional and technical designs
• Participates in project status and stand meetings, and assists with providing aggregated project status for project and program managers
• Assists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions
• Writes code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles
• Delivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency)
• Assists with implementation of data governance programs and best practices
• Performs the cleaning and transforming of data from source systems into analytics models
• Implements models to support data visualizations and integrations
• Assists with implementing DevOps, DataOps and MLOps methodologies on projects
• Writes custom integration logic in applicable programming languages
• Assists project managers with work breakdown structure creation, project estimation, resource staffing, workload planning and adjustments throughout the project lifecycle
• Assists clients with licensing, security, and cost estimation of solutions
• Performs code reviews to ensure adherence to standards
• Works directly with clients and team members to establish secure data analytics platforms and infrastructure
• Contributes to successful deployments of developed solutions and integration of DevOps tools
• Maintains a broad and current understanding of data analytics and business intelligence strategies, cloud platforms, methodologies, and tools
• Builds client relationships during project execution, effectively becoming a trusted advisor of the client
• Participates in support activities for existing software solutions
• Other duties as assigned

Supervisory Responsibilities
• Supervises the day-to-day workload of Associates on assigned engagements to ensure that timelines and deliverables are met, and reviews work product

Education

Qualifications, Knowledge, Skills and Abilities:
• High School Diploma or GED equivalent, required
• Bachelor’s degree, preferred; focus in Information Systems, Data Science or Computer Science, preferred

Experience
• Five (5) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required
• One (1) or more years of experience technically leading development projects, preferred
• One (1) or more years of consulting experience or implementation of cloud-based data analytics solutions, preferred

Software
• Strong SQL skills including Data Definition Language (DDL), Data Manipulation Language (DML), views, functions, stored procedures, or performance tuning, required
• Experience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema Construction, required
• Hands on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, preferred
• Experience with one (1) or more of the following computer languages, preferred:
• C#
• Python
• Java
• Scala
• Experience with tabular modeling within Microsoft Fabric, Power BI, or Azure Analysis Services, preferred
• Experience with Git and DevOps deployment technologies, preferred
• Experience with Linux, preferred
• Experience with one (1) or more of the following, preferred:
• Data Lake Medallion Architecture
• Batch and/or streaming data ingestion into a data lake
• AI Algorithms/Machine Learning
• Automation tools such as UiPath, Alteryx, etc.
• Computer Vision based AI technologies

Other Knowledge, Skills & Abilities
• Ability to work with a high degree of professionalism and autonomy
• Excellent verbal and written communication skills
• Solid organizational skills, especially the ability to meet project deadlines with a focus on details
• Ability to successfully multi-task while working independently or within a group environment
• Ability to work in a deadline-driven environment, and handle multiple projects simultaneously
• Ability to interact effectively with people at all organizational levels of the Firm
• Ability to effectively interact with a team of professionals and delegating work assignments, as needed
• Ability to build and maintain strong relationships with internal and client personnel
• Ability to encourage a team environment on engagements, and contribute to the professional development of assigned personnel

Keywords: Data Analytics, Business Intelligence, BI, Synapse, IoT, Machine Learning, Data Lake, Stream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine Learning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Python, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling, SQL, SSIS, SSAS, SSRS, PySpark, Microsoft Fabric, dbt, Linux, Terraform, Bicep, Data Ops, Purview, Git, Delta, Pandas, Spark SQL

Individual salaries that are offered to a candidate are determined after consideration of numerous factors including but not limited to the candidate’s qualifications, experience, skills, and geography.

California Range: $111,000 - $152,000

Colorado Range: $111,000 - $152,000

New York City/ Valhalla Range: $111,000 - $152,000

Washington Range: $111,000 - $152,000

About Us

BDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients’ needs. We currently serve more than 400 publicly traded domestic and international clients.
• Unparalleled partner-involvement
• Deep industry knowledge and participation
• Geographic coverage across the U.S.
• Cohesive global network
• Focused capabilities across disciplines

BDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world’s fifth largest accounting network.

BDO offers a competitive Total Rewards package that encompass so much more than – “traditional benefits”. Our wide range of rewards and our employees’ ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best & Brightest Companies to Work For and more.

Some Examples Of Our Total Rewards Offerings Include
• Competitive pay and eligibility for an annual performance bonus.
• A 401k plan plus an employer match
• Comprehensive, medical, dental, vision, FSA, and prescription insurance from day one
• Competitive Paid Time Off with daily accrual from day one of employment, plus paid holidays
• Paid Parental Leave
• Adoption Assistance
• Firm paid life insurance
• Wellness programs
• Additional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance

Above offerings may be subject to eligibility requirements.

Click here to find out more!

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status.

""BDO USA, P.A. is an EO employer M/F/Veteran/Disability""",Grand Rapids,US,2023-12-19 12:28:00,http://www.bdo.com,Consulting
162,FULLTIME,Senior Cloud Data Engineer,https://www.linkedin.com/jobs/view/senior-cloud-data-engineer-at-bdo-usa-3765471247,"Job Description

Job Summary:

This position will work with cutting edge technology, deliver high quality solutions across various industries, and oversee team(s) on engagements that range in size and scope. This position will receive continuous career development opportunities, given the size and potential of client engagements. This role will perform hands-on delivery of data analytics projects, contributing to the development and unit testing of solutions.

Job Duties
• Designs and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS
• Listens to client needs to align solution with business requirements and delivery schedule
• Creates written functional and technical designs
• Participates in project status and stand meetings, and assists with providing aggregated project status for project and program managers
• Assists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions
• Writes code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles
• Delivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency)
• Assists with implementation of data governance programs and best practices
• Performs the cleaning and transforming of data from source systems into analytics models
• Implements models to support data visualizations and integrations
• Assists with implementing DevOps, DataOps and MLOps methodologies on projects
• Writes custom integration logic in applicable programming languages
• Assists project managers with work breakdown structure creation, project estimation, resource staffing, workload planning and adjustments throughout the project lifecycle
• Assists clients with licensing, security, and cost estimation of solutions
• Performs code reviews to ensure adherence to standards
• Works directly with clients and team members to establish secure data analytics platforms and infrastructure
• Contributes to successful deployments of developed solutions and integration of DevOps tools
• Maintains a broad and current understanding of data analytics and business intelligence strategies, cloud platforms, methodologies, and tools
• Builds client relationships during project execution, effectively becoming a trusted advisor of the client
• Participates in support activities for existing software solutions
• Other duties as assigned

Supervisory Responsibilities
• Supervises the day-to-day workload of Associates on assigned engagements to ensure that timelines and deliverables are met, and reviews work product

Education

Qualifications, Knowledge, Skills and Abilities:
• High School Diploma or GED equivalent, required
• Bachelor’s degree, preferred; focus in Information Systems, Data Science or Computer Science, preferred

Experience
• Five (5) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required
• One (1) or more years of experience technically leading development projects, preferred
• One (1) or more years of consulting experience or implementation of cloud-based data analytics solutions, preferred

Software
• Strong SQL skills including Data Definition Language (DDL), Data Manipulation Language (DML), views, functions, stored procedures, or performance tuning, required
• Experience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema Construction, required
• Hands on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, preferred
• Experience with one (1) or more of the following computer languages, preferred:
• C#
• Python
• Java
• Scala
• Experience with tabular modeling within Microsoft Fabric, Power BI, or Azure Analysis Services, preferred
• Experience with Git and DevOps deployment technologies, preferred
• Experience with Linux, preferred
• Experience with one (1) or more of the following, preferred:
• Data Lake Medallion Architecture
• Batch and/or streaming data ingestion into a data lake
• AI Algorithms/Machine Learning
• Automation tools such as UiPath, Alteryx, etc.
• Computer Vision based AI technologies

Other Knowledge, Skills & Abilities
• Ability to work with a high degree of professionalism and autonomy
• Excellent verbal and written communication skills
• Solid organizational skills, especially the ability to meet project deadlines with a focus on details
• Ability to successfully multi-task while working independently or within a group environment
• Ability to work in a deadline-driven environment, and handle multiple projects simultaneously
• Ability to interact effectively with people at all organizational levels of the Firm
• Ability to effectively interact with a team of professionals and delegating work assignments, as needed
• Ability to build and maintain strong relationships with internal and client personnel
• Ability to encourage a team environment on engagements, and contribute to the professional development of assigned personnel

Keywords: Data Analytics, Business Intelligence, BI, Synapse, IoT, Machine Learning, Data Lake, Stream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine Learning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Python, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling, SQL, SSIS, SSAS, SSRS, PySpark, Microsoft Fabric, dbt, Linux, Terraform, Bicep, Data Ops, Purview, Git, Delta, Pandas, Spark SQL

Individual salaries that are offered to a candidate are determined after consideration of numerous factors including but not limited to the candidate’s qualifications, experience, skills, and geography.

California Range: $111,000 - $152,000

Colorado Range: $111,000 - $152,000

New York City/ Valhalla Range: $111,000 - $152,000

Washington Range: $111,000 - $152,000

About Us

BDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients’ needs. We currently serve more than 400 publicly traded domestic and international clients.
• Unparalleled partner-involvement
• Deep industry knowledge and participation
• Geographic coverage across the U.S.
• Cohesive global network
• Focused capabilities across disciplines

BDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world’s fifth largest accounting network.

BDO offers a competitive Total Rewards package that encompass so much more than – “traditional benefits”. Our wide range of rewards and our employees’ ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best & Brightest Companies to Work For and more.

Some Examples Of Our Total Rewards Offerings Include
• Competitive pay and eligibility for an annual performance bonus.
• A 401k plan plus an employer match
• Comprehensive, medical, dental, vision, FSA, and prescription insurance from day one
• Competitive Paid Time Off with daily accrual from day one of employment, plus paid holidays
• Paid Parental Leave
• Adoption Assistance
• Firm paid life insurance
• Wellness programs
• Additional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance

Above offerings may be subject to eligibility requirements.

Click here to find out more!

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status.

""BDO USA, P.A. is an EO employer M/F/Veteran/Disability""",Las Vegas,US,2023-12-19 12:11:00,http://www.bdo.com,Consulting
163,FULLTIME,Senior Cloud Data Engineer,https://www.linkedin.com/jobs/view/senior-cloud-data-engineer-at-bdo-usa-3765473101,"Job Description

Job Summary:

This position will work with cutting edge technology, deliver high quality solutions across various industries, and oversee team(s) on engagements that range in size and scope. This position will receive continuous career development opportunities, given the size and potential of client engagements. This role will perform hands-on delivery of data analytics projects, contributing to the development and unit testing of solutions.

Job Duties
• Designs and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS
• Listens to client needs to align solution with business requirements and delivery schedule
• Creates written functional and technical designs
• Participates in project status and stand meetings, and assists with providing aggregated project status for project and program managers
• Assists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions
• Writes code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles
• Delivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency)
• Assists with implementation of data governance programs and best practices
• Performs the cleaning and transforming of data from source systems into analytics models
• Implements models to support data visualizations and integrations
• Assists with implementing DevOps, DataOps and MLOps methodologies on projects
• Writes custom integration logic in applicable programming languages
• Assists project managers with work breakdown structure creation, project estimation, resource staffing, workload planning and adjustments throughout the project lifecycle
• Assists clients with licensing, security, and cost estimation of solutions
• Performs code reviews to ensure adherence to standards
• Works directly with clients and team members to establish secure data analytics platforms and infrastructure
• Contributes to successful deployments of developed solutions and integration of DevOps tools
• Maintains a broad and current understanding of data analytics and business intelligence strategies, cloud platforms, methodologies, and tools
• Builds client relationships during project execution, effectively becoming a trusted advisor of the client
• Participates in support activities for existing software solutions
• Other duties as assigned

Supervisory Responsibilities
• Supervises the day-to-day workload of Associates on assigned engagements to ensure that timelines and deliverables are met, and reviews work product

Education

Qualifications, Knowledge, Skills and Abilities:
• High School Diploma or GED equivalent, required
• Bachelor’s degree, preferred; focus in Information Systems, Data Science or Computer Science, preferred

Experience
• Five (5) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required
• One (1) or more years of experience technically leading development projects, preferred
• One (1) or more years of consulting experience or implementation of cloud-based data analytics solutions, preferred

Software
• Strong SQL skills including Data Definition Language (DDL), Data Manipulation Language (DML), views, functions, stored procedures, or performance tuning, required
• Experience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema Construction, required
• Hands on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, preferred
• Experience with one (1) or more of the following computer languages, preferred:
• C#
• Python
• Java
• Scala
• Experience with tabular modeling within Microsoft Fabric, Power BI, or Azure Analysis Services, preferred
• Experience with Git and DevOps deployment technologies, preferred
• Experience with Linux, preferred
• Experience with one (1) or more of the following, preferred:
• Data Lake Medallion Architecture
• Batch and/or streaming data ingestion into a data lake
• AI Algorithms/Machine Learning
• Automation tools such as UiPath, Alteryx, etc.
• Computer Vision based AI technologies

Other Knowledge, Skills & Abilities
• Ability to work with a high degree of professionalism and autonomy
• Excellent verbal and written communication skills
• Solid organizational skills, especially the ability to meet project deadlines with a focus on details
• Ability to successfully multi-task while working independently or within a group environment
• Ability to work in a deadline-driven environment, and handle multiple projects simultaneously
• Ability to interact effectively with people at all organizational levels of the Firm
• Ability to effectively interact with a team of professionals and delegating work assignments, as needed
• Ability to build and maintain strong relationships with internal and client personnel
• Ability to encourage a team environment on engagements, and contribute to the professional development of assigned personnel

Keywords: Data Analytics, Business Intelligence, BI, Synapse, IoT, Machine Learning, Data Lake, Stream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine Learning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Python, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling, SQL, SSIS, SSAS, SSRS, PySpark, Microsoft Fabric, dbt, Linux, Terraform, Bicep, Data Ops, Purview, Git, Delta, Pandas, Spark SQL

Individual salaries that are offered to a candidate are determined after consideration of numerous factors including but not limited to the candidate’s qualifications, experience, skills, and geography.

California Range: $111,000 - $152,000

Colorado Range: $111,000 - $152,000

New York City/ Valhalla Range: $111,000 - $152,000

Washington Range: $111,000 - $152,000

About Us

BDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients’ needs. We currently serve more than 400 publicly traded domestic and international clients.
• Unparalleled partner-involvement
• Deep industry knowledge and participation
• Geographic coverage across the U.S.
• Cohesive global network
• Focused capabilities across disciplines

BDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world’s fifth largest accounting network.

BDO offers a competitive Total Rewards package that encompass so much more than – “traditional benefits”. Our wide range of rewards and our employees’ ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best & Brightest Companies to Work For and more.

Some Examples Of Our Total Rewards Offerings Include
• Competitive pay and eligibility for an annual performance bonus.
• A 401k plan plus an employer match
• Comprehensive, medical, dental, vision, FSA, and prescription insurance from day one
• Competitive Paid Time Off with daily accrual from day one of employment, plus paid holidays
• Paid Parental Leave
• Adoption Assistance
• Firm paid life insurance
• Wellness programs
• Additional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance

Above offerings may be subject to eligibility requirements.

Click here to find out more!

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status.

""BDO USA, P.A. is an EO employer M/F/Veteran/Disability""",Richmond,US,2023-12-19 10:42:00,http://www.bdo.com,Consulting
164,FULLTIME,Senior Cloud Data Engineer,https://www.linkedin.com/jobs/view/senior-cloud-data-engineer-at-bdo-usa-3765474001,"Job Description

Job Summary:

This position will work with cutting edge technology, deliver high quality solutions across various industries, and oversee team(s) on engagements that range in size and scope. This position will receive continuous career development opportunities, given the size and potential of client engagements. This role will perform hands-on delivery of data analytics projects, contributing to the development and unit testing of solutions.

Job Duties
• Designs and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS
• Listens to client needs to align solution with business requirements and delivery schedule
• Creates written functional and technical designs
• Participates in project status and stand meetings, and assists with providing aggregated project status for project and program managers
• Assists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions
• Writes code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles
• Delivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency)
• Assists with implementation of data governance programs and best practices
• Performs the cleaning and transforming of data from source systems into analytics models
• Implements models to support data visualizations and integrations
• Assists with implementing DevOps, DataOps and MLOps methodologies on projects
• Writes custom integration logic in applicable programming languages
• Assists project managers with work breakdown structure creation, project estimation, resource staffing, workload planning and adjustments throughout the project lifecycle
• Assists clients with licensing, security, and cost estimation of solutions
• Performs code reviews to ensure adherence to standards
• Works directly with clients and team members to establish secure data analytics platforms and infrastructure
• Contributes to successful deployments of developed solutions and integration of DevOps tools
• Maintains a broad and current understanding of data analytics and business intelligence strategies, cloud platforms, methodologies, and tools
• Builds client relationships during project execution, effectively becoming a trusted advisor of the client
• Participates in support activities for existing software solutions
• Other duties as assigned

Supervisory Responsibilities
• Supervises the day-to-day workload of Associates on assigned engagements to ensure that timelines and deliverables are met, and reviews work product

Education

Qualifications, Knowledge, Skills and Abilities:
• High School Diploma or GED equivalent, required
• Bachelor’s degree, preferred; focus in Information Systems, Data Science or Computer Science, preferred

Experience
• Five (5) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required
• One (1) or more years of experience technically leading development projects, preferred
• One (1) or more years of consulting experience or implementation of cloud-based data analytics solutions, preferred

Software
• Strong SQL skills including Data Definition Language (DDL), Data Manipulation Language (DML), views, functions, stored procedures, or performance tuning, required
• Experience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema Construction, required
• Hands on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, preferred
• Experience with one (1) or more of the following computer languages, preferred:
• C#
• Python
• Java
• Scala
• Experience with tabular modeling within Microsoft Fabric, Power BI, or Azure Analysis Services, preferred
• Experience with Git and DevOps deployment technologies, preferred
• Experience with Linux, preferred
• Experience with one (1) or more of the following, preferred:
• Data Lake Medallion Architecture
• Batch and/or streaming data ingestion into a data lake
• AI Algorithms/Machine Learning
• Automation tools such as UiPath, Alteryx, etc.
• Computer Vision based AI technologies

Other Knowledge, Skills & Abilities
• Ability to work with a high degree of professionalism and autonomy
• Excellent verbal and written communication skills
• Solid organizational skills, especially the ability to meet project deadlines with a focus on details
• Ability to successfully multi-task while working independently or within a group environment
• Ability to work in a deadline-driven environment, and handle multiple projects simultaneously
• Ability to interact effectively with people at all organizational levels of the Firm
• Ability to effectively interact with a team of professionals and delegating work assignments, as needed
• Ability to build and maintain strong relationships with internal and client personnel
• Ability to encourage a team environment on engagements, and contribute to the professional development of assigned personnel

Keywords: Data Analytics, Business Intelligence, BI, Synapse, IoT, Machine Learning, Data Lake, Stream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine Learning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Python, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling, SQL, SSIS, SSAS, SSRS, PySpark, Microsoft Fabric, dbt, Linux, Terraform, Bicep, Data Ops, Purview, Git, Delta, Pandas, Spark SQL

Individual salaries that are offered to a candidate are determined after consideration of numerous factors including but not limited to the candidate’s qualifications, experience, skills, and geography.

California Range: $111,000 - $152,000

Colorado Range: $111,000 - $152,000

New York City/ Valhalla Range: $111,000 - $152,000

Washington Range: $111,000 - $152,000

About Us

BDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients’ needs. We currently serve more than 400 publicly traded domestic and international clients.
• Unparalleled partner-involvement
• Deep industry knowledge and participation
• Geographic coverage across the U.S.
• Cohesive global network
• Focused capabilities across disciplines

BDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world’s fifth largest accounting network.

BDO offers a competitive Total Rewards package that encompass so much more than – “traditional benefits”. Our wide range of rewards and our employees’ ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best & Brightest Companies to Work For and more.

Some Examples Of Our Total Rewards Offerings Include
• Competitive pay and eligibility for an annual performance bonus.
• A 401k plan plus an employer match
• Comprehensive, medical, dental, vision, FSA, and prescription insurance from day one
• Competitive Paid Time Off with daily accrual from day one of employment, plus paid holidays
• Paid Parental Leave
• Adoption Assistance
• Firm paid life insurance
• Wellness programs
• Additional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance

Above offerings may be subject to eligibility requirements.

Click here to find out more!

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status.

""BDO USA, P.A. is an EO employer M/F/Veteran/Disability""",Fort Worth,US,2023-12-19 11:52:00,http://www.bdo.com,Consulting
165,FULLTIME,Senior Cloud Data Engineer,https://www.linkedin.com/jobs/view/senior-cloud-data-engineer-at-bdo-usa-3765470282,"Job Description

Job Summary:

This position will work with cutting edge technology, deliver high quality solutions across various industries, and oversee team(s) on engagements that range in size and scope. This position will receive continuous career development opportunities, given the size and potential of client engagements. This role will perform hands-on delivery of data analytics projects, contributing to the development and unit testing of solutions.

Job Duties
• Designs and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS
• Listens to client needs to align solution with business requirements and delivery schedule
• Creates written functional and technical designs
• Participates in project status and stand meetings, and assists with providing aggregated project status for project and program managers
• Assists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions
• Writes code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles
• Delivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency)
• Assists with implementation of data governance programs and best practices
• Performs the cleaning and transforming of data from source systems into analytics models
• Implements models to support data visualizations and integrations
• Assists with implementing DevOps, DataOps and MLOps methodologies on projects
• Writes custom integration logic in applicable programming languages
• Assists project managers with work breakdown structure creation, project estimation, resource staffing, workload planning and adjustments throughout the project lifecycle
• Assists clients with licensing, security, and cost estimation of solutions
• Performs code reviews to ensure adherence to standards
• Works directly with clients and team members to establish secure data analytics platforms and infrastructure
• Contributes to successful deployments of developed solutions and integration of DevOps tools
• Maintains a broad and current understanding of data analytics and business intelligence strategies, cloud platforms, methodologies, and tools
• Builds client relationships during project execution, effectively becoming a trusted advisor of the client
• Participates in support activities for existing software solutions
• Other duties as assigned

Supervisory Responsibilities
• Supervises the day-to-day workload of Associates on assigned engagements to ensure that timelines and deliverables are met, and reviews work product

Education

Qualifications, Knowledge, Skills and Abilities:
• High School Diploma or GED equivalent, required
• Bachelor’s degree, preferred; focus in Information Systems, Data Science or Computer Science, preferred

Experience
• Five (5) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required
• One (1) or more years of experience technically leading development projects, preferred
• One (1) or more years of consulting experience or implementation of cloud-based data analytics solutions, preferred

Software
• Strong SQL skills including Data Definition Language (DDL), Data Manipulation Language (DML), views, functions, stored procedures, or performance tuning, required
• Experience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema Construction, required
• Hands on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, preferred
• Experience with one (1) or more of the following computer languages, preferred:
• C#
• Python
• Java
• Scala
• Experience with tabular modeling within Microsoft Fabric, Power BI, or Azure Analysis Services, preferred
• Experience with Git and DevOps deployment technologies, preferred
• Experience with Linux, preferred
• Experience with one (1) or more of the following, preferred:
• Data Lake Medallion Architecture
• Batch and/or streaming data ingestion into a data lake
• AI Algorithms/Machine Learning
• Automation tools such as UiPath, Alteryx, etc.
• Computer Vision based AI technologies

Other Knowledge, Skills & Abilities
• Ability to work with a high degree of professionalism and autonomy
• Excellent verbal and written communication skills
• Solid organizational skills, especially the ability to meet project deadlines with a focus on details
• Ability to successfully multi-task while working independently or within a group environment
• Ability to work in a deadline-driven environment, and handle multiple projects simultaneously
• Ability to interact effectively with people at all organizational levels of the Firm
• Ability to effectively interact with a team of professionals and delegating work assignments, as needed
• Ability to build and maintain strong relationships with internal and client personnel
• Ability to encourage a team environment on engagements, and contribute to the professional development of assigned personnel

Keywords: Data Analytics, Business Intelligence, BI, Synapse, IoT, Machine Learning, Data Lake, Stream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine Learning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Python, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling, SQL, SSIS, SSAS, SSRS, PySpark, Microsoft Fabric, dbt, Linux, Terraform, Bicep, Data Ops, Purview, Git, Delta, Pandas, Spark SQL

Individual salaries that are offered to a candidate are determined after consideration of numerous factors including but not limited to the candidate’s qualifications, experience, skills, and geography.

California Range: $111,000 - $152,000

Colorado Range: $111,000 - $152,000

New York City/ Valhalla Range: $111,000 - $152,000

Washington Range: $111,000 - $152,000

About Us

BDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients’ needs. We currently serve more than 400 publicly traded domestic and international clients.
• Unparalleled partner-involvement
• Deep industry knowledge and participation
• Geographic coverage across the U.S.
• Cohesive global network
• Focused capabilities across disciplines

BDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world’s fifth largest accounting network.

BDO offers a competitive Total Rewards package that encompass so much more than – “traditional benefits”. Our wide range of rewards and our employees’ ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best & Brightest Companies to Work For and more.

Some Examples Of Our Total Rewards Offerings Include
• Competitive pay and eligibility for an annual performance bonus.
• A 401k plan plus an employer match
• Comprehensive, medical, dental, vision, FSA, and prescription insurance from day one
• Competitive Paid Time Off with daily accrual from day one of employment, plus paid holidays
• Paid Parental Leave
• Adoption Assistance
• Firm paid life insurance
• Wellness programs
• Additional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance

Above offerings may be subject to eligibility requirements.

Click here to find out more!

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status.

""BDO USA, P.A. is an EO employer M/F/Veteran/Disability""",Columbus,US,2023-12-19 12:15:00,http://www.bdo.com,Consulting
166,FULLTIME,Senior Cloud Data Engineer,https://www.linkedin.com/jobs/view/senior-cloud-data-engineer-at-bdo-usa-3765466998,"Job Description

Job Summary:

This position will work with cutting edge technology, deliver high quality solutions across various industries, and oversee team(s) on engagements that range in size and scope. This position will receive continuous career development opportunities, given the size and potential of client engagements. This role will perform hands-on delivery of data analytics projects, contributing to the development and unit testing of solutions.

Job Duties
• Designs and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS
• Listens to client needs to align solution with business requirements and delivery schedule
• Creates written functional and technical designs
• Participates in project status and stand meetings, and assists with providing aggregated project status for project and program managers
• Assists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions
• Writes code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles
• Delivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency)
• Assists with implementation of data governance programs and best practices
• Performs the cleaning and transforming of data from source systems into analytics models
• Implements models to support data visualizations and integrations
• Assists with implementing DevOps, DataOps and MLOps methodologies on projects
• Writes custom integration logic in applicable programming languages
• Assists project managers with work breakdown structure creation, project estimation, resource staffing, workload planning and adjustments throughout the project lifecycle
• Assists clients with licensing, security, and cost estimation of solutions
• Performs code reviews to ensure adherence to standards
• Works directly with clients and team members to establish secure data analytics platforms and infrastructure
• Contributes to successful deployments of developed solutions and integration of DevOps tools
• Maintains a broad and current understanding of data analytics and business intelligence strategies, cloud platforms, methodologies, and tools
• Builds client relationships during project execution, effectively becoming a trusted advisor of the client
• Participates in support activities for existing software solutions
• Other duties as assigned

Supervisory Responsibilities
• Supervises the day-to-day workload of Associates on assigned engagements to ensure that timelines and deliverables are met, and reviews work product

Education

Qualifications, Knowledge, Skills and Abilities:
• High School Diploma or GED equivalent, required
• Bachelor’s degree, preferred; focus in Information Systems, Data Science or Computer Science, preferred

Experience
• Five (5) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required
• One (1) or more years of experience technically leading development projects, preferred
• One (1) or more years of consulting experience or implementation of cloud-based data analytics solutions, preferred

Software
• Strong SQL skills including Data Definition Language (DDL), Data Manipulation Language (DML), views, functions, stored procedures, or performance tuning, required
• Experience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema Construction, required
• Hands on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, preferred
• Experience with one (1) or more of the following computer languages, preferred:
• C#
• Python
• Java
• Scala
• Experience with tabular modeling within Microsoft Fabric, Power BI, or Azure Analysis Services, preferred
• Experience with Git and DevOps deployment technologies, preferred
• Experience with Linux, preferred
• Experience with one (1) or more of the following, preferred:
• Data Lake Medallion Architecture
• Batch and/or streaming data ingestion into a data lake
• AI Algorithms/Machine Learning
• Automation tools such as UiPath, Alteryx, etc.
• Computer Vision based AI technologies

Other Knowledge, Skills & Abilities
• Ability to work with a high degree of professionalism and autonomy
• Excellent verbal and written communication skills
• Solid organizational skills, especially the ability to meet project deadlines with a focus on details
• Ability to successfully multi-task while working independently or within a group environment
• Ability to work in a deadline-driven environment, and handle multiple projects simultaneously
• Ability to interact effectively with people at all organizational levels of the Firm
• Ability to effectively interact with a team of professionals and delegating work assignments, as needed
• Ability to build and maintain strong relationships with internal and client personnel
• Ability to encourage a team environment on engagements, and contribute to the professional development of assigned personnel

Keywords: Data Analytics, Business Intelligence, BI, Synapse, IoT, Machine Learning, Data Lake, Stream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine Learning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Python, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling, SQL, SSIS, SSAS, SSRS, PySpark, Microsoft Fabric, dbt, Linux, Terraform, Bicep, Data Ops, Purview, Git, Delta, Pandas, Spark SQL

Individual salaries that are offered to a candidate are determined after consideration of numerous factors including but not limited to the candidate’s qualifications, experience, skills, and geography.

California Range: $111,000 - $152,000

Colorado Range: $111,000 - $152,000

New York City/ Valhalla Range: $111,000 - $152,000

Washington Range: $111,000 - $152,000

About Us

BDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients’ needs. We currently serve more than 400 publicly traded domestic and international clients.
• Unparalleled partner-involvement
• Deep industry knowledge and participation
• Geographic coverage across the U.S.
• Cohesive global network
• Focused capabilities across disciplines

BDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world’s fifth largest accounting network.

BDO offers a competitive Total Rewards package that encompass so much more than – “traditional benefits”. Our wide range of rewards and our employees’ ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best & Brightest Companies to Work For and more.

Some Examples Of Our Total Rewards Offerings Include
• Competitive pay and eligibility for an annual performance bonus.
• A 401k plan plus an employer match
• Comprehensive, medical, dental, vision, FSA, and prescription insurance from day one
• Competitive Paid Time Off with daily accrual from day one of employment, plus paid holidays
• Paid Parental Leave
• Adoption Assistance
• Firm paid life insurance
• Wellness programs
• Additional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance

Above offerings may be subject to eligibility requirements.

Click here to find out more!

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status.

""BDO USA, P.A. is an EO employer M/F/Veteran/Disability""",Fort Lauderdale,US,2023-12-19 12:11:00,http://www.bdo.com,Consulting
